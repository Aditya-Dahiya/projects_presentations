[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Presentations, Data Viz & More",
    "section": "",
    "text": "Welcome to my webpage, where knowledge meets creativity! Explore my Presentations tab to delve into a collection of insightful training sessions and lectures, and head to Projects to witness the art of data visualization and data science in action. For more about me, visit my main webpage here."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Dr.¬†Aditya Dahiya, IAS\nWelcome to my corner of the internet, where I aim to share my experiences and insights gained from a journey that has taken me from the halls of Harvard to the heart of Haryana. I am Dr.¬†Aditya Dahiya, an IAS officer with a background in medicine, and it‚Äôs truly an honor to have you here. This website serves as a platform where I house the session presentations from various lectures I‚Äôve had the privilege of giving in different places. As I embark on this digital voyage, my hope is to engage with you in meaningful conversations about the worlds of public health, governance, and perhaps even a few stories from the tennis court."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html",
    "href": "manual_office_procedure_22_sep_23.html",
    "title": "Manual of Office Procedure",
    "section": "",
    "text": "Part-IPart-IIPart-III\n\n\n\nBranch: The work unit within a department responsible for attending to items of work allotted to it. It includes ‚ÄòCell,‚Äô ‚ÄòUnit,‚Äô ‚ÄòSection,‚Äô and similar terms. Generally headed by a Branch In-charge, Superintendent, or other officials.\nBranch Officer (Secretariat): An officer of the level of Under Secretary/Deputy Secretary responsible for work within the Branch.\n\n\n\n\nCome-back Case: A case received back for further action, such as re-examination or drafting a summary.\nCall Book: If a current case cannot be expedited for at least 6 months (e.g., cases held up in law courts), it may be transferred to the call book with approval from an officer not below the level of Branch Officer.\n\n\n\n\nSectional Note: A note recorded on one of the many issues raised in the PUC.\nStanding Note: A continuing note explaining the history and development of policy and procedure, serving as background material for policy reviews, replies to Assembly questions, and induction/training material."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-i-definitions",
    "href": "manual_office_procedure_22_sep_23.html#part-i-definitions",
    "title": "Manual of Office Procedure",
    "section": "Part-I: Definitions",
    "text": "Part-I: Definitions\n\nBranch: The work unit within a department responsible for attending to items of work allotted to it. It includes ‚ÄòCell,‚Äô ‚ÄòUnit,‚Äô ‚ÄòSection,‚Äô and similar terms. Generally headed by a Branch In-charge, Superintendent, or other officials.\nBranch Officer (Secretariat): An officer of the level of Under Secretary/Deputy Secretary responsible for work within the Branch."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-ii-definitions",
    "href": "manual_office_procedure_22_sep_23.html#part-ii-definitions",
    "title": "Manual of Office Procedure",
    "section": "Part-II: Definitions",
    "text": "Part-II: Definitions\n\nCome-back Case: A case received back for further action, such as re-examination or drafting a summary.\nCall Book: If a current case cannot be expedited for at least 6 months (e.g., cases held up in law courts), it may be transferred to the call book with approval from an officer not below the level of Branch Officer."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-iii-definitions",
    "href": "manual_office_procedure_22_sep_23.html#part-iii-definitions",
    "title": "Manual of Office Procedure",
    "section": "Part-III: Definitions",
    "text": "Part-III: Definitions\n\nSectional Note: A note recorded on one of the many issues raised in the PUC.\nStanding Note: A continuing note explaining the history and development of policy and procedure, serving as background material for policy reviews, replies to Assembly questions, and induction/training material."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#business-of-the-haryana-government-allocation-rules-1974",
    "href": "manual_office_procedure_22_sep_23.html#business-of-the-haryana-government-allocation-rules-1974",
    "title": "Manual of Office Procedure",
    "section": "Business of the Haryana Government (Allocation) Rules, 1974",
    "text": "Business of the Haryana Government (Allocation) Rules, 1974\n\nAllocate government business among different departments."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#rules-of-business-of-the-government-of-haryana-1977",
    "href": "manual_office_procedure_22_sep_23.html#rules-of-business-of-the-government-of-haryana-1977",
    "title": "Manual of Office Procedure",
    "section": "Rules of Business of the Government of Haryana, 1977",
    "text": "Rules of Business of the Government of Haryana, 1977\n\nPart IPart II\n\n\n\nDefine the authority, responsibility, and obligations of each department.\nSpecify cases to be submitted for prior approval to the Governor, Chief Minister, and Cabinet.\nDescribe circumstances requiring consultation with other departments.\n\n\n\n\nRule 18: Cases disposed of by or under the authority of the Minister-in-charge. Delegation via Standing Orders.\nRule 19: Minister‚Äôs arrangement with Administrative Secretary for cases brought to personal notice.\nRule 28: Matters required to be submitted to the Chief Minister/Governor."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#rules-of-business-of-the-government-of-haryana-1977-1",
    "href": "manual_office_procedure_22_sep_23.html#rules-of-business-of-the-government-of-haryana-1977-1",
    "title": "Manual of Office Procedure",
    "section": "Rules of Business of the Government of Haryana, 1977",
    "text": "Rules of Business of the Government of Haryana, 1977\n\nRule 18: Cases disposed of by or under the authority of the Minister-in-charge. Delegation via Standing Orders.\nRule 19: Minister‚Äôs arrangement with Administrative Secretary for cases brought to personal notice.\nRule 28: Matters required to be submitted to the Chief Minister/Governor."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-i-duties-of-branch-officer",
    "href": "manual_office_procedure_22_sep_23.html#part-i-duties-of-branch-officer",
    "title": "Manual of Office Procedure",
    "section": "Part-I: Duties of Branch Officer",
    "text": "Part-I: Duties of Branch Officer\n\nA Branch officer is the junior most officer on the first rung of the secretariat hierarchy authorized to issue orders in the name of the Governor of Haryana as per Rule 9(i) of the Rules of Business of Government of Haryana, 1977.\nControl and supervise the Branch(es) placed in his charge.\nGuide the staff on how to deal with papers, both generally and in individual cases."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-ii-duties-of-branch-officer",
    "href": "manual_office_procedure_22_sep_23.html#part-ii-duties-of-branch-officer",
    "title": "Manual of Office Procedure",
    "section": "Part-II: Duties of Branch Officer",
    "text": "Part-II: Duties of Branch Officer\n\nCheck for delay, superfluous noting, and prolixity of language, whether in notes or drafts, and enforce the rigid observance of all rules.\nPass final orders approving proposals of a routine nature or requiring only the formal sanction of Government.\nEnsure that points on which orders are required are clearly and concisely set forth and ordinarily express his own views on them."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-iii-duties-of-branch-officer",
    "href": "manual_office_procedure_22_sep_23.html#part-iii-duties-of-branch-officer",
    "title": "Manual of Office Procedure",
    "section": "Part-III: Duties of Branch Officer",
    "text": "Part-III: Duties of Branch Officer\n\nNoting and drafting on cases of policy framing and complicated nature should, as far as possible, be done by the Branch Officer who should utilize the service of Dealing-hand/Assistant/Branch In-charge for the collection of statistics or papers.\nIf there is any dispute on a particular receipt regarding which Branch or who will examine it, the decision for allocation shall be taken by the Branch officer.\nMake surprise visits to the Branch to check attendance and ensure that other instructions are correctly observed."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-i-duties-of-ddo",
    "href": "manual_office_procedure_22_sep_23.html#part-i-duties-of-ddo",
    "title": "Manual of Office Procedure",
    "section": "Part-I: Duties of DDO",
    "text": "Part-I: Duties of DDO\n\nAssist the Head of Office/Head of Department in the discharge of financial activities.\nTimely preparation and submission of receipts/expenditure through the online system.\nTimely submission of reports and returns to the Finance Department/Principal Accountant General, Haryana."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-ii-duties-of-ddo",
    "href": "manual_office_procedure_22_sep_23.html#part-ii-duties-of-ddo",
    "title": "Manual of Office Procedure",
    "section": "Part-II: Duties of DDO",
    "text": "Part-II: Duties of DDO\n\nMaintenance of Salary Bills Register, TA Bills Register, Contingent Register, and Cash Book.\nUpdate entries in the Service Book of employees manually and through HRMS.\nMake available all records required by the Audit Party."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-i-branch-in-charge-duties",
    "href": "manual_office_procedure_22_sep_23.html#part-i-branch-in-charge-duties",
    "title": "Manual of Office Procedure",
    "section": "Part-I: Branch In-charge duties",
    "text": "Part-I: Branch In-charge duties\n\nOverall responsible for supervising the activities and performance of the Branch.\nGo through the dak received, mark it to the dealing hands with dated initials indicating the urgency.\nReturn the dak not concerned to the Branch, if any.\nSend a photo-copy of fresh receipt of important nature to the higher authorities for perusal in case the said authorities have not seen the same, with the indication that action is being taken."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-ii-branch-in-charge-duties",
    "href": "manual_office_procedure_22_sep_23.html#part-ii-branch-in-charge-duties",
    "title": "Manual of Office Procedure",
    "section": "Part-II: Branch In-charge duties",
    "text": "Part-II: Branch In-charge duties\n\nSee that all the corrections have been made before submitting the fair draft for signatures.\nGive special instructions, where necessary, on the draft as to the manner of its issue, e.g., ‚ÄúBy Registered Post,‚Äù ‚ÄúInsured Cover,‚Äù ‚ÄúSpeed Post,‚Äù ‚ÄúBy Hand through Special Messenger,‚Äù or Through email, etc.\nKeep a note in his personal diary about all important receipts like Court Cases; Assembly Business; Important letters received from GOI; and letter(s)/file(s) with the remarks of higher authorities which need prompt examination."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-iii-branch-in-charge-duties",
    "href": "manual_office_procedure_22_sep_23.html#part-iii-branch-in-charge-duties",
    "title": "Manual of Office Procedure",
    "section": "Part-III: Branch In-charge duties",
    "text": "Part-III: Branch In-charge duties\n\nScrutinize the notes and drafts submitted by Assistants for correctness and accuracy and add his own remarks or suggestions where necessary before submitting the case to the higher officers.\nInspect the tables of his Assistant/Clerks periodically to see that fresh receipts and cases are properly and punctually submitted.\nGive priority markings on dak, drafts, letters, etc., and remove or revise such markings as and when necessary."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-iv-branch-in-charge-duties",
    "href": "manual_office_procedure_22_sep_23.html#part-iv-branch-in-charge-duties",
    "title": "Manual of Office Procedure",
    "section": "Part-IV: Branch In-charge duties",
    "text": "Part-IV: Branch In-charge duties\n\nEnsure that the Attendance Register is maintained correctly and submitted to the immediate superior in due time.\nEnsure availability of staff posted under him on holidays or early or late hours whenever required, maintain local addresses and mobile numbers of the entire staff.\nEnsure that each dealing hand and the diarist maintains all required registers and keep the same up-to-date. He should also check these registers at regular intervals."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-v-branch-in-charge-duties",
    "href": "manual_office_procedure_22_sep_23.html#part-v-branch-in-charge-duties",
    "title": "Manual of Office Procedure",
    "section": "Part-V: Branch In-charge duties",
    "text": "Part-V: Branch In-charge duties\n\nEnsure that all Manuals, Acts, Rules, Instructions, Guard Files, and Precedent Registers of the Branch are kept up-to-date by inserting correction-slips or getting new editions.\nKeep in his custody the personal files of the staff and ensure that blank forms for annual reports are put up to the Officers In-charge of the officials working under them in the month of March.\nCheck that the inventory of articles of furniture, etc., hung in their respective Rooms/Branches is kept up-to-date."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---i",
    "href": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---i",
    "title": "Manual of Office Procedure",
    "section": "Duties of ‚Äúdealing hand‚Äù - I",
    "text": "Duties of ‚Äúdealing hand‚Äù - I\n\nAn Assistant/dealing-hand posted in a branch/office works under the supervision of the Branch In-charge.\nHe/she is expected to deal with all the matters allocated to him and submit to the Branch In-charge efficiently as per the prescribed procedure.\nWhere a Record Keeper has not been provided, the functions of the Record Keeper will also be performed by the Assistant/Dealing-hand himself."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---ii",
    "href": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---ii",
    "title": "Manual of Office Procedure",
    "section": "Duties of ‚Äúdealing hand‚Äù - II",
    "text": "Duties of ‚Äúdealing hand‚Äù - II\n\nBefore proper examination of any issue on a file, Dealing-hand should ensure to go through the receipts to check the enclosures/facts and take note of any mistake(s).\nIf a file exists for the receipt, add the receipt to the existing file containing previous papers. In case there is no file on the subject, a new file may be opened as per the procedure laid down."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---iii",
    "href": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---iii",
    "title": "Manual of Office Procedure",
    "section": "Duties of ‚Äúdealing hand‚Äù - III",
    "text": "Duties of ‚Äúdealing hand‚Äù - III\n\nPut up the Standing Guard File/Precedents File or reference folder, other facts and figures relevant to the issue under consideration.\nDocket the receipt and reproduce the remarks, if any, recorded by an officer on the receipt, in the beginning on the right-hand side of his noting.\nRecord his note on the noting-sheet as per the procedure laid down in Chapter-VII, Action on Receipt ‚Äì Noting."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---iv",
    "href": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---iv",
    "title": "Manual of Office Procedure",
    "section": "Duties of ‚Äúdealing hand‚Äù - IV",
    "text": "Duties of ‚Äúdealing hand‚Äù - IV\n\nBring out clearly the administrative, financial, and legal implications, if any, and suggest a course of action wherever possible.\nPrepare and keep up-to-date a ‚Äúrunning summary of facts‚Äù or pr√©cis on a case where it is considered necessary.\nPut up a draft as per detailed procedure in Chapter-VIII of the Manual.\nIndicate the ‚ÄòLevel‚Äô of disposal in the margin of the note as per ‚ÄòStanding Order‚Äô or any other order/decision in vogue."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---v",
    "href": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---v",
    "title": "Manual of Office Procedure",
    "section": "Duties of ‚Äúdealing hand‚Äù - V",
    "text": "Duties of ‚Äúdealing hand‚Äù - V\n\nMaintain the Guard File of important decisions and instructions concerning him.\nEnsure acknowledgments to communications received from Members of Parliament, Legislature, and Public Bodies promptly, and issue interim replies if a delay is anticipated in sending out the final reply.\nMaintain a subject-wise collection of all important decisions and circulars/other communications relating to various subjects dealt with in the Branch along with standard drafts, if any."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#referencing-on-files---i",
    "href": "manual_office_procedure_22_sep_23.html#referencing-on-files---i",
    "title": "Manual of Office Procedure",
    "section": "Referencing on Files - I",
    "text": "Referencing on Files - I\n\nEvery page of the noting/correspondence portion of the file should be consecutively numbered.\nThe paper under consideration or a fresh receipt will be flagged ‚ÄòPUC‚Äô on the right corner of the paper.\nIn case a draft reply is also added, it will be flagged ‚ÄòDFA‚Äô on the left corner of the paper. In referring to the papers, the relevant page number of the noting/correspondence portions will be quoted invariably in the margin of PUC/DFA."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#referencing-on-files---ii",
    "href": "manual_office_procedure_22_sep_23.html#referencing-on-files---ii",
    "title": "Manual of Office Procedure",
    "section": "Referencing on Files - II",
    "text": "Referencing on Files - II\n\nThe recorded files and all other papers which are put up with the current file will be flagged with alphabetical slips for quick identification.\nOnly one alphabetical slip will be attached to each recorded file or compilation. While giving reference to the papers contained therein, those should be identified by the relevant page in addition to the alphabetical slip, e.g., A/15, A/29, and so on."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#referencing-on-files---iii",
    "href": "manual_office_procedure_22_sep_23.html#referencing-on-files---iii",
    "title": "Manual of Office Procedure",
    "section": "Referencing on Files - III",
    "text": "Referencing on Files - III\n\nWhenever reference to the papers contained in other files is given in the note, the number of the file may also be quoted in the note in order to facilitate the location of the reference after those files are removed from the current file after completion of action.\nWhen a single reference is quoted in a fresh receipt, and that reference is in a file put up with another case, a copy of the required paper should be made, and the fresh receipt submitted with it to avoid delay."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#referencing-on-files---iv",
    "href": "manual_office_procedure_22_sep_23.html#referencing-on-files---iv",
    "title": "Manual of Office Procedure",
    "section": "Referencing on Files - IV",
    "text": "Referencing on Files - IV\n\nNo case should be kept pending until the connected references are available without the specific orders of the Branch In-charge.\nIn urgent cases, the Branch In-charge should take orders of higher officers, and he should do the same in ordinary cases if the references needed do not become available within, say, a week of receipt of the communication. Such cases should always be shown in the arrear lists, and it should be noted whether the case is pending under the orders of an officer."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---i",
    "href": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---i",
    "title": "Manual of Office Procedure",
    "section": "Guidelines for Noting - I",
    "text": "Guidelines for Noting - I\n\nA note must be concise, clear, complete, correct, courteous, and to the point. Lengthy notes are to be avoided.\nThe verbatim reproduction of extracts from or paraphrasing of the paper under consideration, fresh receipt, or any other part of correspondence or notes on the same file should be avoided.\nAll notes should be written in the third person."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---ii",
    "href": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---ii",
    "title": "Manual of Office Procedure",
    "section": "Guidelines for Noting - II",
    "text": "Guidelines for Noting - II\n\nRelevant extracts of the provisions of the Act, Rules, and /or guidelines will be placed on the file, and attention will be drawn to it in the note, rather than reproducing the relevant provisions in the note.\nMake a note of the actual points proposed to make without reiterating the ground already covered in the previous notes. If one agrees with the line of action suggested in the preceding note, merely append a signature.\nA self-contained note will be put up with every case submitted to the Administrative Secretary or Minister."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---iii",
    "href": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---iii",
    "title": "Manual of Office Procedure",
    "section": "Guidelines for Noting - III",
    "text": "Guidelines for Noting - III\n\nA self-contained note is prepared while seeking advice or opinion or concurrence of another Department.\nSufficient space, not less than one quarter of the page, should be left below the last recorded note in the note sheet of the file, especially when the file is submitted to the Secretary or Minister level."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---iv",
    "href": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---iv",
    "title": "Manual of Office Procedure",
    "section": "Guidelines for Noting - IV",
    "text": "Guidelines for Noting - IV\n\nTwo extra blank note-sheets should be added to the noting portion after completing the note.\nThe dealing hand (non-gazetted) is required to sign the note on the extreme left part near the margin. However, the gazetted officers will sign on the right-hand side."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#examination-of-file-note-by-a-branch-in-charge",
    "href": "manual_office_procedure_22_sep_23.html#examination-of-file-note-by-a-branch-in-charge",
    "title": "Manual of Office Procedure",
    "section": "Examination of File Note by a Branch In-charge",
    "text": "Examination of File Note by a Branch In-charge\n\nWhen making suggestions for approval of senior officers, the Branch In-charge will confine his note to the actual points he proposes to make without re-iterating the grounds already covered in the previous notes.\nState the questions for consideration and bring out clearly the points requiring a decision."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#running-summary-of-facts",
    "href": "manual_office_procedure_22_sep_23.html#running-summary-of-facts",
    "title": "Manual of Office Procedure",
    "section": "Running Summary of Facts",
    "text": "Running Summary of Facts\n\nTo facilitate consideration and to obviate repeated recapitulation in important, complex, and court cases, a running summary of facts will be prepared and placed on the file in a separate folder labeled as such in every case where it is evident that such a summary would contribute to its speedy disposal.\nPrevious versions of the running summary, if any, shall not be destroyed."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#modification-of-notes-or-order",
    "href": "manual_office_procedure_22_sep_23.html#modification-of-notes-or-order",
    "title": "Manual of Office Procedure",
    "section": "Modification of Notes or Order",
    "text": "Modification of Notes or Order\n\nWhere a final decision already communicated to a party is found later on to have been given on a mistaken ground or wrong facts or wrong interpretation of rules due to misunderstanding or otherwise, such replacement or modification of a note may have legal implications.\nIn all such cases, wherever necessary, a review of the decision should be examined, and the revised decision shall be taken with the approval of an officer higher than the one, if available, who took the original decision."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#types-or-categories-of-cases-and-quantum-of-noting",
    "href": "manual_office_procedure_22_sep_23.html#types-or-categories-of-cases-and-quantum-of-noting",
    "title": "Manual of Office Procedure",
    "section": "Types or Categories of Cases and Quantum of Noting",
    "text": "Types or Categories of Cases and Quantum of Noting\n\n\n\n\n\n\n\n\n\nType or Category of the Case\nQuantum of Noting\n\n\n\n\n1\nEphemeral\nNo noting is needed\n\n\n2\nAction in Correspondence Cases\nShort notes of a few sentences\n\n\n3\nRoutine or Repetitive Case\nDevelop and use Standard Process Sheet\n\n\n4\nProblem Solving Case\nA structured and detailed note is prepared.\n\n\n5\nPolicy/Planning Case\nDetailed note is prepared covering various aspects, implications, and expected outcomes of a policy to be developed or under review."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---i",
    "href": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---i",
    "title": "Manual of Office Procedure",
    "section": "U.O. Letter or Un-Official References - I",
    "text": "U.O. Letter or Un-Official References - I\n\nInter-departmental references are made un-officially to officers and Heads of Departments who are not part of Secretariat.\nWhen Secretaries to Government desire to obtain an expression of opinion, advice, or supplementary information from such officers and Heads of Departments in an un-official manner, they should do so by sending the files and notes.\nIt is only where these officers make references as Secretaries on their own files that it is treated as an un-official reference."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---ii",
    "href": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---ii",
    "title": "Manual of Office Procedure",
    "section": "U.O. Letter or Un-Official References - II",
    "text": "U.O. Letter or Un-Official References - II\n\nIn the case of inter-departmental reference, the department or office of origin should state, with as much precision as possible, the specific points in respect to which reference is made.\nReferences to the Legal Remembrancer should definitely state the points on which his opinion or advice is required."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---iii",
    "href": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---iii",
    "title": "Manual of Office Procedure",
    "section": "U.O. Letter or Un-Official References - III",
    "text": "U.O. Letter or Un-Official References - III\n\nIn every file referred to by one department or office to another department or office, the notes written in the department or office referred to should (when this is desirable) be on separate sheets (in duplicate) from the notes written in the referring department, and the conclusion only should be recorded under the signature of the officer to whom an un-official reference was made."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#level-of-approval-of-draft",
    "href": "manual_office_procedure_22_sep_23.html#level-of-approval-of-draft",
    "title": "Manual of Office Procedure",
    "section": "Level of Approval of Draft",
    "text": "Level of Approval of Draft\n\nAfter the orders are passed by the competent authority on a file, the Draft for Approval (DFA) should be approved by the authority minimum one step above the authority who has to sign the fair draft, except in routine cases (e.g., reminder letter, supply of definite information) after the approval of the competent authority."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#drafting-by-officers-of-important-cases",
    "href": "manual_office_procedure_22_sep_23.html#drafting-by-officers-of-important-cases",
    "title": "Manual of Office Procedure",
    "section": "Drafting by Officers of Important Cases",
    "text": "Drafting by Officers of Important Cases\n\nBranch officers are expected to prepare drafts of important cases. As a general rule, the Branch officer should send to Branch only such cases for submission of drafts, which can easily be followed by an Assistant/Dealing hand."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#inter-departmental-consultation",
    "href": "manual_office_procedure_22_sep_23.html#inter-departmental-consultation",
    "title": "Manual of Office Procedure",
    "section": "Inter-Departmental Consultation",
    "text": "Inter-Departmental Consultation\n\nOn file, the consultation with the concerned Department can be done by either of the two methods:\n\nBy referring the case file; or\nBy making a self-contained U.O. (Un-Official) reference with all relevant documents.\n\nThe first method is the common one and is generally followed in most of the cases, as it is simple because all relevant papers are usually available in the case file."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---i",
    "href": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---i",
    "title": "Manual of Office Procedure",
    "section": "Components of a Charge handing-over Note - I",
    "text": "Components of a Charge handing-over Note - I\n\nList of key areas/responsibilities related to key areas.\nStaff position at present.\nA brief write-up on the sensitive matters being dealt with in the Division."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---ii",
    "href": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---ii",
    "title": "Manual of Office Procedure",
    "section": "Components of a Charge handing-over Note - II",
    "text": "Components of a Charge handing-over Note - II\n\nList of documents required by the officer for handling the responsibilities are annexed.\nWhat were the predecessor‚Äôs experiences of working in the ministry/Department and what steps need to be taken to improve the situation.\nChallenges that he/she has faced and how they have overcome them."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---iii",
    "href": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---iii",
    "title": "Manual of Office Procedure",
    "section": "Components of a Charge handing-over Note - III",
    "text": "Components of a Charge handing-over Note - III\n\nWhat are the constraints under which the work had to be undertaken.\nDetails of counterparts in other Ministries with whom constant interaction takes place and also details of officers of nodal ministries/Departments.\nList of counterparts in various Departments along with the subject matter."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#list-of-important-documents---i",
    "href": "manual_office_procedure_22_sep_23.html#list-of-important-documents---i",
    "title": "Manual of Office Procedure",
    "section": "List of important documents - I",
    "text": "List of important documents - I\n\nSecond Schedule of Rules of Business of Haryana Government, 1977.\nRelevant portion of the Business of the Haryana Government (Allocation) Rules, 1974.\nOrganisation / Functional Chart.\nWork allocation with details of work allocated to sections."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#list-of-important-documents---ii",
    "href": "manual_office_procedure_22_sep_23.html#list-of-important-documents---ii",
    "title": "Manual of Office Procedure",
    "section": "List of important documents - II",
    "text": "List of important documents - II\n\nList of attached offices, subordinate offices, autonomous bodies.\nDelegation of powers and Departmental instructions for decision-making within the Organisation.\nParliamentary matters - A folder containing answers provided to previous questions, notes for supplementary questions, Question days of the Ministry/Department."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#list-of-important-documents---iii",
    "href": "manual_office_procedure_22_sep_23.html#list-of-important-documents---iii",
    "title": "Manual of Office Procedure",
    "section": "List of important documents - III",
    "text": "List of important documents - III\n\nCourt cases - Status of court cases requiring attention.\nProjects/schemes completed and under process.\nBudget provision and the status of the utilization of funds/budget. Action on additional budget requirements, pending Audit paragraphs.\nRTI applications - pending."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#list-of-important-documents---iv",
    "href": "manual_office_procedure_22_sep_23.html#list-of-important-documents---iv",
    "title": "Manual of Office Procedure",
    "section": "List of important documents - IV",
    "text": "List of important documents - IV\n\nImportant instructions on files from senior officers on which responses are pending.\nImportant meetings in the next fortnight. Follow-up action on previous meetings.\nList of periodic reports that are generated by the office and that are received by the office."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#why",
    "href": "manual_office_procedure_22_sep_23.html#why",
    "title": "Manual of Office Procedure",
    "section": "Why?",
    "text": "Why?"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#the-fall-of-the-byzantine-empire",
    "href": "manual_office_procedure_22_sep_23.html#the-fall-of-the-byzantine-empire",
    "title": "Manual of Office Procedure",
    "section": "1. The Fall of the Byzantine Empire:",
    "text": "1. The Fall of the Byzantine Empire:\n\nThe Byzantine Empire fell in 1453 to the Ottoman Empire in part because they failed to adopt newer military technologies such as gunpowder cannons and firearms. This historic event illustrates how the reluctance to embrace technological innovation can lead to a civilization‚Äôs downfall."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#the-kodak-story",
    "href": "manual_office_procedure_22_sep_23.html#the-kodak-story",
    "title": "Manual of Office Procedure",
    "section": "2. The Kodak Story:",
    "text": "2. The Kodak Story:\n\nKodak, once a dominant force in the photography industry, failed to embrace digital photography technology in its early stages. The company‚Äôs reluctance to adapt eventually led to its decline, while digital photography companies like Canon and Nikon thrived. This story emphasizes the importance of staying ahead in the technology curve."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#nokia-and-the-smartphone-revolution",
    "href": "manual_office_procedure_22_sep_23.html#nokia-and-the-smartphone-revolution",
    "title": "Manual of Office Procedure",
    "section": "3. Nokia and the Smartphone Revolution:",
    "text": "3. Nokia and the Smartphone Revolution:\n\nNokia, once the world‚Äôs largest mobile phone manufacturer, underestimated the shift toward smartphones and touchscreen technology. Their inability to adapt quickly led to a significant decline in market share and eventual acquisition by Microsoft. It underscores the importance of recognizing and adapting to industry-changing technologies."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#scheduling-meetings-when2meet",
    "href": "manual_office_procedure_22_sep_23.html#scheduling-meetings-when2meet",
    "title": "Manual of Office Procedure",
    "section": "Scheduling Meetings: When2Meet",
    "text": "Scheduling Meetings: When2Meet\n\n\nThe problem of finding when everyone‚Äôs available !\nSolution:\nwhen2meet.com"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#automate-drafting-chatgpt",
    "href": "manual_office_procedure_22_sep_23.html#automate-drafting-chatgpt",
    "title": "Manual of Office Procedure",
    "section": "Automate Drafting: ChatGPT",
    "text": "Automate Drafting: ChatGPT\n\n\nMinutes of Meeting\nNoting\nPolicy Draft\nChatGPT\nDemonstration"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#speech-to-text",
    "href": "manual_office_procedure_22_sep_23.html#speech-to-text",
    "title": "Manual of Office Procedure",
    "section": "Speech-to-text",
    "text": "Speech-to-text\n\n\nGoogle Docs\nhttps://docs.google.com/\ndicatation.io\nhttps://dictation.io/speech"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#improving-grammer",
    "href": "manual_office_procedure_22_sep_23.html#improving-grammer",
    "title": "Manual of Office Procedure",
    "section": "Improving grammer",
    "text": "Improving grammer\n\nWordTune / Grammarly\nhttps://app.wordtune.com/editor\nChatGPT\nhttps://chat.openai.com/"
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nFeb 16, 2024\n\n\nField Inspections for Engineering Works\n\n\nAditya Dahiya\n\n\n\n\nNov 24, 2023\n\n\nToolkit for effective Inspections by Field Officers\n\n\nAditya Dahiya\n\n\n\n\nSep 22, 2023\n\n\nManual of Office Procedure\n\n\nAditya Dahiya\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\n\n\n\n\n\n\n\n\n\nYear\nDegree\nInstitution\nLocation\n\n\n\n\n2021-22\nMaster of Public Health\nHarvard University\nUSA\n\n\n2005-10\nM.B.B.S.\nAll India Institute of Medical Sciences (AIIMS)\nNew Delhi, India"
  },
  {
    "objectID": "about.html#work",
    "href": "about.html#work",
    "title": "About",
    "section": "Work",
    "text": "Work\n\n\n\n\n\n\n\nYear\nPosition\n\n\n\n\n2011-present\nIndian Administrative Service (IAS)\n\n\nJun 2022 - present\nDirector, Medical Education Haryana and Special Secretary\n\n\n\nGeneral Administration Department, Haryana\n\n\nAug 2021 - Jun 2022\nStudy Leave (Harvard University, USA)\n\n\nFeb 2019 - Aug 2021\nDeputy Commissioner, Jind District\n\n\nJuly 2017 - Feb 2019\nDeputy Commissioner, Karnal District\n\n\nAug 2016 - Jul 2017\nCommissioner, Municipal Corporation Karnal\n\n\nDec 2015 - Aug 2016\nCommissioner, Municipal Corporation Faridabad\n\n\nNov 2014 - Aug 2016\nAdditional Deputy Commissioner, Faridabad\n\n\nSep 2013 - Nov 2014\nSub-Divisional Magistrate, Jagadhri (Yamunanagar)\n\n\nJan 2011 - Aug 2011\nJunior Resident, Department of Neuro-Radiology, AIIMS, New Delhi\n\n\n\nAwards & Honors\n\nMar 2021: Fulbright Masters Fellowship by the Fulbright Commission in India\nDec 25, 2020: Atal Bihari Vajpayee Good Governance Award ‚Äì 2020 by the Government of Haryana\nJuly 15, 2020: Joint-Japan World Bank Graduate Fellowship by the World Bank\nMar 13, 2020: Best Officer in the Mid-Career Training Programme for Indian Administrative Service Officers, Lal Bahadur Shastri National Academy of Administration at Mussoorie (India)\nJan 24, 2019: National Award by the Ministry of Women and Child Development, Government of India for ‚ÄúEffective Community Engagement‚Äù in improvement in Gender-Ratio at Birth (GRB)\nMay 4, 2017: National Award as Commissioner of the Karnal Municipal Corporation - Cleanest City in North India (population category 0.2 to 0.5 million)\nDec 9, 2011: Director‚Äôs Shield for the Best All-Round Officer Trainee of the 86th Foundation Course of All India Services.\nOct 1, 2010: Delhi Medical Association‚Äôs Gold Medal for best all-round medical graduate at A.I.I.M.S. New Delhi\nMay, 2005: 1st Rank in National Pre-Medical Entrance Examination (CBSE PMT) for medical colleges in India\n\nExtracurricular Activities\n\n2013 ‚Äì 2015: Part of the Haryana state team at All-India Civil Services Lawn Tennis Tournament at Bhopal (2013), Chennai (2014), and Pune (2015).\nMay 4, 2013: Participated in the Dida I.T.F. Men‚Äôs Futures 15K Tournament held at Rohtak, India organized by the International Tennis Federation Futures Circuit for Men.\n\nConnect with me!\nWell, folks, that‚Äôs my life in a nutshell - a whirlwind journey that‚Äôs taken me from Harvard‚Äôs hallowed halls to the heartland of Haryana, from the world of scalpels and stethoscopes to the battlefield of bureaucracy, and yes, from the operating room to the tennis court (where I sometimes try to ‚Äòserve‚Äô justice, pun intended).\nDon‚Äôt hesitate to connect, dear reader. I‚Äôm just a click away, and I‚Äôd love to hear your thoughts, questions, or maybe even your own adventures from the world of academia, administration, or sports. üéìüéæ"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#definitions",
    "href": "manual_office_procedure_22_sep_23.html#definitions",
    "title": "Manual of Office Procedure",
    "section": "",
    "text": "Part-IPart-IIPart-III\n\n\n\nBranch: The work unit within a department responsible for attending to items of work allotted to it. It includes ‚ÄòCell,‚Äô ‚ÄòUnit,‚Äô ‚ÄòSection,‚Äô and similar terms. Generally headed by a Branch In-charge, Superintendent, or other officials.\nBranch Officer (Secretariat): An officer of the level of Under Secretary/Deputy Secretary responsible for work within the Branch.\n\n\n\n\nCome-back Case: A case received back for further action, such as re-examination or drafting a summary.\nCall Book: If a current case cannot be expedited for at least 6 months (e.g., cases held up in law courts), it may be transferred to the call book with approval from an officer not below the level of Branch Officer.\n\n\n\n\nSectional Note: A note recorded on one of the many issues raised in the PUC.\nStanding Note: A continuing note explaining the history and development of policy and procedure, serving as background material for policy reviews, replies to Assembly questions, and induction/training material."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#thank-you",
    "href": "manual_office_procedure_22_sep_23.html#thank-you",
    "title": "Manual of Office Procedure",
    "section": "Thank You",
    "text": "Thank You"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#dealing-files-from-another-department",
    "href": "manual_office_procedure_22_sep_23.html#dealing-files-from-another-department",
    "title": "Manual of Office Procedure",
    "section": "Dealing Files from Another Department",
    "text": "Dealing Files from Another Department\n\nIn every file referred by one Department to another for advice, concurrence, or opinion, the notes written by the Department or Branch/Section referred to should be on a ‚Äòshadow file,‚Äô i.e., a separate file.\nIn case the proposal of the receiving Department has been approved by the concerned Minister-in-Charge/Chief Minister, then a specific mention should be made in the advice being tendered to the referring Department that ‚ÄúMinister-in-Charge or Chief Minister, as the case may be, has approved.‚Äù"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#guidelines-for-noting",
    "href": "manual_office_procedure_22_sep_23.html#guidelines-for-noting",
    "title": "Manual of Office Procedure",
    "section": "Guidelines for Noting",
    "text": "Guidelines for Noting\n\nIIIIIIIV\n\n\n\nA note must be concise, clear, complete, correct, courteous, and to the point. Lengthy notes are to be avoided.\nThe verbatim reproduction of extracts from or paraphrasing of the paper under consideration, fresh receipt, or any other part of correspondence or notes on the same file should be avoided.\nAll notes should be written in the third person.\n\n\n\n\nRelevant extracts of the provisions of the Act, Rules, and /or guidelines will be placed on the file, and attention will be drawn to it in the note, rather than reproducing the relevant provisions in the note.\nMake a note of the actual points proposed to make without reiterating the ground already covered in the previous notes. If one agrees with the line of action suggested in the preceding note, merely append a signature.\nA self-contained note will be put up with every case submitted to the Administrative Secretary or Minister.\n\n\n\n\nA self-contained note is prepared while seeking advice or opinion or concurrence of another Department.\nSufficient space, not less than one quarter of the page, should be left below the last recorded note in the note sheet of the file, especially when the file is submitted to the Secretary or Minister level.\n\n\n\n\nTwo extra blank note-sheets should be added to the noting portion after completing the note.\nThe dealing hand (non-gazetted) is required to sign the note on the extreme left part near the margin. However, the gazetted officers will sign on the right-hand side."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Random Projects",
    "section": "",
    "text": "Data Visualizations from D.I.P.\n\n\nExamples of Visualizations created from the Data Is Plural Newsletter by Jeremy Singer-Vine\n\n\n\nData Is Plural\n\n\nData Visualization\n\n\n\n\n\n\n\n\n\nMar 31, 2024\n\n\nAditya Dahiya\n\n\n\n\n\n\n\n\n\n\n\n\nData Visualization Projects\n\n\nExamples of Visualizations Created for #TidyTuesday\n\n\n\n#TidyTuesday\n\n\nData Visualization\n\n\n\n\n\n\n\n\n\nMar 27, 2024\n\n\nAditya Dahiya\n\n\n\n\n\n\n\n\n\n\n\n\nAn interactive map of USA‚Äôs Groundhogs Day predictors\n\n\nInitially Created for #TidyTuesday\n\n\n\n#TidyTuesday\n\n\nInteractive\n\n\nData Visualization\n\n\n\n\n\n\n\n\n\nFeb 4, 2024\n\n\nAditya Dahiya\n\n\n\n\n\n\n\n\n\n\n\n\nA Rayshader Map for India‚Äôs Power Plants\n\n\nUsing Rayshader in R to plot map, inspired by Milos Makes Maps\n\n\n\nData Visualization\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nAditya Dahiya\n\n\n\n\n\n\n\n\n\n\n\n\nElectoral Kaleidoscope: Visualizing the Impact of Proportional Representation\n\n\nHow the PSR System could‚Äôve changed the 1992 and 2020 US House of Representatives majority party!\n\n\n\n#TidyTuesday\n\n\nData Visualization\n\n\n\n\n\n\n\n\n\nNov 12, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\n\n\n\n\n\n\nEerie Revelations: Text Analysis of Snopes.com‚Äôs Horror Legends\n\n\nLooking at the snopes.com articles as a part of #TidyTuesday Week 44 (Oct 31, 2023)\n\n\n\n#TidyTuesday\n\n\nText Mining\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\n\n\n\n\n\n\nPatient Risk Profiles\n\n\nLooking at the Jenna Rep‚Äôs curated data-set of Patient Risk Profiles as a part of #TidyTuesday Week 43 (Oct 23, 2023)\n\n\n\n#TidyTuesday\n\n\n\n\n\n\n\n\n\nOct 25, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\n\n\n\n\n\n\nMaking road-maps of cities with Open Street Maps\n\n\nA user-created function to create street art maps in a single line of code\n\n\n\nData Visualization\n\n\n\n\n\n\n\n\n\nOct 20, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\n\n\n\n\n\n\nDancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music\n\n\nLooking at the W. Jake Thompson‚Äôs curated data-set of Taylor Swift songs as a part of #TidyTuesday (Oct 10, 2023)\n\n\n\n#TidyTuesday\n\n\n\n\n\n\n\n\n\nOct 18, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\n\n\n\n\n\n\nCreating racing bar charts in R with gganimate\n\n\nAnnotated code to create racing bar charts using nycflight13 dataset\n\n\n\nData Visualization\n\n\n\n\n\n\n\n\n\nOct 17, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\n\n\n\n\n\n\nGhostly Jargon in Haunted Spots: A Gendered Perspective\n\n\nLooking at the dataset for haunted places in USA as a part of Tidy Tuesday (Oct 10, 2023)\n\n\n\n#TidyTuesday\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tidy_tuesday_2023_10_10.html",
    "href": "tidy_tuesday_2023_10_10.html",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "",
    "text": "Figure¬†1: Percentage of haunted locations with gender-specific terms in descriptions"
  },
  {
    "objectID": "tidy_tuesday_2023_10_10.html#ghostly-jargon-in-haunted-spots-a-gendered-perspective",
    "href": "tidy_tuesday_2023_10_10.html#ghostly-jargon-in-haunted-spots-a-gendered-perspective",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "text": "Ghostly Jargon in Haunted Spots: A Gendered Perspective\nFigure¬†2 illustrates the prevalence of gender-specific common words in haunted locations, comparing all American locations to haunted spots in universities and colleges.\n\n\n\n\n\nFigure¬†2: Gender-specific words‚Äô prevalence in haunted locations, comparing sites across USA with those in universities and colleges.\n\n\n\n\nCredits: Sentiment Analysis (Mohammad and Turney 2012) and code inspiration from Steven Ponce‚Äôs R script on GitHub."
  },
  {
    "objectID": "tidy_tuesday_2023_10_10.html#unique-verbiage-in-these-haunted-places",
    "href": "tidy_tuesday_2023_10_10.html#unique-verbiage-in-these-haunted-places",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "Unique Verbiage in these haunted places",
    "text": "Unique Verbiage in these haunted places\nIn contrast to the previous slide‚Äôs word clouds featuring overlapping terms, the Figure¬†3 shows distinct vocabulary found exclusively in male and female haunted locations.\n\n\n\n\n\nFigure¬†3: Unique words in descriptions of gender-specific haunted locations, but absent in descriptions of the opposite gender‚Äôs haunted places.\n\n\n\n\nCarefully look at All Haunted Places citing males: Who knew America‚Äôs haunted places had such a penchant for ‚Äúwife‚Äù ‚Äì even beyond the grave! Ghostly husbands, you‚Äôve got some explaining to do! üòÑüëª"
  },
  {
    "objectID": "projects/racing_bar_charts_r.html",
    "href": "projects/racing_bar_charts_r.html",
    "title": "Creating racing bar charts in R with gganimate",
    "section": "",
    "text": "Background\nWe‚Äôre about to embark on a thrilling journey through the world of animated racing bar charts in R - dynamic, action-packed data visualization that showcases the ebb and flow of information over time.\nInspired by the ingenious work of Deepsha Meghnani‚Äôs article on TidyTuesday and drawing creative insights from the brilliant minds at datacornering.com, we‚Äôll be crafting our very own data-driven racing bar chart masterpiece.\nOur canvas is the nycflights13 dataset, with details on flights departing from New York City‚Äôs three iconic airports, courtesy of various carriers, all throughout the year 2013.\nBut that‚Äôs not all. We won‚Äôt stop at just displaying the numbers. We‚Äôll also throw in some flair by illustrating the average delays associated with each of these carriers, injecting a dose of character into the aviation landscape of the Big Apple. We‚Äôre going to unravel the secrets of creating animated racing bar charts using the formidable ggplot2 and gganimate packages in R.\n\n\nCode\nlibrary(tidyverse)          # Loading Tidyverse for data wrangling\nlibrary(gt)                 # Loading gt package for beautiful tables\nlibrary(gganimate)          # For animations\nlibrary(nycflights13)       # for the flights data-set\nlibrary(lubridate)          # to handle dates in tidyverse\n\n\n\n\nCode\n# Loading the flights dataset\ndata(\"flights\")\n\n# Pick out the top nine airline carriers only, to avoid crowding the\n# upcoming animated plot\ncarriers_to_plot &lt;- flights |&gt;\n  \n  # Count the number of flights for each carrier and sort them in descending order\n  count(carrier, sort = TRUE) |&gt;\n  \n  # Select the top 9 carriers based on flight count\n  slice_head(n = 9) |&gt;\n  \n  # Extract the 'carrier' column from the result\n  pull(carrier)\n\ndf &lt;- flights |&gt; \n  \n  # Filter the flights dataset to include only the top 9 carriers\n  filter(carrier %in% carriers_to_plot) |&gt; \n  \n  # Create a new 'date' column by combining year, month, and day\n  # This allows us to make a single date variable, that nicely evolves\n  # over time in an animated plot\n  mutate(date = make_date(year = year, month = month, day = day)) |&gt; \n  \n  # Select only the 'date' and 'carrier' columns\n  select(date, carrier) |&gt;\n  \n  # Joining the full names of airlines for the annotations in animated plot\n  left_join(nycflights13::airlines, by = join_by(carrier)) |&gt;\n  \n  # Remove the 'carrier' column after joining\n  select(-carrier) |&gt;\n  \n  # Rename the 'name' column to 'carrier'\n  rename(carrier = name) |&gt;\n  \n  # Count the number of flights for each date and carrier combination\n  count(date, carrier)\n\n\n\n\nExample 1\nThe visualization below captures the total number of flights operated by each carrier each month, spanning the entire year from January to December 2013. This is an animated bar chart, evolving over time, rather than a truly ‚Äúracing‚Äù bar chart.\n\n\nCode\ngganim &lt;- df |&gt;\n  \n  # Create two new columns, 'month' and 'month_anim'\n  mutate(month = month(date, label = TRUE, abbr = FALSE),\n         month_anim = month(date)) |&gt;\n  \n  # Group the data by 'month' and 'month_anim', and count the number \n  # of flights for each 'carrier'\n  group_by(month, month_anim) |&gt;\n  count(carrier, wt = n) |&gt;\n  \n  # Calculate the rank of each 'carrier' based on the flight count\n  mutate(rank_car = rank(n)) |&gt;\n  \n  # Remove grouping information\n  ungroup() |&gt;\n  \n  # Create a ggplot object with specific aesthetics for rectangles\n  ggplot(aes(xmin = 0,\n             xmax = n,\n             y = rank_car,\n             ymin = rank_car - 0.45,\n             ymax = rank_car + 0.45,\n             fill = carrier,\n             label = round(n, 0))) +\n  \n  # Add filled rectangles with transparency\n  geom_rect(alpha = 0.5) +\n  \n  # Add text labels for flight counts\n  geom_text(aes(x = n, label = as.character(n)), hjust = \"left\") +\n  \n  # Add text labels for carriers\n  geom_text(aes(x = 0, label = carrier), hjust = \"left\") +\n  \n  # Adjust the x-axis scale limits\n  scale_x_continuous(limits = c(0, 5500)) +\n  \n  # Customize labels and titles\n  labs(x = NULL, y = NULL, title = \"Number of flights each month\") +\n  \n  # Add a label indicating the month\n  geom_label(aes(label = month), \n             x = 4500, y = 1, \n             fill = \"white\", col = \"black\",\n             size = 10, \n             label.padding = unit(0.5, \"lines\")) +\n  \n  # Apply a classic theme\n  theme_classic() +\n  \n  # Customize plot appearance\n  theme(legend.position = \"none\",\n        axis.line.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.x = element_blank(),\n        title = element_text(size = 20, hjust = 0.5)) +\n  \n  # Create multiple subplots for each month\n  facet_wrap(~month_anim) +\n  \n  # Remove facet labels: this allows us to superlay the facets on top of each other\n  # and then animate the facets\n  facet_null() + \n  \n  # Create a time-based animation based on 'month_anim'\n  transition_time(month_anim)\n\n# Animate the ggplot object with specified settings\nanimate(gganim,\n        duration = 30,\n        fps = 10,\n        width = 800,\n        height = 500,\n        start_pause = 10, \n        end_pause = 20)\n\n\n\n\n\nAnimated Horizontal Bar chart showing the total flights operated by each carrier, per month.\n\n\n\n\n\nExample 2\nThe visualization below offers a unique perspective, showcasing the cumulative total of flights operated by each carrier from January to December 2013, steadily building the story month by month. A truly ‚Äúracing‚Äù bar chart.\n\n\nCode\ndf1 &lt;- df |&gt;\n  \n  # Group the data by 'carrier'\n  group_by(carrier) |&gt;\n  \n  # Calculate the cumulative sum of 'n' within each carrier group\n  # This allows us to ahve a cumulative number of flights over time in a \n  # truly \"racing\" bar cahrt over time\n  mutate(cum_n = cumsum(n)) |&gt;\n  \n  # Remove grouping information\n  ungroup() |&gt;\n  \n  # Group the data by 'date'\n  group_by(date) |&gt;\n  \n  # Calculate the rank of 'cum_n' within each date group\n  mutate(day_rank = rank(cum_n, ties.method = \"first\"))\n\ngganim &lt;- df1 |&gt; \n  \n  # Create a ggplot object with specific aesthetics for reactangles\n  ggplot(aes(xmin = 0,\n             xmax = cum_n,\n             y = day_rank,\n             ymin = day_rank - 0.45,\n             ymax = day_rank + 0.45,\n             fill = carrier,\n             label = cum_n)) +\n  \n  # Add filled rectangles with transparency\n  geom_rect(alpha = 0.5) +\n  \n  # Add text labels for cumulative flight counts\n  geom_text(aes(x = cum_n, label = as.character(cum_n)), hjust = \"left\") +\n  \n  # Add text labels for carriers\n  geom_text(aes(x = 0, label = carrier), hjust = \"left\") +\n  \n  # Customize labels and titles. Adding {closest_state} adds the transition\n  # variable value to the plot title\n  labs(x = NULL, y = NULL, title = \"Number of total flights operated up to {closest_state}\") +\n  \n  # Apply a classic theme\n  theme_classic() +\n  \n  # Customize plot appearance\n  theme(legend.position = \"none\",\n        axis.line.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.x = element_blank(),\n        title = element_text(size = 20, hjust = 0.5)) +\n  \n  # Create multiple subplots for each date\n  facet_wrap(~ date) +\n \n   # Remove facet labels\n  facet_null() +\n  \n  # Transition the plot by 'date'\n  transition_states(date) +\n  \n  # Follow the view with a fixed x-axis\n  view_follow(fixed_x = FALSE)\n\n# Animate the ggplot object with specified settings\nanimate(gganim,\n        duration = 40,\n        fps = 6,\n        width = 800,\n        height = 500,\n        start_pause = 10, \n        end_pause = 20)\n\n\n\n\n\nCumulative Horizontal racing bar-chart depicting total flights operated by each carrier over the course of the year.\n\n\n\n\n\nExample 3\nIn the final visualiation below, we delve into the average flights‚Äô arrival delay (in minutes) for each carrier, every month, over the course of the year. What makes this data dance even more exciting is how it ranks carriers from the highest delay to the lowest delay, and as we traverse the months, watch as these rankings twirl and pirouette.\n\n\nCode\ngganim2 &lt;- flights |&gt;\n \n   # Filter the flights dataset to include only the top 9 carriers\n  filter(carrier %in% carriers_to_plot) |&gt;\n  \n  # Create new columns: 'date' by combining year, month, and day, and \n  # 'month' to represent the month as a label\n  mutate(date = make_date(year = year, month = month, day = day),\n         month = month(date, label = TRUE, abbr = FALSE)) |&gt;\n  \n  # Select specific columns for the subsequent analysis\n  select(date, month, carrier, arr_delay) |&gt;\n \n  # Group the data by 'month' and 'carrier', and calculate the average arrival delay\n  group_by(month, carrier) |&gt;\n  summarize(\n    avg_delay = mean(arr_delay, na.rm = TRUE)\n  ) |&gt;\n  \n  # Join the full names of airlines for the annotations in the animated plot\n  left_join(nycflights13::airlines, by = join_by(carrier)) |&gt;\n  \n  # Remove the 'carrier' column after joining and rename 'name' to 'carrier'\n  select(-carrier) |&gt;\n  rename(carrier = name) |&gt;\n  \n  # Calculate the rank of average delay, considering ties\n  mutate(delay_rank = rank(avg_delay, ties.method = \"first\")) |&gt;\n  \n  # Create a ggplot object with specific aesthetics for the rectangles\n  ggplot(aes(xmin = 0,\n             xmax = avg_delay,\n             y = delay_rank,\n             ymin = delay_rank - 0.45,\n             ymax = delay_rank + 0.45,\n             fill = carrier\n             )\n         ) +\n  \n  # Add filled rectangles with transparency\n  geom_rect(alpha = 0.5) +\n  \n  # Add text labels for average delay values\n  geom_text(aes(x = avg_delay, \n                label = as.character(round(avg_delay, 1))), \n            hjust = \"left\") +\n  \n  # Add text labels for carriers\n  geom_text(aes(x = 0, label = carrier), hjust = \"left\") +\n  \n  # Add a label indicating the month\n  geom_label(aes(label = month),\n             x = 4500, y = 1,\n             fill = \"white\", col = \"black\",\n             size = 10,\n             label.padding = unit(0.5, \"lines\")) +\n  \n  # Customize labels and titles\n  labs(x = NULL, y = NULL,\n       title = \"Average flight arrival delay (in minutes) during {closest_state}\") +\n  \n  # Apply a classic theme\n  theme_classic() +\n \n  # Customize plot appearance\n  theme(legend.position = \"none\",\n        axis.line.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.x = element_blank(),\n        title = element_text(size = 20, hjust = 0.5)) +\n  \n  # Create multiple subplots for each month\n  facet_wrap(~ month) +\n  \n  # Remove facet labels\n  facet_null() +\n  \n  # Transition the plot by 'month'\n  transition_states(month)\n\n# Animate the ggplot object with specified settings\nanimate(gganim2,\n        duration = 40,\n        fps = 10,\n        width = 800,\n        height = 500,\n        start_pause = 10, \n        end_pause = 20)\n\n\n\n\n\nAn animated horizontal bar chart for average flight arrival delay in each month for different airline carriers\n\n\nNotice that in some bad weather months (like June, July and December), almost every airline has considerable delays. On the contrary, if you like being on time, the best months to fly seem to be September to November."
  },
  {
    "objectID": "projects/tidy_tuesday_2023_10_10.html",
    "href": "projects/tidy_tuesday_2023_10_10.html",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "",
    "text": "Figure¬†1: Percentage of haunted locations with gender-specific terms in descriptions"
  },
  {
    "objectID": "projects/tidy_tuesday_2023_10_10.html#ghostly-jargon-in-haunted-spots-a-gendered-perspective",
    "href": "projects/tidy_tuesday_2023_10_10.html#ghostly-jargon-in-haunted-spots-a-gendered-perspective",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "text": "Ghostly Jargon in Haunted Spots: A Gendered Perspective\nFigure¬†2 illustrates the prevalence of gender-specific common words in haunted locations, comparing all American locations to haunted spots in universities and colleges.\n\n\n\n\n\nFigure¬†2: Gender-specific words‚Äô prevalence in haunted locations, comparing sites across USA with those in universities and colleges.\n\n\n\n\nCredits: Sentiment Analysis (Mohammad and Turney 2012) and code inspiration from Steven Ponce‚Äôs R script on GitHub."
  },
  {
    "objectID": "projects/tidy_tuesday_2023_10_10.html#unique-verbiage-in-these-haunted-places",
    "href": "projects/tidy_tuesday_2023_10_10.html#unique-verbiage-in-these-haunted-places",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "Unique Verbiage in these haunted places",
    "text": "Unique Verbiage in these haunted places\nIn contrast to the previous slide‚Äôs word clouds featuring overlapping terms, the Figure¬†3 shows distinct vocabulary found exclusively in male and female haunted locations.\n\n\n\n\n\nFigure¬†3: Unique words in descriptions of gender-specific haunted locations, but absent in descriptions of the opposite gender‚Äôs haunted places.\n\n\n\n\nCarefully look at All Haunted Places citing males: Who knew America‚Äôs haunted places had such a penchant for ‚Äúwife‚Äù ‚Äì even beyond the grave! Ghostly husbands, you‚Äôve got some explaining to do! üòÑüëª"
  },
  {
    "objectID": "projects/taylor_swift.html",
    "href": "projects/taylor_swift.html",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "",
    "text": "Getting the data from TidyTuesday Retrieve the data originally from the taylor R package from W. Jake Thompson is a curated data set of Taylor Swift songs, including lyrics and audio characteristics. The data comes from Genius and the Spotify API.\n\n\nCode\nlibrary(tidyverse)       # Data Wrangling and Visualization\nlibrary(visdat)          # View data in Exploratory Data Analysis\nlibrary(gganimate)       # For animation\nlibrary(transformr)      # to smoothly animate polygons and paths\n\n# Using Option 2: Read data directly from GitHub\n\ntaylor_album_songs &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_album_songs.csv')\ntaylor_all_songs &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_all_songs.csv')\ntaylor_albums &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_albums.csv')"
  },
  {
    "objectID": "projects/taylor_swift.html#creating-an-animated-plot",
    "href": "projects/taylor_swift.html#creating-an-animated-plot",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Creating an animated plot",
    "text": "Creating an animated plot\n\n# creating a loess predictor variable\ndf &lt;- taylor_all_songs |&gt; \n  select(album_name,\n         track_release,\n         danceability, \n         acousticness) |&gt; \n  drop_na()\n  \ngganim &lt;- df |&gt; \n  mutate(\n    smooth_dance = predict(loess(danceability ~ as.numeric(track_release), \n                                data = df,\n                                span = span_taylor)),\n    smooth_acous = predict(loess(acousticness ~ as.numeric(track_release), \n                                data = df,\n                                span = span_taylor))\n  ) |&gt; \n  pivot_longer(cols = starts_with(\"smooth\"),\n               names_to = \"smooth_indicator\",\n               values_to = \"value_smooth\") |&gt; \n  ggplot(aes(x = track_release)) +\n  geom_jitter(aes(y = danceability,\n                  group = seq_along(track_release)),\n              width = 20, \n              height = 0.001, \n              alpha = 0.3,\n              size = 3,\n              color = \"#54483e\") +\n  geom_jitter(aes(y = acousticness,\n                  group = seq_along(track_release)),\n              width = 20, \n              height = 0.001, \n              alpha = 0.3,\n              size = 3,\n              color = \"#b8396b\") +\n  ggtext::geom_richtext(data = taylor_albums, \n             mapping = aes(x = album_release,\n                           y = 0,\n                           label = album_name),\n             col = \"black\",\n             angle = 90, \n            hjust = \"left\",\n            alpha = 0.8) +\n  geom_line(aes(y = value_smooth,\n                col = smooth_indicator),\n            alpha = 0.7,\n            lwd = 2) +\n  theme_minimal() +\n  \n  scale_x_continuous(breaks = taylor_albums$album_release,\n                     labels = format(taylor_albums$album_release, \n                                     \"%b %Y\")) +\n  \n  # Using color palettes for package tayloRswift for her albums\n  tayloRswift::scale_color_taylor(palette = \"lover\",\n                                  labels = c(\"Acousticness\",\n                                             \"Danceability\") ) +\n  \n  labs(x = NULL,\n       y = \"Spotify App Score for songs\",\n       color = NULL, \n       title = \"Taylor Swift's songs over the years\",\n       subtitle = \"After 2015: Increased Acousticness, reduced danceability\",\n       caption = \"Data: taylor R package (W. Jake Thompson). Animation: Aditya Dahiya #TidyTuesday\") +\n  \n  theme(axis.text.x = element_text(angle = 90,\n                                   size = 10),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(), \n        legend.position = \"bottom\",\n        title = element_text(hjust = 0.5,\n                             size = 20),\n        legend.text = element_text(size = 20)) +\n\n  \n  transition_reveal(track_release) +\n  ease_aes(\"linear\") +\n  shadow_mark(past = TRUE)\n\nanimate(gganim, \n        height = 600,\n        width = 800,\n        fps = 10, \n        duration = 10,\n        start_pause = 3,\n        end_pause = 10)\n\nanim_save(\"docs/taylor_anim1.gif\")\n\n\n\n\nAn animated line chart (with scatterplot in background) of Taylor Swift‚Äôs songs‚Äô acousticness and danceability. The names of albums and release dates are on the bottom x-axis.\n\n\nFuture Plan: Creating an image for the page from AI images: Taylor Swift + R Tidyverse"
  },
  {
    "objectID": "projects/taylor_swift.html#step-3-creating-an-animated-plot",
    "href": "projects/taylor_swift.html#step-3-creating-an-animated-plot",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Step 3: Creating an animated plot",
    "text": "Step 3: Creating an animated plot\n\n\nCode\n# creating a loess predictor variable\ndf &lt;- taylor_all_songs |&gt; \n  select(album_name,\n         track_release,\n         danceability, \n         acousticness) |&gt; \n  drop_na()\n  \ngganim &lt;- df |&gt; \n  mutate(\n    smooth_dance = predict(loess(danceability ~ as.numeric(track_release), \n                                data = df,\n                                span = span_taylor)),\n    smooth_acous = predict(loess(acousticness ~ as.numeric(track_release), \n                                data = df,\n                                span = span_taylor))\n  ) |&gt; \n  pivot_longer(cols = starts_with(\"smooth\"),\n               names_to = \"smooth_indicator\",\n               values_to = \"value_smooth\") |&gt; \n  ggplot(aes(x = track_release)) +\n  geom_jitter(aes(y = danceability,\n                  group = seq_along(track_release)),\n              width = 20, \n              height = 0.001, \n              alpha = 0.3,\n              size = 3,\n              color = \"#54483e\") +\n  geom_jitter(aes(y = acousticness,\n                  group = seq_along(track_release)),\n              width = 20, \n              height = 0.001, \n              alpha = 0.3,\n              size = 3,\n              color = \"#b8396b\") +\n  ggtext::geom_richtext(data = taylor_albums, \n             mapping = aes(x = album_release,\n                           y = 0,\n                           label = album_name),\n             col = \"black\",\n             angle = 90, \n            hjust = \"left\",\n            alpha = 0.8) +\n  geom_line(aes(y = value_smooth,\n                col = smooth_indicator),\n            alpha = 0.7,\n            lwd = 2) +\n  theme_minimal() +\n  \n  scale_x_continuous(breaks = taylor_albums$album_release,\n                     labels = format(taylor_albums$album_release, \n                                     \"%b %Y\")) +\n  \n  # Using color palettes for package tayloRswift for her albums\n  tayloRswift::scale_color_taylor(palette = \"lover\",\n                                  labels = c(\"Acousticness\",\n                                             \"Danceability\") ) +\n  \n  labs(x = NULL,\n       y = \"Spotify App Score for songs\",\n       color = NULL, \n       title = \"Taylor Swift's songs over the years\",\n       subtitle = \"After 2015: Increased Acousticness, reduced danceability\",\n       caption = \"Data: taylor R package (W. Jake Thompson). Animation: Aditya Dahiya #TidyTuesday\") +\n  \n  theme(axis.text.x = element_text(angle = 90,\n                                   size = 10),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(), \n        legend.position = \"bottom\",\n        title = element_text(hjust = 0.5,\n                             size = 20),\n        legend.text = element_text(size = 20)) +\n\n  \n  transition_reveal(track_release) +\n  ease_aes(\"linear\") +\n  shadow_mark(past = TRUE)\n\nanimate(gganim, \n        height = 600,\n        width = 800,\n        fps = 10, \n        duration = 10,\n        start_pause = 3,\n        end_pause = 10)\n\nanim_save(\"docs/taylor_anim1.gif\")\n\n\n\n\n\nAn animated line chart (with scatterplot in background) of Taylor Swift‚Äôs songs‚Äô acousticness and danceability. The names of albums and release dates are on the bottom x-axis."
  },
  {
    "objectID": "street_map_art.html",
    "href": "street_map_art.html",
    "title": "Making road-maps of cities with Open Street Maps",
    "section": "",
    "text": "Here, I have tried to create a user friends single line of code fucntion to recreate street art maps using OpenStreetMaps. The inspiration is from the Github Workflow of Evgeny Politov. Credits to him for the majority of the code here, taken from his insights explained in this article on medium.com.\n\n# Code used for Chandigarh\ncty &lt;- opq(\"Chandigarh\")\n\ncty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\nvery_minor &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"footway\", \"track\", \"path\", \"tertiary_link\", \"secondary_link\", \"primary_link\", \"trunk_link\"))\n\nminor_road &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"residential\", \"tertiary\", \"secondary\"))\n\nmain_roads &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"primary\", \"trunk\"))\n\ncty_map &lt;- ggplot() +\n  geom_sf(\n    data = very_minor,\n    linewidth = 0.1,\n    alpha = 0.2\n  ) +\n  geom_sf(\n    data = minor_road,\n    linewidth = 0.3,\n    alpha = 0.5\n  ) +\n  geom_sf(\n    data = main_roads,\n    linewidth = 0.6,\n    alpha = 0.8\n  ) +\n  labs(title = \"Chandigarh\") +\ntheme_void()\n\nggsave(\"docs/cty_map.png\",\n  plot = cty_map,\n  device = \"png\",\n  width = 1800,\n  height = 1800,\n  units = \"px\"\n)\n\n\nNow, I create a function draw_street_map() to do this task and automate for other cities. If you want, simply copy paste the function, and use it for any city.\n\n# Code used for Chandigarh\n\ndraw_street_map &lt;- function(cityname, filename){\n  require(osmdata)\n  require(tidyverse)\n  require(sf)\n  \n  cty &lt;- osmdata::opq(cityname)\n  \n  cty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\n  very_minor &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"footway\", \"track\", \"path\", \n                          \"tertiary_link\", \"secondary_link\", \n                          \"primary_link\", \"trunk_link\"))\n\n  minor_road &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"residential\", \"tertiary\", \n                          \"secondary\"))\n\n  main_roads &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"primary\", \"trunk\"))\n\n  cty_map &lt;- ggplot() +\n    geom_sf(\n      data = very_minor,\n      linewidth = 0.1,\n      alpha = 0.2\n    ) +\n    geom_sf(\n      data = minor_road,\n      linewidth = 0.3,\n      alpha = 0.5\n    ) +\n    geom_sf(\n      data = main_roads,\n      linewidth = 0.6,\n      alpha = 0.8\n    ) +\n    labs(title = cityname) +\n  theme_void()\n\n  ggsave(filename,\n    plot = cty_map,\n    device = \"png\",\n    width = 1800,\n    height = 1800,\n    units = \"px\")\n  \n}\n\n\ndraw_street_map(\"Panchkula\", \"docs/panchkula.png\")\n\n\n\ndraw_street_map(\"Faridabad\", \"docs/faridabad.png\")\n\n\n\ndraw_street_map(\"Gurugram\", \"docs/gurugram.png\")\n\n\nNow, we create a Gurugram city centre map with some tweaks in the code. Can use opq() or the Open Street Maps‚Äô Export Interface here to get the latitude and longitude of any portion of any city and then just paste it here.\n\n# Code used for Chandigarh\ncty &lt;- opq(\"Gurugram\")\n\ncty$bbox &lt;- \"28.4071, 76.9881, 28.5106, 77.1051\"\n\ncty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\nvery_minor &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"footway\", \"track\", \"path\", \"tertiary_link\", \"secondary_link\", \"primary_link\", \"trunk_link\"))\n\nminor_road &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"residential\", \"tertiary\", \"secondary\"))\n\nmain_roads &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"primary\", \"trunk\"))\n\ncty_map &lt;- ggplot() +\n  geom_sf(\n    data = very_minor,\n    linewidth = 0.1,\n    alpha = 0.2\n  ) +\n  geom_sf(\n    data = minor_road,\n    linewidth = 0.3,\n    alpha = 0.5\n  ) +\n  geom_sf(\n    data = main_roads,\n    linewidth = 0.6,\n    alpha = 0.8\n  ) +\n  labs(title = \"Gurugram City (Central Area)\") +\ntheme_void()\n\nggsave(\"docs/gurugram_city_centre.png\",\n  plot = cty_map,\n  device = \"png\",\n  width = 1800,\n  height = 1800,\n  units = \"px\"\n)"
  },
  {
    "objectID": "street_map_art.html#prepare-the-query",
    "href": "street_map_art.html#prepare-the-query",
    "title": "Making artistic roadmaps of cities with Open Street Maps",
    "section": "Prepare the query",
    "text": "Prepare the query"
  },
  {
    "objectID": "street_map_art.html#pull-data",
    "href": "street_map_art.html#pull-data",
    "title": "Making artistic roadmaps of cities with Open Street Maps",
    "section": "Pull Data",
    "text": "Pull Data"
  },
  {
    "objectID": "street_map_art.html#examine-the-datasets-and-plot-samples",
    "href": "street_map_art.html#examine-the-datasets-and-plot-samples",
    "title": "Making artistic roadmaps of cities with Open Street Maps",
    "section": "Examine the datasets and plot samples",
    "text": "Examine the datasets and plot samples\nIf needed add/remove features and re-run queries"
  },
  {
    "objectID": "projects/street_map_art.html",
    "href": "projects/street_map_art.html",
    "title": "Making road-maps of cities with Open Street Maps",
    "section": "",
    "text": "Here, I have tried to create a user friends single line of code fucntion to recreate street art maps using OpenStreetMaps. The inspiration is from the Github Workflow of Evgeny Politov. Credits to him for the majority of the code here, taken from his insights explained in this article on medium.com.\n\n# Code used for Chandigarh\ncty &lt;- opq(\"Chandigarh\")\n\ncty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\nvery_minor &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"footway\", \"track\", \"path\", \"tertiary_link\", \"secondary_link\", \"primary_link\", \"trunk_link\"))\n\nminor_road &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"residential\", \"tertiary\", \"secondary\"))\n\nmain_roads &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"primary\", \"trunk\"))\n\ncty_map &lt;- ggplot() +\n  geom_sf(\n    data = very_minor,\n    linewidth = 0.1,\n    alpha = 0.2\n  ) +\n  geom_sf(\n    data = minor_road,\n    linewidth = 0.3,\n    alpha = 0.5\n  ) +\n  geom_sf(\n    data = main_roads,\n    linewidth = 0.6,\n    alpha = 0.8\n  ) +\n  labs(title = \"Chandigarh\") +\ntheme_void()\n\nggsave(\"docs/cty_map.png\",\n  plot = cty_map,\n  device = \"png\",\n  width = 1800,\n  height = 1800,\n  units = \"px\"\n)\n\n\nNow, I create a function draw_street_map() to do this task and automate for other cities. If you want, simply copy paste the function, and use it for any city.\n\n# Code used for Chandigarh\n\ndraw_street_map &lt;- function(cityname, filename){\n  require(osmdata)\n  require(tidyverse)\n  require(sf)\n  \n  cty &lt;- osmdata::opq(cityname)\n  \n  cty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\n  very_minor &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"footway\", \"track\", \"path\", \n                          \"tertiary_link\", \"secondary_link\", \n                          \"primary_link\", \"trunk_link\"))\n\n  minor_road &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"residential\", \"tertiary\", \n                          \"secondary\"))\n\n  main_roads &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"primary\", \"trunk\"))\n\n  cty_map &lt;- ggplot() +\n    geom_sf(\n      data = very_minor,\n      linewidth = 0.1,\n      alpha = 0.2\n    ) +\n    geom_sf(\n      data = minor_road,\n      linewidth = 0.3,\n      alpha = 0.5\n    ) +\n    geom_sf(\n      data = main_roads,\n      linewidth = 0.6,\n      alpha = 0.8\n    ) +\n    labs(title = cityname) +\n  theme_void()\n\n  ggsave(filename,\n    plot = cty_map,\n    device = \"png\",\n    width = 1800,\n    height = 1800,\n    units = \"px\")\n  \n}\n\n\ndraw_street_map(\"Panchkula\", \"docs/panchkula.png\")\n\n\n\ndraw_street_map(\"Faridabad\", \"docs/faridabad.png\")\n\n\n\ndraw_street_map(\"Gurugram\", \"docs/gurugram.png\")\n\n\nNow, we create a Gurugram city centre map with some tweaks in the code. Can use opq() or the Open Street Maps‚Äô Export Interface here to get the latitude and longitude of any portion of any city and then just paste it here.\n\ncty &lt;- opq(\"Gurugram\")\n\ncty$bbox &lt;- \"28.4071, 76.9881, 28.5106, 77.1051\"\n\ncty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\nvery_minor &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"footway\", \"track\", \"path\", \"tertiary_link\", \"secondary_link\", \"primary_link\", \"trunk_link\"))\n\nminor_road &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"residential\", \"tertiary\", \"secondary\"))\n\nmain_roads &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"primary\", \"trunk\"))\n\ncty_map &lt;- ggplot() +\n  geom_sf(\n    data = very_minor,\n    linewidth = 0.1,\n    alpha = 0.2\n  ) +\n  geom_sf(\n    data = minor_road,\n    linewidth = 0.3,\n    alpha = 0.5\n  ) +\n  geom_sf(\n    data = main_roads,\n    linewidth = 0.6,\n    alpha = 0.8\n  ) +\n  labs(title = \"Gurugram City (Central Area)\") +\ntheme_void()\n\nggsave(\"docs/gurugram_city_centre.png\",\n  plot = cty_map,\n  device = \"png\",\n  width = 1800,\n  height = 1800,\n  units = \"px\"\n)\n\n\nLastly, I create a simple custom function draw_custom_street_map() to provide custom coordinates and plot these maps. Feel free to use this in your workflows!\nAs an example, I create map for the NIT and Old Faridabad town area of Faridabad City.\n\n\nCode\ndraw_custom_street_map &lt;- function(cityname, filename,\n                                   latitude_min, latitude_max,\n                                   longitude_min, longitude_max){\n  require(osmdata)\n  require(tidyverse)\n  require(sf)\n  \n  cty &lt;- osmdata::opq(cityname)\n  \n  cty$bbox &lt;- paste0(latitude_min, \", \", longitude_min, \", \",\n                     latitude_max, \", \", longitude_max)\n  \n  cty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\n  very_minor &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"footway\", \"track\", \"path\", \n                          \"tertiary_link\", \"secondary_link\", \n                          \"primary_link\", \"trunk_link\"))\n\n  minor_road &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"residential\", \"tertiary\", \n                          \"secondary\"))\n\n  main_roads &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"primary\", \"trunk\"))\n\n  cty_map &lt;- ggplot() +\n    geom_sf(\n      data = very_minor,\n      linewidth = 0.1,\n      alpha = 0.2\n    ) +\n    geom_sf(\n      data = minor_road,\n      linewidth = 0.3,\n      alpha = 0.5\n    ) +\n    geom_sf(\n      data = main_roads,\n      linewidth = 0.6,\n      alpha = 0.8\n    ) +\n    labs(title = cityname) +\n  theme_void()\n\n  ggsave(filename,\n    plot = cty_map,\n    device = \"png\",\n    width = 1800,\n    height = 1800,\n    units = \"px\")\n  \n}\n\n# A box coordinates of box area of NIT and Old Faridabad towns\nlatitude_min &lt;- 28.3687\nlatitude_max &lt;- 28.4291\nlongitude_min &lt;- 77.2783\nlongitude_max &lt;- 77.3397\n\n\n\ndraw_custom_street_map(\"Faridabad\", \"faridabad.png\",\n                       latitude_min = 28.3687,\n                       latitude_max = 28.4291,\n                       longitude_min = 77.2783,\n                       longitude_max = 77.3397)\n\n\nRemember, with some basic ggplot2 knowledge, you can always change the colours and various aesthetics of these maps. An example is shown below: ‚Äì\n\n\nCode\nrequire(osmdata)\nrequire(tidyverse)\nrequire(sf)\n  \ncty &lt;- osmdata::opq(\"Faridabad\")\n  \ncty$bbox &lt;- \"28.3687, 77.2783, 28.4291, 77.3397\"\n  \ncty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\nvery_minor &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"footway\", \"track\", \"path\", \n                          \"tertiary_link\", \"secondary_link\", \n                          \"primary_link\", \"trunk_link\"))\n\nminor_road &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"residential\", \"tertiary\", \n                          \"secondary\"))\n\nmain_roads &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"primary\", \"trunk\"))\n\ncty_map &lt;- ggplot() +\n    geom_sf(\n      data = very_minor,\n      linewidth = 0.1,\n      alpha = 0.2,\n      col = \"steelblue\"\n    ) +\n    geom_sf(\n      data = minor_road,\n      linewidth = 0.3,\n      alpha = 0.5,\n      col = \"steelblue\"\n    ) +\n    geom_sf(\n      data = main_roads,\n      linewidth = 0.6,\n      alpha = 0.8,\n      col = \"#f20a1d\"\n    ) +\n    labs(title = \"Faridabad: NIT, HSVP Sectors and Old City\") +\n  theme_void() +\n  scale_y_continuous(limits = c(28.3689, 28.427))\n\nggsave(\"faridabad_col.png\",\n    plot = cty_map,\n    device = \"png\",\n    width = 1800,\n    height = 1800,\n    units = \"px\")"
  },
  {
    "objectID": "projects/taylor_swift.html#step-1-data-import",
    "href": "projects/taylor_swift.html#step-1-data-import",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "",
    "text": "Getting the data from TidyTuesday Retrieve the data originally from the taylor R package from W. Jake Thompson is a curated data set of Taylor Swift songs, including lyrics and audio characteristics. The data comes from Genius and the Spotify API.\n\n\nCode\nlibrary(tidyverse)       # Data Wrangling and Visualization\nlibrary(visdat)          # View data in Exploratory Data Analysis\nlibrary(gganimate)       # For animation\nlibrary(transformr)      # to smoothly animate polygons and paths\n\n# Using Option 2: Read data directly from GitHub\n\ntaylor_album_songs &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_album_songs.csv')\ntaylor_all_songs &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_all_songs.csv')\ntaylor_albums &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_albums.csv')"
  },
  {
    "objectID": "projects/taylor_swift.html#step-2-some-exploratory-data-analysis",
    "href": "projects/taylor_swift.html#step-2-some-exploratory-data-analysis",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Step 2: Some Exploratory Data Analysis",
    "text": "Step 2: Some Exploratory Data Analysis\n\n\nCode\n# Since all songs of Taylor Swift occur in taylor_all_songs, let us\n# focus on that data set only for now\ntaylor_album_songs |&gt; \n  anti_join(taylor_all_songs)\n\n\n# A tibble: 0 √ó 29\n# ‚Ñπ 29 variables: album_name &lt;chr&gt;, ep &lt;lgl&gt;, album_release &lt;date&gt;,\n#   track_number &lt;dbl&gt;, track_name &lt;chr&gt;, artist &lt;chr&gt;, featuring &lt;chr&gt;,\n#   bonus_track &lt;lgl&gt;, promotional_release &lt;date&gt;, single_release &lt;date&gt;,\n#   track_release &lt;date&gt;, danceability &lt;dbl&gt;, energy &lt;dbl&gt;, key &lt;dbl&gt;,\n#   loudness &lt;dbl&gt;, mode &lt;dbl&gt;, speechiness &lt;dbl&gt;, acousticness &lt;dbl&gt;,\n#   instrumentalness &lt;dbl&gt;, liveness &lt;dbl&gt;, valence &lt;dbl&gt;, tempo &lt;dbl&gt;,\n#   time_signature &lt;dbl&gt;, duration_ms &lt;dbl&gt;, explicit &lt;lgl&gt;, key_name &lt;chr&gt;, ‚Ä¶\n\n\nCode\n# Seeing the number of distinct values for each variable\ntaylor_all_songs |&gt; \n  summarise(across(.cols = everything(),\n                .fns = n_distinct)) |&gt; \n  pivot_longer(cols = everything(),\n               names_to = \"Variable\",\n               values_to = \"n_distinct\")\n\n\n# A tibble: 29 √ó 2\n   Variable            n_distinct\n   &lt;chr&gt;                    &lt;int&gt;\n 1 album_name                  15\n 2 ep                           3\n 3 album_release               15\n 4 track_number                31\n 5 track_name                 273\n 6 artist                      11\n 7 featuring                   20\n 8 bonus_track                  3\n 9 promotional_release         40\n10 single_release              62\n# ‚Ñπ 19 more rows\n\n\nUsing a popular function vis_dat() to see the structure of the data: ‚Äì\n\n\nCode\n# Vis_dat the data\ntaylor_all_songs |&gt; \n  vis_dat()\n\n\n\n\n\nAnd, seeing the change in different song characteristics over time: ‚Äì\n\n\nCode\n# We see the patterns over time for different variables of her \n# songs to see any distinct patterns\ntaylor_all_songs |&gt;\n  select(album_name, track_name, track_release,\n         danceability:duration_ms) |&gt; \n  pivot_longer(cols = -c(album_name, track_name, track_release),\n               names_to = \"indicator\",\n               values_to = \"value\") |&gt; \n  ggplot(aes(x = track_release,\n             y = value)) +\n  geom_point() +\n  geom_smooth() +\n  facet_wrap(~ indicator, scales = \"free\") +\n  theme_classic()\n\n\n\n\n\nCreating a static graph which we will animate later, and setting the span parameter for loess smoother: ‚Äì\n\n\nCode\n#define span to use\nspan_taylor = 0.75\n\n# Take the taylor_all_songs data frame and select specific columns:\ntaylor_all_songs |&gt; \n  select(album_name,\n         track_release,\n         danceability, \n         acousticness) |&gt; \n\n# Pivot the selected columns into a longer format with \"indicators\" and \"values\" columns:\n  pivot_longer(cols = -c(album_name, track_release),\n               names_to = \"indicators\",\n               values_to = \"values\") |&gt;\n\n# Create a ggplot visualization, setting aesthetics and geometries:\n  ggplot(aes(x = track_release,\n             y = values,\n             col = indicators,\n             label = indicators)) +\n\n# Add jittered points to the plot with specified width, height, and alpha:\n  geom_jitter(width = 20, \n              height = 0.001, \n              alpha = 0.2) +\n\n# Add a smoothed line to the plot with specified span, se, and alpha:\n  geom_smooth(span = span_taylor, \n              se = FALSE,\n              alpha = 0.6,\n              lwd = 1.2) +\n\n# Add text labels to the plot, referencing data from taylor_albums:\n  geom_text(data = taylor_albums, \n             mapping = aes(x = album_release,\n                           y = 0,\n                           label = album_name),\n             col = \"black\",\n             angle = 90, \n            hjust = \"left\") +\n\n# Apply a minimal theme to the plot:\n  theme_minimal() +\n\n# Customize the x-axis labels using breaks and formatted labels:\n  scale_x_continuous(breaks = taylor_albums$album_release,\n                     labels = format(taylor_albums$album_release, \n                                     \"%b %Y\")) +\n\n# Using color palettes from the tayloRswift package for Taylor Swift's albums:\n  tayloRswift::scale_color_taylor(palette = \"lover\") +\n\n# Add labels and customize the appearance of the plot:\n  labs(x = NULL,\n       y = \"Spotify App Score for songs\",\n       color = NULL) +\n\n# Further customize the appearance of the plot using theme settings:\n  theme(axis.text.x = element_text(angle = 90),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(), \n        legend.position = \"bottom\")"
  },
  {
    "objectID": "projects/taylor_swift.html#step-4-exploring-further-for-any-interesting-correlations",
    "href": "projects/taylor_swift.html#step-4-exploring-further-for-any-interesting-correlations",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Step 4: Exploring further for any interesting correlations",
    "text": "Step 4: Exploring further for any interesting correlations\n\n\nCode\nvars = c(\"danceability\", \"energy\", \"loudness\",\n         \"speechiness\", \"acousticness\", \"instrumentalness\",\n         \"valence\", \"tempo\", \"duration_ms\")\n\n# Select some variables to examine relations\ntaylor_all_songs |&gt; \n  select(all_of(vars)) |&gt; \n  GGally::ggpairs()\n\n\n\n\n\n\nLets re-focus on danceability and acoustics: ‚Äì\n\n\nCode\ntaylor_all_songs |&gt; \n  select(album_name, track_name, track_release,\n         danceability, acousticness) |&gt; \n  mutate(era = if_else(track_release &lt; ymd(\"2015-01-01\"),\n                       \"Earlier Era\",\n                       \"Recent Era\")) |&gt; \n  ggplot(aes(y = acousticness,\n             x = danceability)) +\n  geom_point(aes(group = era,\n                 col = era),\n             alpha = 0.75) +\n  geom_smooth(aes(group = era,\n                  col = era),\n              se = FALSE) +\n  theme_minimal()\n\n\n\n\n\n\n\nTrying Cluster Analysis, with some interesting results!\n\n\nCode\ntaylor1 &lt;- taylor_all_songs |&gt; \n  select(album_name, track_name, album_release,\n         danceability, acousticness, energy, loudness, \n         speechiness, instrumentalness, tempo) |&gt; \n  drop_na()\n\ntaylor_cluster &lt;- taylor1 |&gt;\n  select(danceability, acousticness) |&gt; \n  as.matrix() |&gt; \n  kmeans(x = _, centers = 2)\n\ntaylor1 |&gt; \n  mutate(cluster = as_factor(taylor_cluster$cluster)) |&gt; \n  mutate(era = if_else(album_release &lt; ymd(\"2013-01-01\"),\n                       \"Pre-2015\",\n                       \"Post-2015\")) |&gt; \n  ggplot(aes(y = acousticness,\n             x = danceability)) +\n  geom_smooth(se = F,\n              method = \"lm\",\n              col = \"grey\",\n              alpha = 0.2,\n              lwd = 2) +\n  geom_point(aes(col = cluster),\n             alpha = 0.5,\n             size = 2) +\n  facet_wrap(~ fct(era,\n                   levels = c(\"Pre-2015\", \"Post-2015\"))) +\n  theme_classic() +\n  theme(legend.position = \"bottom\") +\n  # Using color palettes for package tayloRswift\n  tayloRswift::scale_color_taylor(\n    palette = \"lover\",\n    labels = c(\"Danceability\",\n               \"Acousticness\")) +\n  labs(x = \"Danceability Score (Spotify)\",\n       y = \"Acousticness Score (Spotify)\",\n       col = \"Songs with higher: \")"
  },
  {
    "objectID": "projects/taylor_swift.html#lastly-the-animation",
    "href": "projects/taylor_swift.html#lastly-the-animation",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Lastly, the animation: ‚Äì",
    "text": "Lastly, the animation: ‚Äì\n\nlibrary(magick)\nimg &lt;- image_read(\"docs/taylor_jpeg.jpg\") |&gt; \n  image_colorize(opacity = 80,\n                 color = \"white\")\n  \nanim3 &lt;- taylor1 |&gt; \n  mutate(\n    cluster = as_factor(taylor_cluster$cluster),\n    album_name = fct_reorder(fct(album_name),\n                             .x = album_release)\n  ) |&gt; \n  ggplot(aes(y = acousticness,\n             x = danceability)) +\n  annotation_raster(img,\n                    xmin = -Inf, xmax = Inf,\n                    ymin = -Inf, ymax = Inf) +\n  geom_point(aes(col = cluster),\n             alpha = 0.9,\n             size = 4,\n             shape = 19) +\n  geom_text(aes(label = paste0(month(album_release, \n                                     label = TRUE), \n                               \", \", \n                               year(album_release)),\n                x = 0.25, y = 0.8\n                ),\n            hjust = \"left\",\n            size = 5\n            ) +\n  geom_text(aes(label = album_name,\n                x = 0.25, y = 0.95),\n            hjust = \"left\",\n            size = 8) +\n  facet_wrap(~ album_release) +\n  facet_null() +\n  scale_color_manual(values = c(\"#54483e\",\n                                \"#b8396b\"),\n                     labels = c(\"Danceability\",\n                                \"Acousticness\")) +\n  labs(x = \"Danceability Score (Spotify)\",\n       y = \"Acousticness Score (Spotify)\",\n       col = \"Songs with higher: \",\n       title = \"Acoustics and Danceability in Taylor Swift's songs\",\n       subtitle = \"Albums \\\"folklore\\\" and \\\"evermore\\\" were different from all other albums\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        plot.title.position = \"plot\",\n        title = element_text(size = 15),\n        legend.text = element_text(size = 15)) +\n  transition_states(states = album_release,\n                    transition_length = 6,\n                    state_length = 2) +\n  enter_fade() +\n  exit_fade()\n\nanimate(anim3,\n        height = 350,\n        width = 470,\n        duration = 20,\n        fps = 10,\n        end_pause = 3,\n        start_pause = 1)\n\nanim_save(\"docs/taylor_anim2.gif\")\n\n\nFuture Plan: Adding a time bar below the animated plot! I haven‚Äôt figured it out yet! If you can help, please click on Edit this Page on the right, or go here and send a pull request on GitHub. Thanks in anticipation!"
  },
  {
    "objectID": "projects/taylor_swift.html#step-5-lastly-the-second-animation",
    "href": "projects/taylor_swift.html#step-5-lastly-the-second-animation",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Step 5: Lastly, the second animation: ‚Äì",
    "text": "Step 5: Lastly, the second animation: ‚Äì\n\n\nCode\nlibrary(magick)\nimg &lt;- image_read(\"docs/taylor_jpeg.jpg\") |&gt; \n  image_colorize(opacity = 80,\n                 color = \"white\")\n  \nanim3 &lt;- taylor1 |&gt; \n  mutate(\n    cluster = as_factor(taylor_cluster$cluster),\n    album_name = fct_reorder(fct(album_name),\n                             .x = album_release)\n  ) |&gt; \n  ggplot(aes(y = acousticness,\n             x = danceability)) +\n  annotation_raster(img,\n                    xmin = -Inf, xmax = Inf,\n                    ymin = -Inf, ymax = Inf) +\n  geom_point(aes(col = cluster),\n             alpha = 0.9,\n             size = 4,\n             shape = 19) +\n  geom_text(aes(label = paste0(month(album_release, \n                                     label = TRUE), \n                               \", \", \n                               year(album_release)),\n                x = 0.25, y = 0.8\n                ),\n            hjust = \"left\",\n            size = 5\n            ) +\n  geom_text(aes(label = album_name,\n                x = 0.25, y = 0.95),\n            hjust = \"left\",\n            size = 8) +\n  facet_wrap(~ album_release) +\n  facet_null() +\n  scale_color_manual(values = c(\"#54483e\",\n                                \"#b8396b\"),\n                     labels = c(\"Danceability\",\n                                \"Acousticness\")) +\n  labs(x = \"Danceability Score (Spotify)\",\n       y = \"Acousticness Score (Spotify)\",\n       col = \"Songs with higher: \",\n       title = \"Acoustics and Danceability in Taylor Swift's songs\",\n       subtitle = \"Albums \\\"folklore\\\" and \\\"evermore\\\" were different from all other albums\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        plot.title.position = \"plot\",\n        title = element_text(size = 15),\n        legend.text = element_text(size = 15)) +\n  transition_states(states = album_release,\n                    transition_length = 6,\n                    state_length = 2) +\n  enter_fade() +\n  exit_fade()\n\nanimate(anim3,\n        height = 350,\n        width = 470,\n        duration = 20,\n        fps = 10,\n        end_pause = 3,\n        start_pause = 1)\n\nanim_save(\"docs/taylor_anim2.gif\")"
  },
  {
    "objectID": "projects/taylor_swift.html#step-6-future-plan",
    "href": "projects/taylor_swift.html#step-6-future-plan",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Step 6? Future Plan",
    "text": "Step 6? Future Plan\nAdding a time bar below the animated plot! I haven‚Äôt figured it out yet! If you can help, please click on Edit this Page on the right, or go here and send a pull request on GitHub. Thanks in anticipation!"
  },
  {
    "objectID": "patient_risk_profiles.html",
    "href": "patient_risk_profiles.html",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "In celebration of the virtual R/Pharma Conference, we delve into the fascinating realm of Patient Risk Profiles. Thanks to the dedicated work of Jenna Reps, we have at our disposal a dataset encompassing the medical history features of 100 simulated patients, along with the predicted 1-year risk of 14 distinct outcomes derived from each patient‚Äôs unique medical history.\nWith a keen eye for exploration and a flair for data visualization, we have harnessed the power of the R programming language to unveil Interesting Relations between the different ailments (outcomes) within this dataset, ultimately culminating in the creation of an interactive visualization based on a random forests model. Join us on this data-driven journey as we unlock the secrets concealed within patient risk profiles.\n\n\n\n\n\nThe data is completely numerical, and there are no missing values. So it seems good for creating statistical learning models.\n\n\nCode\npatient_risk_profiles |&gt; \n  visdat::vis_dat() +\n  theme(axis.text.x = element_text(angle = 90,\n                                   size = 4),\n        legend.position = \"bottom\")\n\n\n\n\n\nFigure¬†1: Entire dataframe with vis_dat()\n\n\n\n\nUpon exploration, it seems that the data has mainly these columns:\n\npersonID\nAge groups\nSex\nPresence / Absence of many different risk factors as binary variables\nRisk of many outcomes as decimals (between 0 and 1)\n\nLets us improve the age groups and sex columns to make them into 1 column each. This will allow us to use age as an ordinal variable; or even the mid-point age in developing models.\n\n\n\n\n\nCode\n# Assign the result of a series of data manipulation operations to the 'prf' variable.\n\nprf &lt;- patient_risk_profiles |&gt; \n\n  # Select columns: 'personId,' names starting with \"age group\" and \"Sex\"\n  # select(personId, starts_with(\"age group\"), starts_with(\"Sex\")) |&gt; \n  \n  # Reshape the data to long format for columns starting with \"age group.\"\n  pivot_longer(cols = starts_with(\"age group\"),\n               names_to = \"age_group\",\n               values_to = \"age_value\",\n               names_prefix = \"age group:  \") |&gt; \n  \n  # Filter out rows where 'age_value' is not equal to 0.\n  filter(age_value != 0) |&gt; \n  \n  # Reshape the data to long format for columns starting with \"Sex.\"\n  pivot_longer(cols = starts_with(\"Sex\"),\n               names_to = \"gender\",\n               values_to = \"sex_value\",\n               names_prefix = \"Sex = \") |&gt; \n  \n  # Filter out rows where 'sex_value' is not equal to 0.\n  filter(sex_value != 0) |&gt; \n  \n  # Select all columns except 'sex_value' and 'age_value.'\n  select(-c(sex_value, age_value)) |&gt; \n  \n  # Reorder the columns with 'age_group' and 'gender' after 'personId.'\n  relocate(age_group, gender, .after = personId)\n\n# Creating levels of the age group to make it an ordinal variable\nlevels_age &lt;- prf |&gt; \n  distinct(age_group) |&gt; \n  separate_wider_delim(cols = age_group,\n                       delim = \" -  \",\n                       names = c(\"age_lower\", NA),\n                       cols_remove = FALSE) |&gt; \n  mutate(age_lower = parse_number(age_lower)) |&gt; \n  arrange(age_lower) |&gt; \n  pull(age_group)\n\n# Adding levels of factor to age group  \nprf &lt;- prf |&gt; \n  mutate(age_group = fct(age_group, levels = levels_age))\n\n# Removing double observations for persons with sex male and female both\ngend_rm &lt;- patient_risk_profiles |&gt; \n  filter(`Sex = FEMALE` == 1 & `Sex = MALE` == 1) |&gt; \n  pull(personId)\n\nprf &lt;- prf |&gt; \n  mutate(gender = if_else(personId %in% gend_rm,\n                          \"MIXED\",\n                          gender)) |&gt; \n  filter(!duplicated(personId))\n\n\n\n\n\n\n\n\nCode\nprf |&gt; \n  ggplot(aes(y = age_group)) +\n  geom_bar() +\n  theme_minimal() +\n  labs(title = \"Distribution of age-groups in the data set shows no particular pattern\",\n       y = NULL, x = \"Number of persons in the data set\") +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nFigure¬†2: A bar chart showing distribution of age groups int he simulated data set on Patient Risk Profiles\n\n\n\n\n\n\n\n\nNow, lets focus on outcomes to visually check correlations amongst them. We can see there are total 14 different outcomes which are ‚Äúpredicted‚Äù in this data-set. An interactive heat-map using heatmaply package with a dendrogram to classify groups of outcomes: ‚Äì\n\n\nCode\ncolnames_prf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\")) |&gt; \n  colnames() |&gt;\n  as_tibble() |&gt; \n  mutate(small = str_remove(value, \"predicted risk of \"),\n         smaller = str_sub(small, start = 1, end = 20))\n\nprf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\"))\n\ncolnames(prf1) &lt;- colnames_prf1$smaller\n\nprf1 |&gt; \n  as.data.frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor()\n\n\n\n\n\n\nWe can see that there are two groups of outcomes, one in bottom-left (very strong correlations) and other small group at top-right (less stronger correlations). Lets keep that in mind as we come to it later.\nLets also try principal components analysis to see if there exist groups of outcomes within the 100 simulated patients in terms of their outcomes: ‚Äì\n\n\nCode\npc1 &lt;- prf1 |&gt; \n  as.matrix() |&gt; \n  prcomp(scale = TRUE)\n\nbiplot(pc1, scale = 0)\n\n\n\n\n\nAs we can see in the bivariate plot, the predicted conditions (in red arrows) are clustered along two directions. This, sort of, reinforces out view formed earlier from the heatmap that there are, broadly, two groups of outcomes.\n\n\n\n\nListing the predictors present in the data set: there are 64 of them !\n\n\nCode\nprf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender)) |&gt; \n  colnames() |&gt; \n  as_tibble() |&gt; \n  rename(`Variables` = value) |&gt; \n  gt::gt() |&gt; gt::opt_interactive(page_size_default = 5) |&gt; \n  gt::tab_header(title = \"List of risk factors in the data set\")\n\n\n\n\n\n\nList of risk factors in the data set\n\n\n\n\n\n\n\nAnd, the correlations between different risk factors using an interactive heat-map: ‚Äì\n\n\nCode\n# Selecting the predictors alone\nprf2 &lt;- prf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender))\n\n# Creating a tibble of their full names, small and \n# smaller names\ncolnames_prf2 &lt;- colnames(prf2) |&gt;\n  as_tibble() |&gt; \n  mutate(\n    small = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_to_title(),\n    \n    smaller = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_sub(start = 1, end = 15) |&gt; \n      str_to_title()\n  )\n\n# Easy names to display in correlation matrix\ncolnames(prf2) &lt;- colnames_prf2$smaller\n\nprf2 |&gt; \n  as_data_frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor(fontsize_row = 4,\n                           fontsize_col = 4)\n\n\n\n\n\n\nAs we can see, no specific patterns stand out amongst predictors. A few moderately positive correlations seem to be ones of disease - medicine. For example, Urinary Tract Infections are treated by Spreptogramins. Hence, both appear together.\n\n\n\n\nTrying out Variable Importance Plots and Random Forests to select best predictors\nPlanned steps\n\nFind top predictors for each outcome and also save their %IncMSE\nCombine predictor importance for each outcome into a final tibble\nCreate a stacked bar chart for all these predictors\nMake it interactive with plotly\n\n\n\n\n\nCode\n# Loading random Forest library\nlibrary(randomForest)\n\n# Setting a seed for reproducability of results\nset.seed(1)\n\n# cleaning out names of all risk factors and outcomes for easy\n# construction of formulas in for loops\nprftemp &lt;- prf |&gt;\n  clean_names()\n\n# An empty tibble to fill in the data\nrisk_factors &lt;- tibble(\n  outcome_variable = NA,\n  risk_factors = NA,\n  percentage_increase_in_MSE = NA\n)\n\n# Repeating the following loop for all outcomes\n\nfor (i in 68:81) {\n  \n  # Finding the i'th outcome variable\n  var_num = i\n  \n  # Name of the outcome - condition\n  output_var = names(prftemp)[var_num]\n  \n  # A vector of all risk factors\n  input_var = str_flatten(names(prftemp)[2:67], collapse = \" + \")\n  \n  # Creating a formula to use in Random Forest\n  modelformula = formula(paste0(output_var, \" ~ \", input_var))\n  \n  # RandomForest model created\n  model &lt;- randomForest(formula = modelformula, \n                        data = prftemp, \n                        importance = TRUE)\n  \n  # Adding risk factors and their importance to final tibbe to plot\n  risk_factors &lt;- bind_rows(\n    \n    risk_factors,\n    \n    as_tibble(\n    data.frame(risk_factors = rownames(importance(model)), \n               importance(model),\n               outcome_variable = output_var)\n    ) |&gt; \n    rename(percentage_increase_in_MSE = `X.IncMSE`) |&gt; \n    select(-IncNodePurity) |&gt; \n    relocate(outcome_variable) |&gt; \n    arrange(desc(percentage_increase_in_MSE))\n    \n  )  \n  \n}\n\n\nNow, plotting the results in a nice static ggplot2 graph: ‚Äì\n\n\nCode\n# Writing a nice caption for the plot\nplot_caption &lt;- expression(paste(\n  italic(\"#TidyTuesday\"),\n  \". Data: Simulated Patient Risk Profiles by Jenna Reps.\",\n  italic(\"Graphics: Aditya Dahiya\")))\n\nrisk_factors |&gt; \n  drop_na() |&gt; \n  mutate(\n    outcome_variable = str_remove(outcome_variable,\n                                       \"predicted_risk_of_\"),\n    outcome_variable = to_title_case(outcome_variable),\n    risk_factors = to_sentence_case(risk_factors),\n    outcome_variable = str_remove(outcome_variable, \" with\"),\n    outcome_variable = str_remove(outcome_variable, \" Trd\")\n  ) |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" No \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" or 2 Nd \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt;\n  filter(percentage_increase_in_MSE &gt; 5) |&gt; \n  group_by(outcome_variable) |&gt; \n  mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(y = reorder(outcome_variable, reorder_var),\n             x = percentage_increase_in_MSE,\n             fill = risk_factors)) +\n  geom_bar(stat = \"identity\",\n           position = position_stack(reverse = TRUE)) +\n  labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n       y = NULL,\n       title = \"Age is the most important risk factor associated with 8 out of 13 conditions\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n       caption = plot_caption,\n       fill = NULL) +\n  scale_fill_brewer(palette = \"Set3\") +\n  theme_minimal() +\n  theme(axis.line = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.grid = element_blank(),\n        plot.title.position = \"plot\",\n        legend.position = \"bottom\")\n\n\n\n\n\n\nA static graph can only show so few risk factor to avoid overcrowding. Lets look at an interactive graph now using ggplotly() (Sievert 2020) to display all the risk factors: ‚Äì\n\n\nCode\nlibrary(plotly)\n\nplotly::ggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE),\n           percentage_increase_in_MSE = round(percentage_increase_in_MSE, 1)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Age is the most important risk factor for most ailments\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\"),\n  \n  tooltip = c(\"fill\", \"x\")\n)\n\n\n\n\n\nFigure¬†3: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors in predicting the outcome ailments in the simulated Patient Risk Profiles data-set\n\n\n\n\n\n\n\nAnother better interactive visualization with higlighting feature across ailments using datawrapper.de . However, I am unable to add tool-tips to this interactive visualization: ‚Äì\n\n\n\n\n\nNow, since we know that age is such a dominant risk factor, lets remove it and see the other most important risk factor in an interactive visualization with plotly: ‚Äì\n\n\nCode\nggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    filter(risk_factors != \"Age group\") |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Role of other risk factors (removing age)\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    scale_fill_viridis_d() +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\")\n  ,\n  \n  tooltip = c(\"fill\", \"x\")\n  )\n\n\n\n\n\nFigure¬†4: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors, except age groups, in predicting the outcome ailments in the simulated Patient Risk Profiles data-set"
  },
  {
    "objectID": "patient_risk_profiles.html#interesting-relations-between-the-different-ailments-outcomes",
    "href": "patient_risk_profiles.html#interesting-relations-between-the-different-ailments-outcomes",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Now, lets focus on outcomes to visually check correlations amongst them. We can see there are total 14 different outcomes which are ‚Äúpredicted‚Äù in this data-set. An interactive heat-map using heatmaply package with a dendrogram to classify groups of outcomes: ‚Äì\n\n\nCode\ncolnames_prf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\")) |&gt; \n  colnames() |&gt;\n  as_tibble() |&gt; \n  mutate(small = str_remove(value, \"predicted risk of \"),\n         smaller = str_sub(small, start = 1, end = 20))\n\nprf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\"))\n\ncolnames(prf1) &lt;- colnames_prf1$smaller\n\nprf1 |&gt; \n  as.data.frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor()\n\n\n\n\n\n\nWe can see that there are two groups of outcomes, one in bottom-left (very strong correlations) and other small group at top-right (less stronger correlations). Lets keep that in mind as we come to it later.\nLets also try principal components analysis to see if there exist groups of outcomes within the 100 simulated patients in terms of their outcomes: ‚Äì\n\n\nCode\npc1 &lt;- prf1 |&gt; \n  as.matrix() |&gt; \n  prcomp(scale = TRUE)\n\nbiplot(pc1, scale = 0)\n\n\n\n\n\nAs we can see in the bivariate plot, the predicted conditions (in red arrows) are clustered along two directions. This, sort of, reinforces out view formed earlier from the heatmap that there are, broadly, two groups of outcomes."
  },
  {
    "objectID": "patient_risk_profiles.html#a-look-at-the-different-risk-factors",
    "href": "patient_risk_profiles.html#a-look-at-the-different-risk-factors",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Listing the predictors present in the data set: there are 64 of them !\n\n\nCode\nprf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender)) |&gt; \n  colnames() |&gt; \n  as_tibble() |&gt; \n  rename(`Variables` = value) |&gt; \n  gt::gt() |&gt; gt::opt_interactive(page_size_default = 5) |&gt; \n  gt::tab_header(title = \"List of risk factors in the data set\")\n\n\n\n\n\n\nList of risk factors in the data set\n\n\n\n\n\n\n\nAnd, the correlations between different risk factors using an interactive heat-map: ‚Äì\n\n\nCode\n# Selecting the predictors alone\nprf2 &lt;- prf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender))\n\n# Creating a tibble of their full names, small and \n# smaller names\ncolnames_prf2 &lt;- colnames(prf2) |&gt;\n  as_tibble() |&gt; \n  mutate(\n    small = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_to_title(),\n    \n    smaller = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_sub(start = 1, end = 15) |&gt; \n      str_to_title()\n  )\n\n# Easy names to display in correlation matrix\ncolnames(prf2) &lt;- colnames_prf2$smaller\n\nprf2 |&gt; \n  as_data_frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor(fontsize_row = 4,\n                           fontsize_col = 4)\n\n\n\n\n\n\nAs we can see, no specific patterns stand out amongst predictors. A few moderately positive correlations seem to be ones of disease - medicine. For example, Urinary Tract Infections are treated by Spreptogramins. Hence, both appear together."
  },
  {
    "objectID": "patient_risk_profiles.html#important-predictors-for-each-outcome",
    "href": "patient_risk_profiles.html#important-predictors-for-each-outcome",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Trying out Variable Importance Plots and Random Forests to select best predictors\nPlanned steps\n\nFind top predictors for each outcome and also save their %IncMSE\nCombine predictor importance for each outcome into a final tibble\nCreate a stacked bar chart for all these predictors\nMake it interactive with plotly\n\n\n\n\n\nCode\n# Loading random Forest library\nlibrary(randomForest)\n\n# Setting a seed for reproducability of results\nset.seed(1)\n\n# cleaning out names of all risk factors and outcomes for easy\n# construction of formulas in for loops\nprftemp &lt;- prf |&gt;\n  clean_names()\n\n# An empty tibble to fill in the data\nrisk_factors &lt;- tibble(\n  outcome_variable = NA,\n  risk_factors = NA,\n  percentage_increase_in_MSE = NA\n)\n\n# Repeating the following loop for all outcomes\n\nfor (i in 68:81) {\n  \n  # Finding the i'th outcome variable\n  var_num = i\n  \n  # Name of the outcome - condition\n  output_var = names(prftemp)[var_num]\n  \n  # A vector of all risk factors\n  input_var = str_flatten(names(prftemp)[2:67], collapse = \" + \")\n  \n  # Creating a formula to use in Random Forest\n  modelformula = formula(paste0(output_var, \" ~ \", input_var))\n  \n  # RandomForest model created\n  model &lt;- randomForest(formula = modelformula, \n                        data = prftemp, \n                        importance = TRUE)\n  \n  # Adding risk factors and their importance to final tibbe to plot\n  risk_factors &lt;- bind_rows(\n    \n    risk_factors,\n    \n    as_tibble(\n    data.frame(risk_factors = rownames(importance(model)), \n               importance(model),\n               outcome_variable = output_var)\n    ) |&gt; \n    rename(percentage_increase_in_MSE = `X.IncMSE`) |&gt; \n    select(-IncNodePurity) |&gt; \n    relocate(outcome_variable) |&gt; \n    arrange(desc(percentage_increase_in_MSE))\n    \n  )  \n  \n}\n\n\nNow, plotting the results in a nice static ggplot2 graph: ‚Äì\n\n\nCode\n# Writing a nice caption for the plot\nplot_caption &lt;- expression(paste(\n  italic(\"#TidyTuesday\"),\n  \". Data: Simulated Patient Risk Profiles by Jenna Reps.\",\n  italic(\"Graphics: Aditya Dahiya\")))\n\nrisk_factors |&gt; \n  drop_na() |&gt; \n  mutate(\n    outcome_variable = str_remove(outcome_variable,\n                                       \"predicted_risk_of_\"),\n    outcome_variable = to_title_case(outcome_variable),\n    risk_factors = to_sentence_case(risk_factors),\n    outcome_variable = str_remove(outcome_variable, \" with\"),\n    outcome_variable = str_remove(outcome_variable, \" Trd\")\n  ) |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" No \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" or 2 Nd \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt;\n  filter(percentage_increase_in_MSE &gt; 5) |&gt; \n  group_by(outcome_variable) |&gt; \n  mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(y = reorder(outcome_variable, reorder_var),\n             x = percentage_increase_in_MSE,\n             fill = risk_factors)) +\n  geom_bar(stat = \"identity\",\n           position = position_stack(reverse = TRUE)) +\n  labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n       y = NULL,\n       title = \"Age is the most important risk factor associated with 8 out of 13 conditions\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n       caption = plot_caption,\n       fill = NULL) +\n  scale_fill_brewer(palette = \"Set3\") +\n  theme_minimal() +\n  theme(axis.line = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.grid = element_blank(),\n        plot.title.position = \"plot\",\n        legend.position = \"bottom\")\n\n\n\n\n\n\nA static graph can only show so few risk factor to avoid overcrowding. Lets look at an interactive graph now using ggplotly() (Sievert 2020) to display all the risk factors: ‚Äì\n\n\nCode\nlibrary(plotly)\n\nplotly::ggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE),\n           percentage_increase_in_MSE = round(percentage_increase_in_MSE, 1)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Age is the most important risk factor for most ailments\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\"),\n  \n  tooltip = c(\"fill\", \"x\")\n)\n\n\n\n\n\nFigure¬†3: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors in predicting the outcome ailments in the simulated Patient Risk Profiles data-set\n\n\n\n\n\n\n\nAnother better interactive visualization with higlighting feature across ailments using datawrapper.de . However, I am unable to add tool-tips to this interactive visualization: ‚Äì\n\n\n\n\n\nNow, since we know that age is such a dominant risk factor, lets remove it and see the other most important risk factor in an interactive visualization with plotly: ‚Äì\n\n\nCode\nggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    filter(risk_factors != \"Age group\") |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Role of other risk factors (removing age)\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    scale_fill_viridis_d() +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\")\n  ,\n  \n  tooltip = c(\"fill\", \"x\")\n  )\n\n\n\n\n\nFigure¬†4: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors, except age groups, in predicting the outcome ailments in the simulated Patient Risk Profiles data-set"
  },
  {
    "objectID": "projects/patient_risk_profiles.html",
    "href": "projects/patient_risk_profiles.html",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "In celebration of the virtual R/Pharma Conference, we delve into the fascinating realm of Patient Risk Profiles. Thanks to the dedicated work of Jenna Reps, we have at our disposal a dataset encompassing the medical history features of 100 simulated patients, along with the predicted 1-year risk of 14 distinct outcomes derived from each patient‚Äôs unique medical history.\nWith a keen eye for exploration and a flair for data visualization, we have harnessed the power of the R programming language to unveil Interesting Relations between the different ailments (outcomes) within this dataset, ultimately culminating in the creation of an interactive visualization based on a random forests model. Join us on this data-driven journey as we unlock the secrets concealed within patient risk profiles.\n\n\n\n\n\nThe data is completely numerical, and there are no missing values. So it seems good for creating statistical learning models.\n\n\nCode\npatient_risk_profiles |&gt; \n  visdat::vis_dat() +\n  theme(axis.text.x = element_text(angle = 90,\n                                   size = 4),\n        legend.position = \"bottom\")\n\n\n\n\n\nFigure¬†1: Entire dataframe with vis_dat()\n\n\n\n\nUpon exploration, it seems that the data has mainly these columns:\n\npersonID\nAge groups\nSex\nPresence / Absence of many different risk factors as binary variables\nRisk of many outcomes as decimals (between 0 and 1)\n\nLets us improve the age groups and sex columns to make them into 1 column each. This will allow us to use age as an ordinal variable; or even the mid-point age in developing models.\n\n\n\n\n\nCode\n# Assign the result of a series of data manipulation operations to the 'prf' variable.\n\nprf &lt;- patient_risk_profiles |&gt; \n\n  # Select columns: 'personId,' names starting with \"age group\" and \"Sex\"\n  # select(personId, starts_with(\"age group\"), starts_with(\"Sex\")) |&gt; \n  \n  # Reshape the data to long format for columns starting with \"age group.\"\n  pivot_longer(cols = starts_with(\"age group\"),\n               names_to = \"age_group\",\n               values_to = \"age_value\",\n               names_prefix = \"age group:  \") |&gt; \n  \n  # Filter out rows where 'age_value' is not equal to 0.\n  filter(age_value != 0) |&gt; \n  \n  # Reshape the data to long format for columns starting with \"Sex.\"\n  pivot_longer(cols = starts_with(\"Sex\"),\n               names_to = \"gender\",\n               values_to = \"sex_value\",\n               names_prefix = \"Sex = \") |&gt; \n  \n  # Filter out rows where 'sex_value' is not equal to 0.\n  filter(sex_value != 0) |&gt; \n  \n  # Select all columns except 'sex_value' and 'age_value.'\n  select(-c(sex_value, age_value)) |&gt; \n  \n  # Reorder the columns with 'age_group' and 'gender' after 'personId.'\n  relocate(age_group, gender, .after = personId)\n\n# Creating levels of the age group to make it an ordinal variable\nlevels_age &lt;- prf |&gt; \n  distinct(age_group) |&gt; \n  separate_wider_delim(cols = age_group,\n                       delim = \" -  \",\n                       names = c(\"age_lower\", NA),\n                       cols_remove = FALSE) |&gt; \n  mutate(age_lower = parse_number(age_lower)) |&gt; \n  arrange(age_lower) |&gt; \n  pull(age_group)\n\n# Adding levels of factor to age group  \nprf &lt;- prf |&gt; \n  mutate(age_group = fct(age_group, levels = levels_age))\n\n# Removing double observations for persons with sex male and female both\ngend_rm &lt;- patient_risk_profiles |&gt; \n  filter(`Sex = FEMALE` == 1 & `Sex = MALE` == 1) |&gt; \n  pull(personId)\n\nprf &lt;- prf |&gt; \n  mutate(gender = if_else(personId %in% gend_rm,\n                          \"MIXED\",\n                          gender)) |&gt; \n  filter(!duplicated(personId))\n\n\n\n\n\n\n\n\nCode\nprf |&gt; \n  ggplot(aes(y = age_group)) +\n  geom_bar() +\n  theme_minimal() +\n  labs(title = \"Distribution of age-groups in the data set shows no particular pattern\",\n       y = NULL, x = \"Number of persons in the data set\") +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nFigure¬†2: A bar chart showing distribution of age groups int he simulated data set on Patient Risk Profiles\n\n\n\n\n\n\n\n\nNow, lets focus on outcomes to visually check correlations amongst them. We can see there are total 14 different outcomes which are ‚Äúpredicted‚Äù in this data-set. An interactive heat-map using heatmaply package with a dendrogram to classify groups of outcomes: ‚Äì\n\n\nCode\ncolnames_prf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\")) |&gt; \n  colnames() |&gt;\n  as_tibble() |&gt; \n  mutate(small = str_remove(value, \"predicted risk of \"),\n         smaller = str_sub(small, start = 1, end = 20))\n\nprf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\"))\n\ncolnames(prf1) &lt;- colnames_prf1$smaller\n\nprf1 |&gt; \n  as.data.frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor()\n\n\n\n\n\n\nWe can see that there are two groups of outcomes, one in bottom-left (very strong correlations) and other small group at top-right (less stronger correlations). Lets keep that in mind as we come to it later.\nLets also try principal components analysis to see if there exist groups of outcomes within the 100 simulated patients in terms of their outcomes: ‚Äì\n\n\nCode\npc1 &lt;- prf1 |&gt; \n  as.matrix() |&gt; \n  prcomp(scale = TRUE)\n\nbiplot(pc1, scale = 0)\n\n\n\n\n\nAs we can see in the bivariate plot, the predicted conditions (in red arrows) are clustered along two directions. This, sort of, reinforces out view formed earlier from the heatmap that there are, broadly, two groups of outcomes.\n\n\n\n\nListing the predictors present in the data set: there are 64 of them !\n\n\nCode\nprf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender)) |&gt; \n  colnames() |&gt; \n  as_tibble() |&gt; \n  rename(`Variables` = value) |&gt; \n  gt::gt() |&gt; gt::opt_interactive(page_size_default = 5) |&gt; \n  gt::tab_header(title = \"List of risk factors in the data set\")\n\n\n\n\n\n\nList of risk factors in the data set\n\n\n\n\n\n\n\nAnd, the correlations between different risk factors using an interactive heat-map: ‚Äì\n\n\nCode\n# Selecting the predictors alone\nprf2 &lt;- prf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender))\n\n# Creating a tibble of their full names, small and \n# smaller names\ncolnames_prf2 &lt;- colnames(prf2) |&gt;\n  as_tibble() |&gt; \n  mutate(\n    small = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_to_title(),\n    \n    smaller = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_sub(start = 1, end = 15) |&gt; \n      str_to_title()\n  )\n\n# Easy names to display in correlation matrix\ncolnames(prf2) &lt;- colnames_prf2$smaller\n\nprf2 |&gt; \n  as_data_frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor(fontsize_row = 4,\n                           fontsize_col = 4)\n\n\n\n\n\n\nAs we can see, no specific patterns stand out amongst predictors. A few moderately positive correlations seem to be ones of disease - medicine. For example, Urinary Tract Infections are treated by Spreptogramins. Hence, both appear together.\n\n\n\n\nTrying out Variable Importance Plots and Random Forests to select best predictors\nPlanned steps\n\nFind top predictors for each outcome and also save their %IncMSE\nCombine predictor importance for each outcome into a final tibble\nCreate a stacked bar chart for all these predictors\nMake it interactive with plotly\n\n\n\n\n\nCode\n# Loading random Forest library\nlibrary(randomForest)\n\n# Setting a seed for reproducability of results\nset.seed(1)\n\n# cleaning out names of all risk factors and outcomes for easy\n# construction of formulas in for loops\nprftemp &lt;- prf |&gt;\n  clean_names()\n\n# An empty tibble to fill in the data\nrisk_factors &lt;- tibble(\n  outcome_variable = NA,\n  risk_factors = NA,\n  percentage_increase_in_MSE = NA\n)\n\n# Repeating the following loop for all outcomes\n\nfor (i in 68:81) {\n  \n  # Finding the i'th outcome variable\n  var_num = i\n  \n  # Name of the outcome - condition\n  output_var = names(prftemp)[var_num]\n  \n  # A vector of all risk factors\n  input_var = str_flatten(names(prftemp)[2:67], collapse = \" + \")\n  \n  # Creating a formula to use in Random Forest\n  modelformula = formula(paste0(output_var, \" ~ \", input_var))\n  \n  # RandomForest model created\n  model &lt;- randomForest(formula = modelformula, \n                        data = prftemp, \n                        importance = TRUE)\n  \n  # Adding risk factors and their importance to final tibbe to plot\n  risk_factors &lt;- bind_rows(\n    \n    risk_factors,\n    \n    as_tibble(\n    data.frame(risk_factors = rownames(importance(model)), \n               importance(model),\n               outcome_variable = output_var)\n    ) |&gt; \n    rename(percentage_increase_in_MSE = `X.IncMSE`) |&gt; \n    select(-IncNodePurity) |&gt; \n    relocate(outcome_variable) |&gt; \n    arrange(desc(percentage_increase_in_MSE))\n    \n  )  \n  \n}\n\n\nNow, plotting the results in a nice static ggplot2 graph: ‚Äì\n\n\nCode\n# Writing a nice caption for the plot\nplot_caption &lt;- expression(paste(\n  italic(\"#TidyTuesday\"),\n  \". Data: Simulated Patient Risk Profiles by Jenna Reps.\",\n  italic(\"Graphics: Aditya Dahiya\")))\n\nrisk_factors |&gt; \n  drop_na() |&gt; \n  mutate(\n    outcome_variable = str_remove(outcome_variable,\n                                       \"predicted_risk_of_\"),\n    outcome_variable = to_title_case(outcome_variable),\n    risk_factors = to_sentence_case(risk_factors),\n    outcome_variable = str_remove(outcome_variable, \" with\"),\n    outcome_variable = str_remove(outcome_variable, \" Trd\")\n  ) |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" No \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" or 2 Nd \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt;\n  filter(percentage_increase_in_MSE &gt; 5) |&gt; \n  group_by(outcome_variable) |&gt; \n  mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(y = reorder(outcome_variable, reorder_var),\n             x = percentage_increase_in_MSE,\n             fill = risk_factors)) +\n  geom_bar(stat = \"identity\",\n           position = position_stack(reverse = TRUE)) +\n  labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n       y = NULL,\n       title = \"Age is the most important risk factor associated with 8 out of 13 conditions\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n       caption = plot_caption,\n       fill = NULL) +\n  scale_fill_brewer(palette = \"Set3\") +\n  theme_minimal() +\n  theme(axis.line = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.grid = element_blank(),\n        plot.title.position = \"plot\",\n        legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nA static graph can only show so few risk factor to avoid overcrowding. Lets look at an interactive graph now using ggplotly() to display all the risk factors: ‚Äì\n\n\nCode\nlibrary(plotly)\n\nplotly::ggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE),\n           percentage_increase_in_MSE = round(percentage_increase_in_MSE, 1)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Age is the most important risk factor for most ailments\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\"),\n  \n  tooltip = c(\"fill\", \"x\")\n)\n\n\n\n\n\nFigure¬†3: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors in predicting the outcome ailments in the simulated Patient Risk Profiles data-set\n\n\n\n\n\n\nTrying to create and embed an interactive visualization from observable, with data wrangling in R: ‚Äì\n\n\n\n\n\nAnother better interactive visualization with highlighting feature across ailments using datawrapper.de . However, I am unable to add tool-tips to this interactive visualization: ‚Äì\n\n\n\n\n\nNow, since we know that age is such a dominant risk factor, lets remove it and see the other most important risk factor in an interactive visualization with plotly: ‚Äì\n\n\nCode\nggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    filter(risk_factors != \"Age group\") |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Role of other risk factors (removing age)\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    scale_fill_viridis_d() +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\")\n  ,\n  \n  tooltip = c(\"fill\", \"x\")\n  )\n\n\n\n\n\nFigure¬†4: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors, except age groups, in predicting the outcome ailments in the simulated Patient Risk Profiles data-set"
  },
  {
    "objectID": "projects/patient_risk_profiles.html#interesting-relations-between-the-different-ailments-outcomes",
    "href": "projects/patient_risk_profiles.html#interesting-relations-between-the-different-ailments-outcomes",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Now, lets focus on outcomes to visually check correlations amongst them. We can see there are total 14 different outcomes which are ‚Äúpredicted‚Äù in this data-set. An interactive heat-map using heatmaply package with a dendrogram to classify groups of outcomes: ‚Äì\n\n\nCode\ncolnames_prf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\")) |&gt; \n  colnames() |&gt;\n  as_tibble() |&gt; \n  mutate(small = str_remove(value, \"predicted risk of \"),\n         smaller = str_sub(small, start = 1, end = 20))\n\nprf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\"))\n\ncolnames(prf1) &lt;- colnames_prf1$smaller\n\nprf1 |&gt; \n  as.data.frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor()\n\n\n\n\n\n\nWe can see that there are two groups of outcomes, one in bottom-left (very strong correlations) and other small group at top-right (less stronger correlations). Lets keep that in mind as we come to it later.\nLets also try principal components analysis to see if there exist groups of outcomes within the 100 simulated patients in terms of their outcomes: ‚Äì\n\n\nCode\npc1 &lt;- prf1 |&gt; \n  as.matrix() |&gt; \n  prcomp(scale = TRUE)\n\nbiplot(pc1, scale = 0)\n\n\n\n\n\nAs we can see in the bivariate plot, the predicted conditions (in red arrows) are clustered along two directions. This, sort of, reinforces out view formed earlier from the heatmap that there are, broadly, two groups of outcomes."
  },
  {
    "objectID": "projects/patient_risk_profiles.html#a-look-at-the-different-risk-factors",
    "href": "projects/patient_risk_profiles.html#a-look-at-the-different-risk-factors",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Listing the predictors present in the data set: there are 64 of them !\n\n\nCode\nprf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender)) |&gt; \n  colnames() |&gt; \n  as_tibble() |&gt; \n  rename(`Variables` = value) |&gt; \n  gt::gt() |&gt; gt::opt_interactive(page_size_default = 5) |&gt; \n  gt::tab_header(title = \"List of risk factors in the data set\")\n\n\n\n\n\n\nList of risk factors in the data set\n\n\n\n\n\n\n\nAnd, the correlations between different risk factors using an interactive heat-map: ‚Äì\n\n\nCode\n# Selecting the predictors alone\nprf2 &lt;- prf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender))\n\n# Creating a tibble of their full names, small and \n# smaller names\ncolnames_prf2 &lt;- colnames(prf2) |&gt;\n  as_tibble() |&gt; \n  mutate(\n    small = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_to_title(),\n    \n    smaller = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_sub(start = 1, end = 15) |&gt; \n      str_to_title()\n  )\n\n# Easy names to display in correlation matrix\ncolnames(prf2) &lt;- colnames_prf2$smaller\n\nprf2 |&gt; \n  as_data_frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor(fontsize_row = 4,\n                           fontsize_col = 4)\n\n\n\n\n\n\nAs we can see, no specific patterns stand out amongst predictors. A few moderately positive correlations seem to be ones of disease - medicine. For example, Urinary Tract Infections are treated by Spreptogramins. Hence, both appear together."
  },
  {
    "objectID": "projects/patient_risk_profiles.html#important-predictors-for-each-outcome",
    "href": "projects/patient_risk_profiles.html#important-predictors-for-each-outcome",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Trying out Variable Importance Plots and Random Forests to select best predictors\nPlanned steps\n\nFind top predictors for each outcome and also save their %IncMSE\nCombine predictor importance for each outcome into a final tibble\nCreate a stacked bar chart for all these predictors\nMake it interactive with plotly\n\n\n\n\n\nCode\n# Loading random Forest library\nlibrary(randomForest)\n\n# Setting a seed for reproducability of results\nset.seed(1)\n\n# cleaning out names of all risk factors and outcomes for easy\n# construction of formulas in for loops\nprftemp &lt;- prf |&gt;\n  clean_names()\n\n# An empty tibble to fill in the data\nrisk_factors &lt;- tibble(\n  outcome_variable = NA,\n  risk_factors = NA,\n  percentage_increase_in_MSE = NA\n)\n\n# Repeating the following loop for all outcomes\n\nfor (i in 68:81) {\n  \n  # Finding the i'th outcome variable\n  var_num = i\n  \n  # Name of the outcome - condition\n  output_var = names(prftemp)[var_num]\n  \n  # A vector of all risk factors\n  input_var = str_flatten(names(prftemp)[2:67], collapse = \" + \")\n  \n  # Creating a formula to use in Random Forest\n  modelformula = formula(paste0(output_var, \" ~ \", input_var))\n  \n  # RandomForest model created\n  model &lt;- randomForest(formula = modelformula, \n                        data = prftemp, \n                        importance = TRUE)\n  \n  # Adding risk factors and their importance to final tibbe to plot\n  risk_factors &lt;- bind_rows(\n    \n    risk_factors,\n    \n    as_tibble(\n    data.frame(risk_factors = rownames(importance(model)), \n               importance(model),\n               outcome_variable = output_var)\n    ) |&gt; \n    rename(percentage_increase_in_MSE = `X.IncMSE`) |&gt; \n    select(-IncNodePurity) |&gt; \n    relocate(outcome_variable) |&gt; \n    arrange(desc(percentage_increase_in_MSE))\n    \n  )  \n  \n}\n\n\nNow, plotting the results in a nice static ggplot2 graph: ‚Äì\n\n\nCode\n# Writing a nice caption for the plot\nplot_caption &lt;- expression(paste(\n  italic(\"#TidyTuesday\"),\n  \". Data: Simulated Patient Risk Profiles by Jenna Reps.\",\n  italic(\"Graphics: Aditya Dahiya\")))\n\nrisk_factors |&gt; \n  drop_na() |&gt; \n  mutate(\n    outcome_variable = str_remove(outcome_variable,\n                                       \"predicted_risk_of_\"),\n    outcome_variable = to_title_case(outcome_variable),\n    risk_factors = to_sentence_case(risk_factors),\n    outcome_variable = str_remove(outcome_variable, \" with\"),\n    outcome_variable = str_remove(outcome_variable, \" Trd\")\n  ) |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" No \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" or 2 Nd \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt;\n  filter(percentage_increase_in_MSE &gt; 5) |&gt; \n  group_by(outcome_variable) |&gt; \n  mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(y = reorder(outcome_variable, reorder_var),\n             x = percentage_increase_in_MSE,\n             fill = risk_factors)) +\n  geom_bar(stat = \"identity\",\n           position = position_stack(reverse = TRUE)) +\n  labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n       y = NULL,\n       title = \"Age is the most important risk factor associated with 8 out of 13 conditions\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n       caption = plot_caption,\n       fill = NULL) +\n  scale_fill_brewer(palette = \"Set3\") +\n  theme_minimal() +\n  theme(axis.line = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.grid = element_blank(),\n        plot.title.position = \"plot\",\n        legend.position = \"bottom\")"
  },
  {
    "objectID": "projects/patient_risk_profiles.html#interactive-visualization",
    "href": "projects/patient_risk_profiles.html#interactive-visualization",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "A static graph can only show so few risk factor to avoid overcrowding. Lets look at an interactive graph now using ggplotly() to display all the risk factors: ‚Äì\n\n\nCode\nlibrary(plotly)\n\nplotly::ggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE),\n           percentage_increase_in_MSE = round(percentage_increase_in_MSE, 1)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Age is the most important risk factor for most ailments\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\"),\n  \n  tooltip = c(\"fill\", \"x\")\n)\n\n\n\n\n\nFigure¬†3: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors in predicting the outcome ailments in the simulated Patient Risk Profiles data-set\n\n\n\n\n\n\nTrying to create and embed an interactive visualization from observable, with data wrangling in R: ‚Äì\n\n\n\n\n\nAnother better interactive visualization with highlighting feature across ailments using datawrapper.de . However, I am unable to add tool-tips to this interactive visualization: ‚Äì\n\n\n\n\n\nNow, since we know that age is such a dominant risk factor, lets remove it and see the other most important risk factor in an interactive visualization with plotly: ‚Äì\n\n\nCode\nggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    filter(risk_factors != \"Age group\") |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Role of other risk factors (removing age)\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    scale_fill_viridis_d() +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\")\n  ,\n  \n  tooltip = c(\"fill\", \"x\")\n  )\n\n\n\n\n\nFigure¬†4: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors, except age groups, in predicting the outcome ailments in the simulated Patient Risk Profiles data-set"
  },
  {
    "objectID": "projects/horror_legends.html",
    "href": "projects/horror_legends.html",
    "title": "Eerie Revelations: Text Analysis of Snopes.com‚Äôs Horror Legends",
    "section": "",
    "text": "‚ÄôTis the season of spookiness, and in the spirit of #TidyTuesday, we delve into the cryptic world of snopes.com, a realm filled with explaining (and debunking false) horror legends and mysterious tales. Snopes, once known as the Urban Legends Reference Pages, is no ordinary fact-checking website. It has been whispered about as a ‚Äúwell-regarded reference for sorting out myths and rumors‚Äù on the vast, dark Internet.\nBack in 1994, a time when shadows concealed secrets and the internet was a nascent entity, David Mikkelson and Barbara Mikkelson summoned forth an urban folklore web site, which would later evolve into the enigmatic Snopes.com. In this analysis, we shall peer into the texts of over 200 articles that dwell on snopes.com, deciphering how their content has evolved over the ages. Furthermore, we will unearth the themes crafted by different authors, distinguishing the works of David and Barbara Mikkelson from the rest of the snopes staff.\nPrepare yourself, for we shall conjure data tricks, harnessing arcane knowledge from the tome known as Text Mining with R by Julia Silge and David Robinson. Let the haunting analysis begin!"
  },
  {
    "objectID": "projects/horror_legends.html#loading-libraries-and-data",
    "href": "projects/horror_legends.html#loading-libraries-and-data",
    "title": "#TidyTuesday Week 44: Horror Legends",
    "section": "",
    "text": "Code\n# Loading libraries\nlibrary(tidyverse)      # for everything tidy manipulation and plot\nlibrary(gt)             # for nice tables\nlibrary(visdat)         # for visualizing data\nlibrary(tidytext)       # Text Evaluation\nlibrary(rvest)          # Web-scraping for complete articles\n\n# Read data directly from GitHub\n# horror_articles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-31/horror_articles.csv')\n\n# Using harvested data - to include complete text of all articles\nhorror_articles &lt;- read_csv(\"horror_legends.csv\")\n\nvis_dat(horror_articles)\n\n\n\n\n\nAlternate: Cleaning Script from #TidyTuesday webpage\n\n\nCode\nlibrary(tidyverse)\nlibrary(here)\nlibrary(fs)\nlibrary(rvest)\n\nworking_dir &lt;- here::here(\"data\", \"2023\", \"2023-10-31\")\n\nurls &lt;- paste0(\n  \"https://www.snopes.com/fact-check/category/horrors/?pagenum=\",\n  1:15\n)\n\nextract_rating &lt;- function(article_page) {\n  rating &lt;- article_page |&gt; \n    rvest::html_element(\".rating_title_wrap\") |&gt; \n    rvest::html_text2() |&gt; \n    stringr::str_remove(\"About this rating\")\n  if (is.na(rating)) {\n    rating &lt;- article_page |&gt; \n      rvest::html_element(\".status_color\") |&gt; \n      rvest::html_text2()\n  }\n  if (is.na(rating)) {\n    rating &lt;- article_page |&gt; \n      rvest::html_elements(\"noindex\") |&gt; \n      rvest::html_text2() |&gt; \n      stringr::str_squish() |&gt; \n      stringr::str_subset(\"^Status:\") |&gt; \n      stringr::str_remove(\"Status:\")\n  }\n  rating &lt;- tolower(rating) |&gt; \n    stringr::str_squish() |&gt; \n    stringr::str_remove(\"\\\\.|\\\\:\")\n  rating &lt;- dplyr::case_match(\n    rating,\n    c(\n      \"a number of real entries, one unknown, and one fiction\",\n      \"multiple\",\n      \"multiple ‚Äî see below\",\n      \"two real entries, the others are fiction\"\n    ) ~ \"mixture\",\n    .default = rating\n  )\n  return(rating)\n}\n\nextract_claim &lt;- function(article_page) {\n  claim &lt;- article_page |&gt; \n    rvest::html_element(\".claim_cont\") |&gt; \n    rvest::html_text2() |&gt; \n    stringr::str_squish()\n  if (is.na(claim)) {\n    claim &lt;- rvest::html_elements(article_page, \"p\") |&gt; \n      rvest::html_text2() |&gt; \n      stringr::str_subset(\"^Claim:\") |&gt; \n      stringr::str_remove(\"Claim:\") |&gt; \n      stringr::str_squish()\n  }\n  return(claim)\n}\n\nhorror_articles &lt;- urls |&gt;\n  purrr::map(\n    \\(article_list_url) {\n      article_list_url |&gt; \n        rvest::read_html() |&gt; \n        rvest::html_elements(\".article_wrapper\") |&gt; \n        purrr::map(\n          \\(article) {\n            # Grabbbing info from this page can result in truncation. Instead grab the\n            # URL and dig into that.\n            url &lt;- article |&gt;\n              rvest::html_element(\"a\") |&gt;\n              rvest::html_attr(\"href\")\n            article_page &lt;- rvest::read_html(url)\n            tibble::tibble(\n              title = article_page |&gt;\n                rvest::html_element(\"h1\") |&gt; \n                rvest::html_text2(),\n              url = url,\n              # Failed for some articles &lt;= 2015-05-16\n              rating = extract_rating(article_page),\n              subtitle = article_page |&gt;\n                rvest::html_element(\"h2\") |&gt; \n                rvest::html_text2(),\n              author = article_page |&gt; \n                rvest::html_element(\".author_name\") |&gt; \n                rvest::html_text() |&gt; \n                stringr::str_squish(),\n              published = article |&gt; \n                rvest::html_element(\".article_date\") |&gt; \n                rvest::html_text2() |&gt; \n                lubridate::mdy(),\n              # Failed for some articles &lt;= 2015-05-16\n              claim = extract_claim(article_page)\n            )\n          }\n        ) |&gt; \n        purrr::list_rbind()\n    }\n  ) |&gt; \n  purrr::list_rbind()\n\nreadr::write_csv(\n  horror_articles,\n  fs::path(working_dir, \"horror_articles.csv\")\n)\n\n\n\n\nTwo authors dominate the articles‚Äô authorship\n\n\nCode\nhorror_articles |&gt; \n  count(author, sort = TRUE)\n\n\n# A tibble: 13 √ó 2\n   author                n\n   &lt;chr&gt;             &lt;int&gt;\n 1 Barbara Mikkelson  1440\n 2 David Mikkelson     611\n 3 Snopes Staff         98\n 4 Kim LaCapria         40\n 5 Brooke Binkowski     26\n 6 David Emery          23\n 7 Dan Evon             22\n 8 Dan MacGuill         22\n 9 Bethania Palma       21\n10 Jordan Liles         13\n11 Arturo Garcia        12\n12 Alex Kasprak          7\n13 Madison Dapcevich     2"
  },
  {
    "objectID": "projects/horror_legends.html#other-ideas",
    "href": "projects/horror_legends.html#other-ideas",
    "title": "#TidyTuesday Week 44: Horror Legends",
    "section": "Other Ideas:",
    "text": "Other Ideas:\n\nStudy Text Mining with R\nText Analysis of the title, subtitle and claim - facet them by true, false and others.\nScrape story text from url and try to do text analysis by true, false and others.\nImprove visualization skills this time - make a nice poster with custom fonts and shape as from the Halloween previous Tidy Tuesday.\n\n\nMost common words in Titles, Sub-titles and Claim over time\nThere are no enough recurring words in ‚Äútitle‚Äù to draw meaningful conclusions.\n\n\nCode\nhorror_articles |&gt; \n  select(published, title) |&gt; \n  unnest_tokens(output = \"word\",\n                input = \"title\") |&gt; \n  anti_join(stop_words) |&gt; \n  group_by(published) |&gt; \n  count(word, sort = TRUE) |&gt; \n  ungroup() |&gt; \n  arrange(desc(n)) |&gt; \n  slice_head(n = 5)\n\n\n# A tibble: 5 √ó 3\n  published  word         n\n  &lt;date&gt;     &lt;chr&gt;    &lt;int&gt;\n1 1999-02-27 films       38\n2 1999-02-27 snuff       38\n3 1998-03-01 attacks     37\n4 1998-03-01 hiv         37\n5 1998-03-01 infected    37\n\n\nLets try the same in subtitle. Again, very few words that are common or recurring in subtitles.\n\n\nCode\nhorror_articles |&gt; \n  select(published, subtitle) |&gt; \n  unnest_tokens(output = \"word\",\n                input = \"subtitle\") |&gt; \n  anti_join(stop_words) |&gt; \n  group_by(published) |&gt; \n  count(word, sort = TRUE) |&gt; \n  ungroup() |&gt; \n  arrange(desc(n)) |&gt; \n  slice_head(n = 5)\n\n\n# A tibble: 5 √ó 3\n  published  word        n\n  &lt;date&gt;     &lt;chr&gt;   &lt;int&gt;\n1 1999-02-27 films      38\n2 1999-02-27 real       38\n3 1999-02-27 snuff      38\n4 1998-03-01 decades    37\n5 1998-03-01 hiv        37\n\n\nNow, let us try in the claim. First seeing how long the claims are: ‚Äì\n\n\nCode\nhorror_articles |&gt; \n  mutate(claim_length = str_length(claim)) |&gt; \n  pull(claim_length) |&gt; \n  summary()\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  26.00   75.00   92.00   99.17  117.00  625.00 \n\n\nSo, we see that the claims are not very long. On average they are 100 characters long only! Still, let us try to find the common words in claims: ‚Äì\n\n\nCode\nhorror_articles |&gt; \n  select(published, claim) |&gt; \n  unnest_tokens(output = \"word\",\n                input = \"claim\") |&gt; \n  anti_join(stop_words) |&gt; \n  group_by(published) |&gt; \n  count(word, sort = TRUE) |&gt; \n  filter(n &gt;= 2) |&gt; \n  ungroup() |&gt; \n  arrange(desc(n)) |&gt; \n  slice_head(n = 5)\n\n\n# A tibble: 5 √ó 3\n  published  word              n\n  &lt;date&gt;     &lt;chr&gt;         &lt;int&gt;\n1 1999-02-27 camera           38\n2 1999-02-27 entertainment    38\n3 1999-02-27 films            38\n4 1999-02-27 murdered         38\n5 1999-02-27 participants     38\n\n\nAgain, not enough words to plot. Let‚Äôs see if we can download the complete article text? Yes, we can!\nFinding common words in complete text by dates\n\n\nCode\n# Number of common words to plot\ncommon_n &lt;- 9\n\nstop_words &lt;- \n  bind_rows(stop_words,\n            tibble(\n              word = c(\"nbsp\", \"nobr\", \"dt\", \"dd\"),\n              lexicon = \"CUSTOM\"\n            ))\n\ntidy_horror &lt;- horror_articles |&gt; \n  select(text, paragraph, title, published) |&gt; \n  unnest_tokens(output = \"word\", \n                input = text) |&gt; \n  anti_join(stop_words) \n\ncommon_words &lt;- tidy_horror |&gt; \n  count(word, sort = TRUE) |&gt; \n  slice_head(n = common_n) |&gt; \n  pull(word)\n\ntidy_horror |&gt;\n  filter(word %in% common_words) |&gt;\n  mutate(word = fct(word, levels = common_words)) |&gt; \n  count(published, word, sort = TRUE) |&gt; \n  ggplot(aes(x = published, y = n, col = word)) +\n  geom_smooth(se = FALSE, span = 0.2) +\n  gghighlight::gghighlight() +\n  facet_wrap(~ word, ncol = (common_n %/% 3)) +\n  labs(title = \"The most common words in snopes.com articles over time\",\n       y = \"Number of times the word appears in the articles\",\n       x = NULL) +\n  scale_x_date(date_breaks = \"3 year\",\n               date_labels = \"%Y\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        panel.grid.minor = element_blank(),\n        panel.grid.major.y = element_blank(),\n        axis.text.x = element_text(angle = 90),\n        plot.title.position = \"plot\")\n\n\n\n\n\n\n\nSentiment Analysis over the course of time\nUsing nrc sentiment analysis. (Mohammad and Turney 2012)\n\n\nCode\n# seeing the distribution of the number of paragraphs in each article\nhorror_articles |&gt;\n  select(title, paragraph) |&gt; \n  group_by(title) |&gt; \n  mutate(max_p = max(paragraph)) |&gt; \n  ggplot() +\n  geom_histogram(aes(max_p), col = \"darkgrey\", fill = \"white\") +\n  theme_minimal()\n\n\n\n\n\nCode\n# One time download / agree to license of get_sentiments()\n# get_sentiments(\"afinn\")\n# get_sentiments(\"bing\")\nget_sentiments(\"nrc\")\n\n\n# A tibble: 13,872 √ó 2\n   word        sentiment\n   &lt;chr&gt;       &lt;chr&gt;    \n 1 abacus      trust    \n 2 abandon     fear     \n 3 abandon     negative \n 4 abandon     sadness  \n 5 abandoned   anger    \n 6 abandoned   fear     \n 7 abandoned   negative \n 8 abandoned   sadness  \n 9 abandonment anger    \n10 abandonment fear     \n# ‚Ñπ 13,862 more rows\n\n\nCode\n# Sentiment Analysis\nhorror_articles |&gt;\n  select(published, title, paragraph, text) |&gt; \n  unnest_tokens(word, text) |&gt;\n  mutate(index = row_number()) |&gt;\n  anti_join(stop_words) |&gt;\n  inner_join(get_sentiments(\"nrc\"),\n             relationship = \"many-to-many\") |&gt; \n  count(published, sentiment) |&gt;\n  group_by(published) |&gt; \n  mutate(prop_n = n / sum(n)) |&gt;\n  filter(!(sentiment %in% c(\"joy\", \"positive\"))) |&gt; \n  ggplot(aes(x = published,\n             y = prop_n,\n             col = sentiment)) + \n  geom_smooth(span = 0.1, se = FALSE) +\n  gghighlight::gghighlight() +\n  facet_wrap(~ sentiment, nrow = 2) +\n  labs(x = NULL, y = NULL) +\n  scale_y_continuous(labels = )\n\n\n\n\n\nCode\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 90))\n\n\nList of 2\n $ axis.text.x    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.position: chr \"none\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\n\n\n\nWord-Cloud\n\n\nImportant Words: tf-idf (by author)\n\n\nAnalyse bi-grams to find most common bi-grams"
  },
  {
    "objectID": "projects/horror_legends.html#most-common-horror-legends-words-over-the-years",
    "href": "projects/horror_legends.html#most-common-horror-legends-words-over-the-years",
    "title": "Eerie Revelations: Text Analysis of Snopes.com‚Äôs Horror Legends",
    "section": "Most common ‚Äúhorror-legends‚Äù words (over the years)",
    "text": "Most common ‚Äúhorror-legends‚Äù words (over the years)\nWhen we set out on our quest to unearth the most common words, we first tried our luck with titles, subtitles, and claims. Alas, these snippets were as fleeting as ghostly whispers, and no meaningful words could be found repeating. So, we embarked on a daring journey into the depths of web-scraping using rvest (Wickham 2022b). The treasure we unearthed was worth the eerie expedition. Figure¬†2 shows the most common words that have echoed in ‚ÄúFacts Check - Horror Legends‚Äù over the years. It seems ‚Äúcar‚Äù was popular in horror in late 1990s and mid-2000s, while ‚Äúpolice‚Äù was popular in early 2010s.\n\n\nCode\n# Number of common words to plot\ncommon_n &lt;- 6\n\nstop_words &lt;- \n  bind_rows(tidytext::stop_words,\n            tibble(\n              word = c(\"nbsp\", \"nobr\", \"dt\", \n                       \"dd\", \"font\", \"color\",\n                       \"story\", \"legend\", \"time\"),\n              lexicon = \"CUSTOM\"\n            ))\n\ntidy_horror &lt;- horror_articles |&gt; \n  select(text, paragraph, title, published) |&gt; \n  unnest_tokens(output = \"word\", \n                input = text) |&gt; \n  anti_join(stop_words) \n\ncommon_words &lt;- tidy_horror |&gt; \n  count(word, sort = TRUE) |&gt; \n  slice_head(n = common_n) |&gt; \n  pull(word)\n\ntidy_horror |&gt;\n  filter(word %in% common_words) |&gt;\n  mutate(word = snakecase::to_title_case(word)) |&gt; \n  # mutate(word = fct(word, levels = common_words)) |&gt; \n  count(published, word, sort = TRUE) |&gt; \n  ggplot(aes(x = published, y = n, col = word)) +\n  geom_smooth(se = FALSE, span = 0.2) +\n  gghighlight::gghighlight(\n    unhighlighted_params = list(col = \"lightgrey\")\n  ) +\n  facet_wrap(~ word, \n             ncol = (common_n %/% 3)) +\n  labs(y = \"Number of times the word appears in the articles\",\n       x = NULL) +\n  scale_x_date(date_breaks = \"3 year\",\n               date_labels = \"%Y\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        panel.grid.minor = element_blank(),\n        panel.grid.major.y = element_blank(),\n        axis.text.x = element_text(angle = 90),\n        plot.title.position = \"plot\",\n        strip.text = element_text(face = \"bold\"))\n\n\n\n\n\nFigure¬†2: The most common words in snopes.com articles over time\n\n\n\n\nNow, lets cast our gaze upon two word clouds, one representing the older articles (before 2010) and the other the newer articles (after 2010). The common words emerge like familiar apparitions, reminding us that some things in the world of horror legends never change. But, don‚Äôt be too quick to dismiss the surface-level spookiness. To plunge even deeper into the crypt of understanding, we shall wield the powerful technique of natural language processing, tf-idf to uncover the truly important words lurking in the shadows. Read on for the thrilling revelations that lie ahead! üîç\n\n\nCode\nlibrary(ggwordcloud)\n\ntidy_horror |&gt;\n  mutate(period = if_else(published &lt; as_date(\"2010-01-01\"),\n                          \"Old Posts on snopes.com (pre-2010)\",\n                          \"Newer posts on snopes.com (post-2010)\")) |&gt; \n  count(period, word, sort = TRUE) |&gt; \n  group_by(period) |&gt; \n  mutate(prop_word = n/sum(n)) |&gt; \n  slice_max(order_by = prop_word, n = 100) |&gt; \n  \n  ggplot(aes(label = word,\n             size = prop_word)) +\n  geom_text_wordcloud() +\n  facet_wrap(~ period) +\n  theme_minimal() +\n  theme(strip.text = element_text(face = \"bold\"))\n\n\n\n\n\nFigure¬†3: ?(caption)"
  },
  {
    "objectID": "projects/horror_legends.html#important-words-for-different-authors-tf-idf",
    "href": "projects/horror_legends.html#important-words-for-different-authors-tf-idf",
    "title": "Eerie Revelations: Text Analysis of Snopes.com‚Äôs Horror Legends",
    "section": "Important Words for different authors (tf-idf)",
    "text": "Important Words for different authors (tf-idf)\nEnter the realm of tf-idf, a magical incantation from the realm of information retrieval, where we unveil the importance of words within articles. In this eerie exploration, our main focus falls upon Barbara Mikkelson and David Mikkelson. As for the rest of the authors, they‚Äôve contributed only sparsely, so we merge their meager contributions into a collective cauldron.\nSome interesting revelations emerge in Figure¬†4 . David‚Äôs articles were dominated by words ‚Äúsmarties,‚Äù ‚ÄúHoudini,‚Äù ‚Äúhotel,‚Äù ‚Äúperfume,‚Äù and ‚Äúmeat‚Äù as if weaving a curious web of mystery. Meanwhile, Barbara‚Äôs writings whispered of ‚ÄúDarwin,‚Äù ‚Äúwebkinz,‚Äù ‚Äúpurse,‚Äù and ‚Äúkidney,‚Äù painting a vivid tapestry of subjects that have danced through her tales.\n\n\nCode\nimp_auths &lt;- c(\"Barbara Mikkelson\", \"David Mikkelson\", \"Snopes Staff\")\n\nhorror_articles |&gt; \n  mutate(\n    author = fct(author),\n    author = fct_lump_n(author, n = 2)\n  ) |&gt; \n  unnest_tokens(output = \"word\", \n                input = text) |&gt; \n  anti_join(stop_words) |&gt; \n  count(author, word) |&gt; \n  bind_tf_idf(term = word,\n              document = author,\n              n = n) |&gt; \n  group_by(author) |&gt;\n  slice_max(order_by = tf_idf, n = 20) |&gt; \n  mutate(tf_idf = tf_idf / sum(tf_idf)) |&gt; \n  ggplot(aes(size = tf_idf,\n             label = word)) +\n  geom_text_wordcloud() +\n  facet_wrap(~ author) +\n  theme_minimal() +\n  theme(strip.text = element_text(face = \"bold\"))\n\n\n\n\n\nFigure¬†4: Unique and Important recurring words, sized by recurrence, in works of different authors at snopes.com\n\n\n\n\nVenturing deeper into the depths of our textual analysis, we‚Äôve summoned the most common two-worded phrases, also known as bigrams, from the works of our different authors. These combinations of words offer a glimpse into the unique patterns and narratives that each author weaves: ‚Äì\n\n\nCode\nremove_words &lt;- c(\"https\", \"www.snopes.com\", \"color_g\", \"absmiddle\", \n                  \"return\", \"class\", \"width\", \"align\", \"border\", \"height\")\n\nhorror_articles |&gt; \n  unnest_tokens(output = bigram,\n                input = text,\n                token = \"ngrams\",\n                n = 2) |&gt; \n  filter(!is.na(bigram)) |&gt; \n  \n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \") |&gt; \n  anti_join(stop_words, by = join_by(\"word1\" == \"word\")) |&gt; \n  anti_join(stop_words, by = join_by(\"word2\" == \"word\")) |&gt; \n  mutate(\n    author = fct(author),\n    author = fct_lump_n(author, n = 2)\n  ) |&gt; \n  count(author, word1, word2, sort = TRUE) |&gt; \n  \n  # Remove some stop words and technical html words\n  filter(!(word1 %in% remove_words)) |&gt; \n  filter(!(word2 %in% remove_words)) |&gt; \n  \n  # Uniting back word1 and word2 to form a bigram\n  unite(col = \"bigram\", \n        word1, word2,\n        sep = \" \") |&gt; \n  \n  # To run the analyses by author\n  group_by(author) |&gt; \n  \n  # Removing duplicacies in plural and singular terms\n  mutate(bigram = if_else(bigram == \"darwin award\",\n                          \"darwin awards\",\n                          bigram)) |&gt; \n  mutate(bigram = if_else(bigram == \"urban legend\",\n                          \"urban legends\",\n                          bigram)) |&gt; \n  mutate(perc_word = (100 * n) / sum(n) ) |&gt; \n  \n  slice_max(order_by = perc_word, n = 10, with_ties = FALSE) |&gt; \n  \n  \n  ggplot(aes(x = perc_word, \n             y = fct_reorder(bigram, n))) +\n  geom_col(fill = \"orange\", alpha = 0.8) +\n  geom_text(aes(label = bigram,\n                x = 0),\n            hjust = \"left\") +\n  facet_wrap(~ author, scales = \"free\") +\n  \n  scale_x_continuous(labels = percent_format()) +\n  labs(x = NULL, y = NULL) +\n  theme_minimal() +\n  theme(axis.text.y = element_blank(),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        strip.text = element_text(face = \"bold\",\n                                  size = 12)\n        )\n\n\n\n\n\nFigure¬†5: Most common bi-grams by authors in the articles of horro legends at snopes.com"
  },
  {
    "objectID": "projects/horror_legends.html#sentiments-in-horror-legends-over-the-years",
    "href": "projects/horror_legends.html#sentiments-in-horror-legends-over-the-years",
    "title": "Eerie Revelations: Text Analysis of Snopes.com‚Äôs Horror Legends",
    "section": "‚ÄúSentiments‚Äù in Horror-Legends over the years",
    "text": "‚ÄúSentiments‚Äù in Horror-Legends over the years\nNow, let‚Äôs unravel the evolution of sentiments in articles spanning the past two decades. Armed with the nrc sentiment analysis (Mohammad and Turney 2012) and the methods from Text Mining with R we depict the ebbs and flows of emotion in the written word visually. As we see in Figure¬†6 , recently, articles have become more laced with words expressing ‚Äúfear‚Äù and ‚Äúanticipation‚Äù. Meanwhile, words expressing ‚Äúdisgust‚Äù and ‚Äúsadness‚Äù seem to have faded over time. The ghosts of emotions past are shifting and morphing in the text, revealing a tale of changing sentiments in horror legends. üëª\n\n\nCode\n# One time download / agree to license of get_sentiments()\n# get_sentiments(\"afinn\")\n# get_sentiments(\"bing\")\n# get_sentiments(\"nrc\")\n\n# Sentiment Analysis\nhorror_articles |&gt;\n  select(published, title, paragraph, text) |&gt; \n  unnest_tokens(word, text) |&gt;\n  mutate(index = row_number()) |&gt;\n  anti_join(stop_words) |&gt;\n  inner_join(get_sentiments(\"nrc\"),\n             relationship = \"many-to-many\") |&gt; \n  count(published, sentiment) |&gt;\n  group_by(published) |&gt; \n  mutate(prop_n = n / sum(n)) |&gt;\n  filter(!(sentiment %in% c(\"joy\", \"positive\", \"negative\", \"trust\"))) |&gt;\n  mutate(sentiment = snakecase::to_title_case(sentiment)) |&gt; \n  \n  ggplot(aes(x = published,\n             y = prop_n,\n             col = sentiment)) + \n  geom_smooth(span = 0.3, se = FALSE) +\n  gghighlight::gghighlight(\n    unhighlighted_colour = \"#dcdedc\"\n  ) +\n  facet_wrap(~ sentiment, nrow = 2) +\n  \n  labs(x = NULL, y = NULL) +\n  scale_y_continuous(labels = ) +\n  scale_color_brewer(palette = \"Dark2\") +\n  \n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 90, \n                                   vjust = 0.5),\n        strip.text = element_text(face = \"bold\",\n                                  size = 12),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.minor.x = element_blank()\n        )\n\n\n\n\n\nFigure¬†6: Change in the frequency of words depicting an emotion in te articles over time. The y-axis represents percentage of words that express this particular emotion\n\n\n\n\n\nVisualizing word-networks within ‚Äúhorror legends‚Äù\nTo add a touch of visual enchantment to our exploration, we‚Äôve harnessed ggraph (Pedersen 2022) to craft a captivating map of the most common word associations within the realm of horror legends. As anticipated, certain word pairings emerge as familiar apparitions, like ‚Äúcell phone,‚Äù ‚Äúurban legends,‚Äù ‚Äúgas stations,‚Äù ‚Äúfast food,‚Äù and ‚Äúsocial media,‚Äù which seem to haunt the narratives time and again. However, one curious gem in this tapestry of terror is the mention of ‚ÄúLos Angeles,‚Äù a city that may harbor its own cryptic secrets in the world of horror legends. üó∫Ô∏è\n\n\nCode\nlibrary(igraph)\nlibrary(ggraph)\nset.seed(1)\n\nremove_words &lt;- c(\"https\", \"www.snopes.com\", \"color_g\", \"absmiddle\", \n                  \"return\", \"class\", \"width\", \"themes\", \"content\", \"images\",\n                  \"common\", \"img\", \"src\")\n\n# Credits: https://www.tidytextmining.com/ngrams\n\nhorror_articles |&gt; \n  unnest_tokens(output = bigram,\n                input = text,\n                token = \"ngrams\",\n                n = 2) |&gt; \n  filter(!is.na(bigram)) |&gt; \n  \n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \") |&gt; \n  anti_join(stop_words, by = join_by(\"word1\" == \"word\")) |&gt; \n  anti_join(stop_words, by = join_by(\"word2\" == \"word\")) |&gt; \n  count(word1, word2, sort = TRUE) |&gt; \n  filter(!(word1 %in% remove_words)) |&gt; \n  filter(!(word2 %in% remove_words)) |&gt; \n  slice_max(order_by = n, n = 80) |&gt; \n  graph_from_data_frame() |&gt; \n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()\n\n\n\n\n\nFigure¬†7: Most common word associations within the horror legends articles\n\n\n\n\nIdeas & Motivation: A lot of the work and code in this article is inspired from teachings in Text Mining with R by Julia Silge and David Robinson."
  },
  {
    "objectID": "projects/horror_legends.html#exploring-the-publication-and-authorship-of-articles",
    "href": "projects/horror_legends.html#exploring-the-publication-and-authorship-of-articles",
    "title": "Eerie Revelations: Text Analysis of Snopes.com‚Äôs Horror Legends",
    "section": "Exploring the publication and authorship of Articles",
    "text": "Exploring the publication and authorship of Articles\nNow, let‚Äôs dive into the data crypt with exploratory data analysis in R, where we unearth 253 eerie articles and over 2,400 paragraphs waiting to be dissected. Mysteriously enough, a majority of these articles were penned by the dynamic duo of David and Barbara Mikkelson, and their tales span from the late 1990s to the present day. The following Figure¬†1 unveils basic trends üëª\n\n\nCode\nhorror_articles |&gt; \n  ggplot(aes(published)) +\n  geom_histogram(fill = \"orange\",\n                 col = \"black\") +\n  theme_minimal() +\n  labs(y = \"Number of articles published\",\n       title = \"Articles published on snopes.com in \\\"Facts Check: Horror\\\" over the years\",\n       x = \"\") +\n  theme(plot.title.position = \"plot\",\n        axis.line = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.grid.major.x = element_blank())\n\n\nhorror_articles |&gt; \n  count(author, sort = TRUE) |&gt;\n  mutate(author = fct(author),\n         author = fct_lump_n(author, n = 2, w = n)) |&gt;\n  group_by(author) |&gt; \n  summarise(n = sum(n)) |&gt; \n  mutate('Percentage of Total Articles' = n/sum(n)) |&gt; \n  rename(Author = author,\n         `Number of Articles` = n) |&gt; \n  ggplot(aes(x = \"\",\n             y = `Number of Articles`,\n             fill = reorder(Author, `Number of Articles`),\n             label = `Percentage of Total Articles`)) +\n  geom_col(position = \"stack\", \n           col = \"white\") +\n  geom_text(aes(label = paste0(Author, \": \", `Number of Articles`)),\n            position = position_stack(vjust = 0.55)) +\n  coord_polar(theta = \"y\", start = 0) +\n  theme_void() +\n  theme(legend.position = \"none\") +\n  scale_fill_brewer(palette = \"Oranges\") +\n  labs(title = \"Number of articles at snopes.com by authorship\")\n\n\n\n\n\n\n\n\n(a) Timeline\n\n\n\n\n\n\n\n\n\n(b) Authorship\n\n\n\n\nFigure¬†1: Articles at Horror Legends Fact Check - dates of publication"
  },
  {
    "objectID": "projects/us_house_election_results.html",
    "href": "projects/us_house_election_results.html",
    "title": "Electoral Kaleidoscope: Visualizing the Impact of Proportional Representation",
    "section": "",
    "text": "In the thrilling world of elections, there are two main contenders duking it out for the title of ‚ÄúBest Voting System‚Äù: the classic First-Past-the-Post (FPTP) and the avant-garde Proportional Seats Representation (PSR).\nThink of FPTP as the sprinter, the first to cross the finish line takes it all, while PSR is more like a democratic marathon, ensuring everyone‚Äôs voice is heard. Or, imagine you‚Äôre at a pizza party‚ÄîFPTP would be that one friend who grabs the last slice before you even realize it‚Äôs up for grabs, while PSR ensures everyone gets a fair share of the cheesy goodness.\nNow, let‚Äôs dive into the wild world of U.S. House of Representatives elections from 1976 to 2022 and see how these systems have been throwing their punches in the political ring. The data comes from the MIT Election Data and Science Lab (MEDSL), and from the MEDSL‚Äôs report New Report: How We Voted in 2022. I‚Äôll be specifically working on the data on House elections from 1976-2022 downloaded from the Harvard Dataverse.\nCode\n# Load libraries and data\n\nlibrary(tidyverse)    # all things tidy\nlibrary(shiny)        # shiny app\nlibrary(sf)           # for maps\nlibrary(ggparliament) # for parliament seats plots\nlibrary(gganimate)    # to create animations\nlibrary(gt)           # gt tables\nlibrary(gtExtras)     # nicer gt tables\nlibrary(RColorBrewer) # colours\n\n# Using the Option of Reading data directly from GitHub\n\n# house &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-11-07/house.csv')\n\n# write_csv(house, file = here::here(\"docs\", \"house.csv\"))\n\n# For faster loading times, I have saved the interim tibbles as csv\n# and simply loading them, hoever, all the code to generate the following csv\n# are given below\n\nmap_data &lt;- read_csv(here::here(\"docs\", \"map_data.csv\"))\ntotalparl &lt;- read_csv(here::here(\"docs\", \"totalparl.csv\"))\npropparl &lt;- read_csv(here::here(\"docs\", \"propparl.csv\"))"
  },
  {
    "objectID": "projects/us_house_election_results.html#us-house-election-results",
    "href": "projects/us_house_election_results.html#us-house-election-results",
    "title": "Week 45 #TidyTuesday",
    "section": "",
    "text": "In the thrilling world of elections, there are two main contenders duking it out for the title of ‚ÄúBest Voting System‚Äù: the classic First-Past-the-Post (FPTP) and the avant-garde Proportional Seats Representation (PSR).\nThink of FPTP as the sprinter, the first to cross the finish line takes it all, while PSR is more like a democratic marathon, ensuring everyone‚Äôs voice is heard. Or, imagine you‚Äôre at a pizza party‚ÄîFPTP would be that one friend who grabs the last slice before you even realize it‚Äôs up for grabs, while PSR ensures everyone gets a fair share of the cheesy goodness.\nNow, let‚Äôs dive into the wild world of U.S. House of Representatives elections from 1976 to 2022 and see how these systems have been throwing their punches in the political ring. The data comes from the MIT Election Data and Science Lab (MEDSL), and from the MEDSL‚Äôs report New Report: How We Voted in 2022. I‚Äôll be specifically working on the data on House elections from 1976-2022 downloaded from the Harvard Dataverse.\n\n\nCode\n# Load libraries and data\n\nlibrary(tidyverse)    # all things tidy\nlibrary(shiny)        # shiny app\nlibrary(sf)           # for maps\nlibrary(ggparliament) # for parliament seats plots\nlibrary(gganimate)    # to create animations\nlibrary(gt)           # gt tables\nlibrary(gtExtras)     # nicer gt tables\nlibrary(RColorBrewer) # colours\n\n# Using the Option of Reading data directly from GitHub\n\n# house &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-11-07/house.csv')\n\n# write_csv(house, file = here::here(\"docs\", \"house.csv\"))\n\n# For faster loading times, I have saved the interim tibbles as csv\n# and simply loading them, hoever, all the code to generate the following csv\n# are given below\n\nmap_data &lt;- read_csv(here::here(\"docs\", \"map_data.csv\"))\ntotalparl &lt;- read_csv(here::here(\"docs\", \"totalparl.csv\"))\npropparl &lt;- read_csv(here::here(\"docs\", \"propparl.csv\"))\n\n\n\n\nTo unravel the secrets hidden within the labyrinth of U.S. House of Representatives election results from 1976 to 2022, I‚Äôve armed myself with an arsenal of tidyverse (Wickham et al. 2019) tools and a few trusty sidekicks: sf (Pebesma and Bivand 2023) to map out the results, and ggparliament (Hickman, Meers, and Leeper 2018) and gganimate (Pedersen and Robinson 2022) to add some visual spice, and gt (Iannone et al. 2023) and gtExtras (Mock 2023) step in for a dash of elegance. If you wish to peek behind the curtain and explore the data science magic, just hit the ‚ÄúCode‚Äù button.\n\n\nCode\n# Read the CSV file from the specified URL using the readr package\nhouse &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-11-07/house.csv')\n\n# Visualize the structure and missing values of the data using the visdat package\nvisdat::vis_dat(house)\n\n# Generate a summary report of the data using the dfSummary function from the summarytools package\nsummarytools::dfSummary(house)"
  },
  {
    "objectID": "projects/us_house_election_results.html#exploratory-data-analysis",
    "href": "projects/us_house_election_results.html#exploratory-data-analysis",
    "title": "Week 45 #TidyTuesday",
    "section": "",
    "text": "Explain the meaning of first-past the post system and the proportional representation system.\nExplain in 2-3 line system of Congress in USA."
  },
  {
    "objectID": "projects/us_house_election_results.html#calculate-victor-and-percentage-votes",
    "href": "projects/us_house_election_results.html#calculate-victor-and-percentage-votes",
    "title": "Week 45 #TidyTuesday",
    "section": "",
    "text": "Create a tibble of proportion of votes received for each candidate\n\n\n\n\n\n\nFigure¬†1: Seats and Popular Vote Percentage for the two major US parties\n\n\n\n\n\n\n\n\n\nThe Actual plots: ‚Äì\n\n\n\nSelect the Year of Elections"
  },
  {
    "objectID": "projects/us_house_shiny.html",
    "href": "projects/us_house_shiny.html",
    "title": "Week 45 #TidyTuesday",
    "section": "",
    "text": "This data comes from the MIT Election Data and Science Lab (MEDSL), and from the MEDSL‚Äôs report¬†New Report: How We Voted in 2022\nWe‚Äôre specifically working on the data on House elections from 1976-2022. Check out the MEDSL website for additional datasets and tools.\nClean data and dictionary downloaded from the Harvard Dataverse.\n\n\n\nExplain the meaning of first-past the post system and the proportional representation system.\nExplain in 2-3 line system of Congress in USA.\n\n\n\nCreate a tibble of proportion of votes received for each candidate\n\n\n\n\n\n\nFigure¬†1: Seats and Popular Vote Percentage for the two major US parties\n\n\n\n\n\n\n\n\n\nThe Actual plots: ‚Äì\n\n\n\nSelect the Year of Elections"
  },
  {
    "objectID": "projects/us_house_shiny.html#us-house-election-results",
    "href": "projects/us_house_shiny.html#us-house-election-results",
    "title": "Week 45 #TidyTuesday",
    "section": "",
    "text": "This data comes from the MIT Election Data and Science Lab (MEDSL), and from the MEDSL‚Äôs report¬†New Report: How We Voted in 2022\nWe‚Äôre specifically working on the data on House elections from 1976-2022. Check out the MEDSL website for additional datasets and tools.\nClean data and dictionary downloaded from the Harvard Dataverse."
  },
  {
    "objectID": "projects/us_house_shiny.html#exploratory-data-analysis",
    "href": "projects/us_house_shiny.html#exploratory-data-analysis",
    "title": "Week 45 #TidyTuesday",
    "section": "",
    "text": "Explain the meaning of first-past the post system and the proportional representation system.\nExplain in 2-3 line system of Congress in USA."
  },
  {
    "objectID": "projects/us_house_shiny.html#calculate-victor-and-percentage-votes",
    "href": "projects/us_house_shiny.html#calculate-victor-and-percentage-votes",
    "title": "Week 45 #TidyTuesday",
    "section": "",
    "text": "Create a tibble of proportion of votes received for each candidate\n\n\n\n\n\n\nFigure¬†1: Seats and Popular Vote Percentage for the two major US parties\n\n\n\n\n\n\n\n\n\nThe Actual plots: ‚Äì\n\n\n\nSelect the Year of Elections"
  },
  {
    "objectID": "projects/us_house_election_results.html#each-election-result-over-time-1976---2022",
    "href": "projects/us_house_election_results.html#each-election-result-over-time-1976---2022",
    "title": "Electoral Kaleidoscope: Visualizing the Impact of Proportional Representation",
    "section": "Each election result over time: 1976 - 2022",
    "text": "Each election result over time: 1976 - 2022\n\n\nThis animated bar chart is a mesmerizing dance of political prowess. It reveals the ebb and flow of seats won by the dynamic duo of the two main parties in each biennial election from 1976 to 2022. It seems the stage is monopolized by the headliners, leaving the ‚ÄúOther‚Äù party contenders with no representation.\n\n\n\n\n\n\n\nCode\n# Define a vector containing the names of the main political parties\nmain_parties &lt;- c(\"DEMOCRAT\", \"REPUBLICAN\")\n\n# Create a new dataframe 'h1' using the magrittr pipe operator %&gt;%\nh1 &lt;- house |&gt; \n  # Group the data by state, district, and year\n  group_by(state, district, year) |&gt; \n  # Add new columns: prop_votes (proportion of votes), victory (boolean indicating victory), party\n  mutate(\n    prop_votes = candidatevotes / totalvotes,\n    victory = (prop_votes == max(prop_votes)),\n    party = party,\n    .keep = \"used\"\n  ) |&gt; \n  # Remove grouping\n  ungroup()\n\n# Create a new dataframe 'ganim' using the magrittr pipe operator %&gt;%\nganim &lt;- h1 |&gt; \n  # Filter rows where 'victory' is TRUE\n  filter(victory) |&gt; \n  # Group the data by 'year' and count the occurrences of each 'party'\n  group_by(year) |&gt; \n  count(party) |&gt;\n  # Remove grouping\n  ungroup() |&gt; \n  # Mutate columns: convert 'party' to title case, convert to factor, and lump categories to top 2\n  mutate(\n    party = snakecase::to_title_case(party),\n    party = fct(party),\n    party = fct_lump_n(party, n = 2)\n  ) |&gt; \n  \n  # Create a ggplot visualization\n  ggplot(aes(x = n, y = fct_rev(party), fill = party)) +\n    geom_col() +\n    geom_vline(xintercept = 218, lwd = 1, alpha = 0.2) +\n    facet_wrap( ~ year) +\n    scale_fill_manual(values = c(\"blue\", \"red\", \"darkgrey\")) +\n    labs(x = \"Seats in House of Representatives\", \n         y = NULL,\n         title = 'Year: {closest_state}') +\n    \n    ggthemes::theme_clean() +\n    theme(\n      legend.position = \"none\",\n      axis.line.y = element_blank(),\n      plot.background = element_rect(colour = \"white\"),\n      plot.title = element_text(size = 36, hjust = 0.5),\n      axis.text = element_text(size = 15)\n    ) +\n    facet_null() +\n    # Create an animated transition over 'year' using gganimate\n    transition_states(year, \n                      transition_length = 10, \n                      state_length = 1) +\n    enter_fade() +\n    exit_fade()\n\n# Save the animated plot as a GIF\nanim_save(\n  here::here(\"docs\", \"us_house_anim1.gif\"),\n  animation = ganim, \n  fps = 30, \n  duration = 45,\n  end_pause = 3\n)"
  },
  {
    "objectID": "projects/us_house_election_results.html#seats-won-vs.-the-popular-vote-for-the-main-two-parties",
    "href": "projects/us_house_election_results.html#seats-won-vs.-the-popular-vote-for-the-main-two-parties",
    "title": "Electoral Kaleidoscope: Visualizing the Impact of Proportional Representation",
    "section": "Seats won Vs. the popular vote for the main two parties",
    "text": "Seats won Vs. the popular vote for the main two parties\nNow, you‚Äôd think the seats would just follow the popular vote, right? Wrong! The graph below spills the beans on the popular vote percentages versus the actual seats won by the Democrat and Republican parties ‚Äî the solid-colored lines show the seats won, and the faint, see-through ones are the actual percentage of popular votes!\nSurprise, surprise, the winning party is always snagging more seats than its popular vote percentages would lead you to believe.\n\n\nCode\n# Number of seats for each party in the Congress\nh1a &lt;- h1 |&gt; \n  filter(victory) |&gt; \n  group_by(year) |&gt; \n  count(party) |&gt; \n  filter(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt; \n  mutate(party = fct(party, levels = c(\"DEMOCRAT\", \"REPUBLICAN\")))\n\n# Number of votes for each party in that election\nh1b &lt;- h1 |&gt; \n  group_by(year, party) |&gt; \n  summarise(\n    votes = sum(candidatevotes)\n  ) |&gt; \n  mutate(prop_votes = votes / sum(votes)) |&gt; \n  filter(party %in% main_parties) |&gt; \n  mutate(party = fct(party, levels = c(\"DEMOCRAT\", \"REPUBLICAN\"))) |&gt; \n  ungroup()\n\n# A multiplication factor for the dual y-axis\nsec_axis_factor = 435\n\nggplot(data = h1a, \n         aes(x = year, y = n, col = party)) +\n  geom_line() +\n  geom_point() +\n  geom_line(data = h1b, aes(y = prop_votes*sec_axis_factor), lty = 2, alpha = 0.4) +\n  geom_point(data = h1b, aes(y = prop_votes*sec_axis_factor), alpha = 0.2) +\n  geom_hline(aes(yintercept = sec_axis_factor/2), alpha = 0.2, lwd = 0.5) +\n  \n  \n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  scale_x_continuous(breaks = unique(h1 |&gt; pull(year))) +\n  scale_y_continuous(\n    sec.axis = sec_axis(trans = ~./(sec_axis_factor/100), \n                        name = \"Percentage of Popular Vote (% votes polled)\")\n  ) +\n  \n  labs(x = NULL, y = \"Number of seats won\",\n       title = \"Winning party almost always has a lower share of popular vote than number of seats reflect\") +\n  \n  theme_minimal() +\n  theme(panel.grid.minor = element_blank(),\n        panel.grid.major.y = element_blank(),\n        axis.text.x = element_text(angle = 90),\n        legend.position = \"none\", \n        plot.title.position = \"plot\")\n\n\n\n\n\nFigure¬†1: Seats and Popular Vote Percentage for the two major US parties"
  },
  {
    "objectID": "projects/us_house_election_results.html#popular-vote-for-the-party-controlling-the-house",
    "href": "projects/us_house_election_results.html#popular-vote-for-the-party-controlling-the-house",
    "title": "Electoral Kaleidoscope: Visualizing the Impact of Proportional Representation",
    "section": "Popular Vote % for the party controlling the House",
    "text": "Popular Vote % for the party controlling the House\nNow, this graph depicts the percentage of popular votes snagged by the party in control of the House each year. Brace yourselves for a mind-bender ‚Äî out of the 24 times people cast their votes for the House of Representatives, a whopping nine times saw the winning party clutching victory with less than 50% of the popular vote.\n\n\nCode\n# A tibble of party controlling the congress each bi-year (party_in_power)\np_in_p &lt;- h1 |&gt; \n  \n  # taking only victorious candidates\n  filter(victory) |&gt; \n  \n  # number of seats won by each party\n  count(year, party) |&gt; \n  \n  # add a column of total number of seats\n  group_by(year) |&gt; \n  mutate(total_seats = sum(n)) |&gt; \n  rename(seats = n) |&gt; \n  mutate(control = seats/total_seats &gt; 0.5) |&gt; \n  filter(control) |&gt; \n  select(year, party) |&gt; \n  rename(party_in_power = party)\n\n# Computing percetnage of people who voted for winning party\nh1 |&gt; \n  left_join(p_in_p) |&gt; \n  mutate(victory = if_else(party == party_in_power,\n                           \"Victorious Party\",\n                           \"Others\",\n                           missing = \"Others\")) |&gt; \n  group_by(year, victory) |&gt; \n  summarise(votes = sum(candidatevotes)) |&gt; \n  mutate(prop = votes / sum(votes)) |&gt; \n  filter(victory == \"Victorious Party\") |&gt; \n  mutate(col_prop = prop &lt; 0.5) |&gt; \n  \n  # Plot the votes percentage\n  ggplot(aes(x = year, \n             y = prop)) +\n  geom_point(aes(col = col_prop)) + \n  geom_line(lty = 2, \n            lwd = 0.2) +\n  geom_hline(yintercept = 0.5, \n             col = \"grey\", \n             alpha = 0.5,\n             lty = 2) +\n  \n  scale_x_continuous(breaks = unique(h1 |&gt; pull(year))) +\n  scale_y_continuous(labels = scales::percent_format(),\n                     limits = c(0.4, 0.6)) +\n  scale_color_manual(values = c(\"black\", \"red\")) +\n  \n  labs(x = NULL, \n       y = \"% Votes polled for Party controlling the House\",\n       col = NULL,\n       title = \"The ruling party did not have the majority popular vote in 9 out of 24 Houses\") +\n  \n  theme_minimal() +\n  theme(panel.grid.minor = element_blank(),\n        panel.grid.major.y = element_blank(),\n        axis.text.x = element_text(angle = 90),\n        legend.position = \"none\",\n        plot.title.position = \"plot\")"
  },
  {
    "objectID": "projects/us_house_election_results.html#the-two-times-that-psr-wouldve-changed-majority-party",
    "href": "projects/us_house_election_results.html#the-two-times-that-psr-wouldve-changed-majority-party",
    "title": "Electoral Kaleidoscope: Visualizing the Impact of Proportional Representation",
    "section": "The two times that PSR would‚Äôve changed majority party",
    "text": "The two times that PSR would‚Äôve changed majority party\nTo cap off our journey, let‚Äôs zoom in on the pivotal election years of 1992 and 2020, where the very fabric of majority rule would have been rewoven under a Proportional Seats Representation (PSR) system. In 1992, the Democratic majority would‚Äôve been replaced with requirement of a coalition of sorts. Fast forward to 2020, and similar outcome would‚Äôve arisen. But the real star of the show? Those grey coloured ‚ÄúOther Parties‚Äù section of the graphs below. In a PSR universe, they step into the limelight, their influence reaching far beyond regional boundaries. #PSRRevolution #TidyTuesday #ElectionEpilogue"
  },
  {
    "objectID": "projects/us_house_election_results.html#us-house-of-representatives-results",
    "href": "projects/us_house_election_results.html#us-house-of-representatives-results",
    "title": "Electoral Kaleidoscope: Visualizing the Impact of Proportional Representation",
    "section": "1992: US House of Representatives Results",
    "text": "1992: US House of Representatives Results\n\n\nCode\ninput = NULL\ninput$year = 1992\nus_map &lt;- USAboundaries::us_congressional(resolution = \"low\") |&gt; \n  \n  # Extract District Number\n  mutate(district = parse_number(namelsad)) |&gt; \n  \n  select(state_abbr, district, geometry) |&gt; \n  as_tibble() |&gt; \n  \n  # Correct encoding of districts to match our data\n  mutate(district = replace_na(district, replace = 0))\n\nmap_data |&gt; \n  \n  # Join with the map geometry column\n  left_join(us_map) |&gt; \n  \n  # Leave out non-continental USA\n  filter(!state_abbr %in% c(\"PR\", \"AK\", \"HI\")) |&gt;\n  filter(year == input$year) |&gt;\n  \n  ggplot(aes(fill = party, \n             geometry = geometry)) + \n  geom_sf(col = \"white\") + \n  geom_text(aes(label = year, x = -75, y = 48), size = 12) +\n  coord_sf() + \n  \n  scale_fill_manual(values = c(\"#3333FF\", \"#B4B4B4\", \"#E81B23\")) +\n  \n  theme_void() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nCode\nusparl &lt;- totalparl |&gt; \n  filter(year == input$year)\n\nmajority &lt;- usparl |&gt; \n  filter(seats &gt;= 218) |&gt; \n  pull(party_long) |&gt; \n  as.character() \n\nmajority &lt;- if_else(is.na(majority), \"Coalition\", majority)\n\nusparl |&gt; \n  parliament_data(type = \"semicircle\", \n                  parl_rows = 10,\n                  party_seats = usparl$seats) |&gt; \n  ggplot(aes(x = x, y = y, colour = party_short)) +\n  geom_parliament_seats() +\n  draw_majoritythreshold(n = 218, label = TRUE, type = \"semicircle\") +\n  draw_partylabels(type = \"semicircle\",\n                   party_names = party_long,\n                   party_seats = seats,\n                   party_colours = colour) +\n  geom_highlight_government(government == 1, size = 4) +\n  \n  labs(title = paste0(\"Actual House of Representatives: \", input$year),\n       subtitle = paste0(\"Majority: \", majority)) +\n  theme_ggparliament(legend = FALSE) +\n  scale_colour_manual(values = usparl$colour,\n                      limits = usparl$party_short)  +\n  theme(plot.title = element_text(size = 20),\n        plot.subtitle = element_text(size = 14))\nuspropparl &lt;- propparl |&gt; \n  filter(year == input$year)\n\nuspropparl |&gt; \n  parliament_data(type = \"semicircle\", \n                  parl_rows = 10,\n                  party_seats = uspropparl$seats) |&gt; \n  ggplot(aes(x = x, y = y, colour = party_short)) +\n  geom_parliament_seats() +\n  draw_majoritythreshold(n = 218, label = TRUE, type = \"semicircle\") +\n  draw_partylabels(type = \"semicircle\",\n                   party_names = party_long,\n                   party_seats = seats,\n                   party_colours = colour) +\n  geom_highlight_government(government == 1, size = 4) +\n  \n  labs(title = paste0(\"USA House of Reps (PSR Sytem): \", input$year),\n       subtitle = \"No party would've had majority.\") +\n  theme_ggparliament(legend = FALSE) +\n  scale_colour_manual(values = usparl$colour,\n                      limits = usparl$party_short)  +\n  theme(plot.title = element_text(size = 20),\n        plot.subtitle = element_text(size = 14))"
  },
  {
    "objectID": "projects/us_house_election_results.html#us-house-of-representatives-results-1",
    "href": "projects/us_house_election_results.html#us-house-of-representatives-results-1",
    "title": "Electoral Kaleidoscope: Visualizing the Impact of Proportional Representation",
    "section": "2020: US House of Representatives Results",
    "text": "2020: US House of Representatives Results\n\n\nCode\ninput = NULL\ninput$year = 2020\n\nmap_data |&gt; \n  \n  # Join with the map geometry column\n  left_join(us_map) |&gt; \n  \n  # Leave out non-continental USA\n  filter(!state_abbr %in% c(\"PR\", \"AK\", \"HI\")) |&gt;\n  filter(year == input$year) |&gt;\n  \n  ggplot(aes(fill = party, \n             geometry = geometry)) + \n  geom_sf(col = \"white\") + \n  geom_text(aes(label = year, x = -75, y = 48), size = 12) +\n  coord_sf() + \n  \n  scale_fill_manual(values = c(\"#3333FF\", \"#E81B23\")) +\n  \n  theme_void() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nCode\nusparl &lt;- totalparl |&gt; \n  filter(year == input$year)\n\nmajority &lt;- usparl |&gt; \n  filter(seats &gt;= 218) |&gt; \n  pull(party_long) |&gt; \n  as.character() \n\nmajority &lt;- if_else(is.na(majority), \"Coalition\", majority)\n\nusparl |&gt; \n  parliament_data(type = \"semicircle\", \n                  parl_rows = 10,\n                  party_seats = usparl$seats) |&gt; \n  ggplot(aes(x = x, y = y, colour = party_short)) +\n  geom_parliament_seats() +\n  draw_majoritythreshold(n = 218, label = TRUE, type = \"semicircle\") +\n  draw_partylabels(type = \"semicircle\",\n                   party_names = party_long,\n                   party_seats = seats,\n                   party_colours = colour) +\n  geom_highlight_government(government == 1, size = 4) +\n  \n  labs(title = paste0(\"Actual House of Representatives: \", input$year),\n       subtitle = paste0(\"Majority: \", majority)) +\n  theme_ggparliament(legend = FALSE) +\n  scale_colour_manual(values = usparl$colour,\n                      limits = usparl$party_short)  +\n  theme(plot.title = element_text(size = 20),\n        plot.subtitle = element_text(size = 14))\nuspropparl &lt;- propparl |&gt; \n  filter(year == input$year)\n\nuspropparl |&gt; \n  parliament_data(type = \"semicircle\", \n                  parl_rows = 10,\n                  party_seats = uspropparl$seats) |&gt; \n  ggplot(aes(x = x, y = y, colour = party_short)) +\n  geom_parliament_seats() +\n  draw_majoritythreshold(n = 218, label = TRUE, type = \"semicircle\") +\n  draw_partylabels(type = \"semicircle\",\n                   party_names = party_long,\n                   party_seats = seats,\n                   party_colours = colour) +\n  geom_highlight_government(government == 1, size = 4) +\n  \n  labs(title = paste0(\"USA House of Reps (PSR Sytem): \", input$year),\n       subtitle = \"No party would've had majority\") +\n  theme_ggparliament(legend = FALSE) +\n  scale_colour_manual(values = usparl$colour,\n                      limits = usparl$party_short) +\n  theme(plot.title = element_text(size = 20),\n        plot.subtitle = element_text(size = 14))"
  },
  {
    "objectID": "presentations/toolkit_inspection_24_nov_2023.html",
    "href": "presentations/toolkit_inspection_24_nov_2023.html",
    "title": "Toolkit for effective Inspections by Field Officers",
    "section": "",
    "text": "Link to the Presentation (PDF)\nToolkit for effective Inspections by Field Officers\n\n\n\nOther random useful links:\n\nInspecting quality of steel bars (sariya): here and here\nCentral Vigilance Commission: Tender Guidelines\nManual for Procurement of Works (GoI, Ministry of Finance), updated June 2022\nCPWD - Rates (DSR) Manual and CPWD Works Manual (2012)\nHaryana Schedule of Rates HSR by PWD B&R Haryana"
  },
  {
    "objectID": "projects/tidy_tuesday.html",
    "href": "projects/tidy_tuesday.html",
    "title": "Data Visualization Projects",
    "section": "",
    "text": "Hey there, data enthusiasts! Feast your eyes on the visualizations meticulously crafted by yours truly. This spectacle unfolds every week as part of the #TidyTuesday Movement, a data-driven extravaganza ignited by the blazing passion of the R4DS Online Learning Community. We‚Äôre not just talking about any data; we‚Äôre talking about real-world datasets that pack a punch and make learning to dance with data a riveting experience.\nBut wait, there‚Äôs more! Before you dive headfirst into this visual feast, I‚Äôve laid out the secrets behind the magic ‚Äì the code, the portal to the dataset, and a description.\nWelcome to the future of visual storytelling ‚Äì where data meets design in a symphony of awe-inspiring graphics. Let the adventure begin! üöÄüìä‚ú®"
  },
  {
    "objectID": "projects/rastermaps.html",
    "href": "projects/rastermaps.html",
    "title": "Drawing Raster Maps with ggplot2: showing Urbanization levels",
    "section": "",
    "text": "This post is inspired from the tutorial 3D map with rayshader and ggplot2 in R by Milos Popovic. Credits to this repo for most of the code shown below.\n\nStatic Map of Urbanization\n\nObtaining the map of Haryana (from India‚Äôs Official Government Map)\nSource: Survey of India Official Maps\n\n\nCode\n# Plotting the plain map of Haryana\nggplot(haryana_borders |&gt; st_simplify(dTolerance = 100)) +\n  geom_sf() +\n  ggthemes::theme_map() +\n  labs(title = \"A Map of Haryana (India) plotted with geom_sf()\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\nFigure¬†1: Using sf package to obtain, transform and plot a Map of Haryana (India). The map is plotted with geom_sf()\n\n\n\n\n\n\nObtaining Urban Cover Data\nCredits for this data goes to Copernicus Global Land Service which provides bio-geophysical products of global land surface. Using this code we get a raster file.\n\n\nCode\n# Obtaining the official data from\n# https://lcviewer.vito.be/download\n\n# A fixed initial part of the URL for data\nstart_url &lt;- \"https://s3-eu-west-1.amazonaws.com/vito.landcover.global/v3.0.1/2015/E060N40/E060N40_PROBAV_LC100_global_v3.0.1_\"\n\n# Variable part: Each year\nvar_url &lt;- 2015:2019\n\n# Fixed part of the end of the URL\nend &lt;- \"-nrt_BuiltUp-CoverFraction-layer_EPSG-4326.tif\"\n\nurls &lt;- paste0(start_url, var_url, end)\n\n# For now, focussing only on the final year data, i.e. 2019\nurls &lt;- urls[5]\n\n# for (url in urls) {\n#    download.file(\n#      url, \n#      destfile = basename(url), \n#      mode = \"wb\")\n#}\n\n\n\n\nGetting the data on Urban Cover into R\nWe can use the rast() fucntion in {terra} package to display the urban cover in R. This forms the rough data basis which we will use to later plot the object.\n\n\nCode\nurban_cover &lt;- lapply(raster_files, terra::rast)\nurban_cover_mosaic &lt;- urban_cover[[1]]\n\nplot(urban_cover_mosaic)\n\n\n\n\n\nFigure¬†2: A raw depiction of the raster data on Urban Cover Tile fetched from Copernicus Data\n\n\n\n\nNow, we can crop this raster data to the size fo the geometrical object, Haryana, in this case.\n\n\nCode\nget_urban_cover_cropped &lt;- function() {\n    # Create a Spatial Vector from haryana borders sf object\n    haryana_borders_vect &lt;- terra::vect(\n        haryana_borders\n    )\n    \n    # Cut out a part of a Spatial Raster\n    urban_cover_cropped &lt;- terra::crop(\n        urban_cover_mosaic, haryana_borders_vect,\n        snap = \"in\", mask = T\n    )\n\n    return(urban_cover_cropped)\n}\n\n# Lower Resolution to save space\nurban_cover_cropped &lt;- get_urban_cover_cropped() |&gt;\n    terra::aggregate(fact = 5) \n\nplot(urban_cover_cropped)\n\n\n\n\n\nFigure¬†3: The same raster image as above, now cropped according to the boundaries of Haryana\n\n\n\n\nLastly, we convert this raster data into a tibble, so that we can use it with ggplot2 and change it as we wish later on.\n\n\nCode\nurban_cover_df &lt;- urban_cover_cropped |&gt;\n    as.data.frame(xy = T) |&gt; \n    as_tibble()\n\nnames(urban_cover_df)[3] &lt;- \"percent_cover\"\n\n\n\n\nPlotting the Urbanization Map of Haryana with ggplot2\n\n\nCode\n# Load fonts\nfont_add_google(\"Days One\", \n                family = \"title_font\")       # Font for titles\nfont_add_google(\"Saira Extra Condensed\", \n                family = \"caption_font\")     # Font for the caption\nfont_add_google(\"Strait\", \n                family = \"body_font\")        # Font for plot text\nshowtext_auto()\n\n# Define Text Size\nts = unit(20, units = \"cm\")                             # Text Size\n\n# Caption stuff\nsysfonts::font_add(family = \"Font Awesome 6 Brands\",\n                   regular = here::here(\"docs\", \"Font Awesome 6 Brands-Regular-400.otf\"))\ngithub &lt;- \"&#xf09b\"\ngithub_username &lt;- \"aditya-dahiya\"\nxtwitter &lt;- \"&#xe61b\"\nxtwitter_username &lt;- \"@adityadahiyaias\"\nlinkedin &lt;- \"&#xf08c\"\nlinkedin_username &lt;- \"dr-aditya-dahiya-ias\"\nsocial_caption &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{github_username}  &lt;/span&gt; &lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{xtwitter_username}&lt;/span&gt; &lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{linkedin};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{linkedin_username}&lt;/span&gt;\")\n\n# Add text to plot--------------------------------------------------------------\nplot_title &lt;- \"Urbanization in Haryana (2019)\"\n\nplot_caption &lt;- paste0(\"**Data:** Copernicus Global Land Service | \", \"**Graphics:** \", social_caption)\n\ntext_col = \"#631b00\"\nbg_col = \"white\"\n\np &lt;- ggplot(urban_cover_df) +\n    geom_raster(aes(\n      x = x, \n      y = y, \n      fill = percent_cover\n      )) +\n    geom_sf(\n      data = haryana_borders,\n      fill = \"transparent\", \n      color = \"black\", \n      size = 1) +\n    paletteer::scale_fill_paletteer_c(\"grDevices::OrRd\",\n                                      direction = -1) +\n    guides(\n        fill = guide_legend(\n            title = \"Urbanized Area (%)\",\n            direction = \"horizontal\",\n            title.position = \"top\",\n            label.position = \"bottom\",\n            nrow = 1,\n            byrow = T\n        )\n    ) +\n    labs(\n      title = plot_title,\n      caption = plot_caption\n    ) +\n    ggthemes::theme_map() +\n    theme(\n      legend.position = c(0, 0.1),\n      legend.key.width = unit(15, \"mm\"),\n      plot.caption =  element_textbox(family = \"caption_font\",\n                                  hjust = 0.5,\n                                  colour = text_col,\n                                  size = 1.5 * ts),\n      plot.title   =     element_text(hjust = 0.5,\n                                  size = 6 * ts,\n                                  family = \"title_font\",\n                                  face = \"bold\",\n                                  colour = text_col,\n                                  margin = margin(0,0,0,0)),\n      plot.background =  element_rect(fill = bg_col,\n                                  color = bg_col,\n                                  linewidth = 0),\n    plot.title.position = \"plot\",\n    legend.text = element_text(size = 2 * ts,\n                             family = \"body_font\",\n                             colour = text_col,\n                             margin = margin(0,0,0,0),\n                             hjust = 0.5),\n    legend.key = element_rect(fill = bg_col,\n                            colour = bg_col),\n    legend.background = element_rect(fill = bg_col),\n    legend.title = element_text(family = \"title_font\",\n                                colour = text_col,\n                                hjust = 0.5,\n                                size = 45)\n)\n    \n\n\n\nggsave(\n  plot = p,\n  filename = here(\"projects\", \"rastermaps.png\"),\n  height = unit(10, \"cm\"),\n  width = unit(10, \"cm\"),\n  bg = \"white\"\n)\n\n\n\n\n\nFinal Plot of Urbanization in Haryana (2019)\n\n\n\n\n\nChange in Urbanization over Time\nFor this, we focus on UAE to see changes over time from 2015 to 2019. Unfortunately, the current data does not change over time, thus, there is no perceptible difference. But the code works!\n\n\nCode\nlibrary(gganimate)\n\n# Setting the CRS for projections in all following data\ncrsLONGLAT &lt;- \"+proj=longlat +datum=WGS84 +no_defs\"\n\n\nggn_borders &lt;- st_read(here(\"data\", \n                            \"uae\", \n                            \"are_admbnda_adm1_fcsc_20230515.shp\")) |&gt; \n  select(geometry) |&gt;\n  st_transform(crsLONGLAT)\n\nraster_files &lt;- list.files(\n    path = here(\"data\", \"uae\"),\n    pattern = \"BuiltUp-CoverFraction-layer_EPSG-4326.tif\",\n    full.names = T\n)\n\nurban_cover &lt;- lapply(raster_files, terra::rast)\n\n\nget_urban_cover_cropped &lt;- function(image) {\n    ggn_borders_vect &lt;- terra::vect(\n        ggn_borders\n    )\n    urban_cover_cropped &lt;- terra::crop(\n        image, ggn_borders_vect,\n        snap = \"in\", mask = T\n    )\n\n    return(urban_cover_cropped)\n}\n\nfact_res &lt;- 5\n\n# Save image for each year from 2015 to 2019\nurban2015 &lt;- get_urban_cover_cropped(urban_cover[[1]]) |&gt; \n  terra::aggregate(fact = fact_res) \nurban2016 &lt;- get_urban_cover_cropped(urban_cover[[2]]) |&gt; \n  terra::aggregate(fact = fact_res) \nurban2017 &lt;- get_urban_cover_cropped(urban_cover[[3]]) |&gt; \n  terra::aggregate(fact = fact_res) \nurban2018 &lt;- get_urban_cover_cropped(urban_cover[[4]]) |&gt; \n  terra::aggregate(fact = fact_res) \nurban2019 &lt;- get_urban_cover_cropped(urban_cover[[5]]) |&gt; \n  terra::aggregate(fact = fact_res) \n\nmake_img_df &lt;- function(image, year_coded){\n  temp &lt;- image |&gt; \n    as.data.frame(xy = T) |&gt; \n    as_tibble()\n  \n  names(temp)[3] &lt;- \"percent_cover\"\n  \n  temp &lt;- temp |&gt; \n    mutate(year = year_coded)\n  \n  return(temp)\n}\n\nurban_cover_df &lt;- bind_rows(\n  make_img_df(urban2015, 2015),\n  make_img_df(urban2015, 2016),\n  make_img_df(urban2015, 2017),\n  make_img_df(urban2015, 2018),\n  make_img_df(urban2015, 2019)\n)\n  \ng &lt;- ggplot(urban_cover_df) +\n    geom_tile(aes(\n      x = x, \n      y = y, \n      fill = percent_cover\n      )) +\n    geom_sf(\n      data = ggn_borders,\n      fill = \"transparent\", \n      color = \"black\", \n      size = 1) +\n    paletteer::scale_fill_paletteer_c(\"grDevices::OrRd\",\n                                      direction = -1) +\n    guides(\n        fill = guide_legend(\n            title = \"Urbanized Area (%)\",\n            direction = \"horizontal\",\n            title.position = \"top\",\n            label.position = \"bottom\",\n            nrow = 1,\n            byrow = T\n        )\n    ) +\n    labs(\n      title = \"Urbanization in U.A.E. during {closest_state}\"\n    ) +\n    ggthemes::theme_map() +\n    theme(\n      plot.title = element_text(hjust = 0.5,\n                                face = \"bold\",\n                                size = 18)\n    ) +\n    transition_states(states = factor(year)) +\n    enter_fade() +\n    exit_fade()\n\nanim_save(\n  animation = g,\n  filename = here(\"docs\", \"uae_urban.gif\"),\n  nframes = 20,\n  duration = 10\n)"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-46-diwali-sales",
    "href": "projects/tidy_tuesday.html#week-46-diwali-sales",
    "title": "Data Visualization Projects",
    "section": "Week 46: Diwali Sales",
    "text": "Week 46: Diwali Sales\nDiwali Sales at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-47-r-ladies-chapter-events",
    "href": "projects/tidy_tuesday.html#week-47-r-ladies-chapter-events",
    "title": "Data Visualization Projects",
    "section": "Week 47: R-Ladies Chapter Events",
    "text": "Week 47: R-Ladies Chapter Events\nR-Ladies Chapter Events at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-48-doctor-who-episodes",
    "href": "projects/tidy_tuesday.html#week-48-doctor-who-episodes",
    "title": "Data Visualization Projects",
    "section": "Week 48: Doctor Who Episodes",
    "text": "Week 48: Doctor Who Episodes\nDoctor Who Episodes at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-49-life-expectancy",
    "href": "projects/tidy_tuesday.html#week-49-life-expectancy",
    "title": "Data Visualization Projects",
    "section": "Week 49: Life Expectancy",
    "text": "Week 49: Life Expectancy\nLife Expectancy (Our World in Data) at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-50-holiday-movies",
    "href": "projects/tidy_tuesday.html#week-50-holiday-movies",
    "title": "Data Visualization Projects",
    "section": "Week 50: Holiday Movies",
    "text": "Week 50: Holiday Movies\nHoliday Movies by IMDb non-commercial datasets at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-51-holiday-episodes",
    "href": "projects/tidy_tuesday.html#week-51-holiday-episodes",
    "title": "Data Visualization Projects",
    "section": "Week 51: Holiday Episodes",
    "text": "Week 51: Holiday Episodes\nHoliday Episodes by IMDb non-commercial datasets at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-52-r-packages-structure",
    "href": "projects/tidy_tuesday.html#week-52-r-packages-structure",
    "title": "Data Visualization Projects",
    "section": "Week 52: R Packages Structure",
    "text": "Week 52: R Packages Structure\nHistorical Trends in R Package Structure and Inter-dependency on CRAN by Mark Padgham and Noam Ross at #TidyTuesday"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-1-movie-theaters-in-delhi-india",
    "href": "projects/tidy_tuesday.html#week-1-movie-theaters-in-delhi-india",
    "title": "Data Visualization Projects",
    "section": "Week 1: Movie Theaters in Delhi (India)",
    "text": "Week 1: Movie Theaters in Delhi (India)\nMovie Theatre Data for 8 Indian Cities by Harsha Devulapalli at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-2-canadian-hockey-player-birth-months",
    "href": "projects/tidy_tuesday.html#week-2-canadian-hockey-player-birth-months",
    "title": "Data Visualization Projects",
    "section": "Week 2: Canadian Hockey Player Birth Months",
    "text": "Week 2: Canadian Hockey Player Birth Months\nInspired by Are Birth Dates Still Destiny for Canadian NHL Players? by JLaw at #TidyTuesday | Code | Data\n\nCode for another graph with the same data."
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-3-us-polling-places-2012-2020",
    "href": "projects/tidy_tuesday.html#week-3-us-polling-places-2012-2020",
    "title": "Data Visualization Projects",
    "section": "Week 3: US Polling Places 2012-2020",
    "text": "Week 3: US Polling Places 2012-2020\nUS Polling Places 2012-2020 by Center for Public Integrity at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/rayshader_powerplants.html",
    "href": "projects/rayshader_powerplants.html",
    "title": "A Rayshader Map for India‚Äôs Power Plants",
    "section": "",
    "text": "Using data from , and code from Learn to Make 3D Maps with Light Bubbles using rayshader in R by Milos Popovic\n\nLoading Libraries\n\n\nCode\nlibrary(terra)     # For raster maps handling\nlibrary(sf)        # For spatial objects\nlibrary(tidyverse) # Data wrangling\nlibrary(rayshader) # Rayshader Maps\nlibrary(elevatr)   # Get elevation matrices for plotting\nlibrary(here)      # For locating working directory\nlibrary(showtext)       # Using Fonts More Easily in R Graphs\nlibrary(ggimage)        # Using Images in ggplot2\nlibrary(fontawesome)    # Social Media icons\nlibrary(ggtext)         # Markdown Text in ggplot2\n\n\n\n\nGetting the Data on Power Plants in India\n\n\nCode\n# The URL of the database\nurl &lt;- \"https://wri-dataportal-prod.s3.amazonaws.com/manual/global_power_plant_database_v_1_3.zip\"\n\n# Saving a filename for downloading the data into\nfilename &lt;- basename(url)\n\ndownload.file(\n    url = url,\n    destfile = here(\"data\", \"power_plants\", filename),\n    mode = \"wb\"\n)\n\nunzip(here(\"data\", \"power_plants\", filename))\n\nlist.files(here(\"data\", \"power_plants\"))\n\n\nWe can directly use the downloaded data from Global Power Plant Database as shown below: ‚Äì\n\n\nCode\npower_plant_df &lt;- read.csv(\n  here(\n    \"data\",\n    \"power_plants\",\n    \"global_power_plant_database.csv\"\n  )\n) |&gt; \n  as_tibble()\n\n# Getting the Power Plants data for India\ncountry_power_plant_df &lt;- power_plant_df |&gt; \n  filter(country == \"IND\") |&gt; \n  select(\n    latitude,\n    longitude,\n    primary_fuel,\n    capacity_mw,\n    commissioning_year\n    )\n\n# Converting the Points into CRS 4326\ncountry_power_plant_sf &lt;- country_power_plant_df |&gt;\n    sf::st_as_sf(\n        coords = c(\"longitude\", \"latitude\"),\n        crs = 4326\n    )\n\n\n\n\nObtaining Data on India‚Äôs States and National Borders\nGetting the official map of India by Survey of India, official Government agency.\n\n\nCode\ncountry_sf &lt;- read_sf(\n  here(\"data\", \"india_map\", \"India_State_Boundary.shp\")\n) |&gt; \n  st_simplify(dTolerance = 1000)\n\nggplot(country_sf) +\n  geom_sf() +\n  ggthemes::theme_map()\n\n\n\n\n\n\n\nCreating a digital elevation model for the Rayshader\n\n\nCode\nelev &lt;- elevatr::get_elev_raster(\n    locations = country_sf,\n    z = 1,\n    clip = \"locations\"\n)\n\nelev_lambert &lt;- elev |&gt;\n    terra::rast()\nelev_lambert[elev_lambert &lt; 0] &lt;- 0\n\nplot(elev_lambert)\n\n\n\n\n\nFigure¬†1: A simple plot of the elevation raster data for India\n\n\n\n\n\n\nCode\n# Creating a matrix of elevation points\nelmat &lt;- elev_lambert |&gt;\n    rayshader::raster_to_matrix()\n\n# Coverting as below sea level points to sea level\nelmat[elmat &lt; 0] &lt;- 0\n\n# Removing missing values of elevation and replacing\n# them with minimum elevation value\nelmat[is.na(elmat)] &lt;- min(\n    elmat,\n    na.rm = T\n)\n\n\n\n\nSelecting Power Plants that are within India‚Äôs borders\n\n\nCode\ncountry_power_plant_sf &lt;- st_transform(\n  country_power_plant_sf, \n  crs = st_crs(country_sf))\n\ncountry_points &lt;- sf::st_intersection(\n    country_power_plant_sf,\n    country_sf\n)\n\nindia_terrain &lt;- elev_lambert |&gt; \n  as.data.frame(xy = TRUE) |&gt; \n  as_tibble()\n\nnames(india_terrain)[3] &lt;- \"elevation\"\n\n\nAn interim plot: ‚Äî\n\n\nCode\n# Colours to use for different Power Plant Types\ncols_vals &lt;- c(\"#F9A01BFF\", \"#418FDEFF\", \"#BA0C2FFF\")\n\n\n# Load fonts\nfont_add_google(\"Akronim\", \n                family = \"title_font\")       # Font for titles\nfont_add_google(\"Saira Extra Condensed\", \n                family = \"caption_font\")     # Font for the caption\nfont_add_google(\"Redressed\", \n                family = \"body_font\")        # Font for plot text\nshowtext_auto()\n\nbg_col &lt;- \"white\"                   # Background Colour\ntext_col &lt;- \"#4f2a00\"                 # Colour for the text\ntext_hil &lt;- \"#4f2a00\"                 # Colour for highlighted text\n\n# Define Text Size\nts = unit(20, units = \"cm\")                             # Text Size\n\n# Caption stuff\nsysfonts::font_add(family = \"Font Awesome 6 Brands\",\n                   regular = here::here(\"docs\", \"Font Awesome 6 Brands-Regular-400.otf\"))\ngithub &lt;- \"&#xf09b\"\ngithub_username &lt;- \"aditya-dahiya\"\nxtwitter &lt;- \"&#xe61b\"\nxtwitter_username &lt;- \"@adityadahiyaias\"\nlinkedin &lt;- \"&#xf08c\"\nlinkedin_username &lt;- \"dr-aditya-dahiya-ias\"\nsocial_caption &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{github_username}  &lt;/span&gt; &lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{xtwitter_username}&lt;/span&gt; &lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{linkedin};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{linkedin_username}&lt;/span&gt;\")\n\n# Add text to plot--------------------------------------------------------------\nplot_title &lt;- \"Power Plants in India\"\n\nsubtitle_text &lt;- \"A look at Coal, Hydro and Nuclear Power Plants in India, overlaid on the terrain elevation map of India. The coal plants are concentrated in the deccan trap and central India - the site of coal beds. The Hydro-Electric Plants are mostly found in the northern part (Himalayas Mountains) or the southern hills (Western  & Eastern Ghats)\"\nplot_subtitle &lt;- paste(strwrap(subtitle_text, 100), collapse = \"\\n\")\n\nplot_caption &lt;- paste0(\"**Data:** Global Power Plant Database | \", \"**Graphics:** \", social_caption)\n\n\ng &lt;- ggplot() + \n  geom_tile(\n    data = india_terrain,\n    aes(\n      x = x,\n      y = y,\n      fill = elevation\n    )\n  ) +\n  geom_sf(\n    data = country_sf,\n    fill = \"transparent\",\n    col = \"#666666FF\"\n  ) +\n  geom_sf(\n    data = country_points |&gt; \n      filter(primary_fuel %in% c(\n        \"Coal\", \"Hydro\", \"Nuclear\"\n      )),\n    mapping = aes(\n      col = primary_fuel,\n      size = capacity_mw),\n    alpha = 0.85, \n    pch = 19\n    ) +\n  scale_x_continuous(expand = expansion(0)) +\n  scale_y_continuous(expand = expansion(0)) +\n  scale_fill_gradient2(\n    low = \"white\",\n    high = \"#802a00\",\n    mid = \"#996136FF\",\n    midpoint = 4500,\n    na.value = \"transparent\",\n    labels = scales::label_number_si(),\n    guide = guide_colourbar(\n      direction = \"horizontal\",\n      title.position = \"top\",\n      barwidth = unit(4, \"cm\"),\n      barheight = unit(2, \"mm\")\n    )) +\n  scale_colour_manual(\n    values = cols_vals,\n    guide = guide_legend(\n      direction = \"horizontal\",\n      title.position = \"top\",\n      keywidth = unit(3, \"mm\"),\n      override.aes = list(\n        size = 3\n      )\n    )\n  ) +\n  scale_size(\n    range = c(0.5, 6),\n    labels = scales::label_number_si(),\n    guide = guide_legend(\n      direction = \"horizontal\",\n      title.position = \"top\",\n      keywidth = unit(5, \"mm\"),\n      override.aes = list(\n        col = \"#996136FF\"\n      )\n    )\n  ) +\n  ggthemes::theme_map() +\n  labs(\n    size = \"Capacity (MW)\",\n    color = \"Fuel\",\n    fill  = \"Elevation (m)\",\n    title = plot_title,\n    subtitle = plot_subtitle,\n    caption = plot_caption\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    plot.caption =  element_textbox(family = \"caption_font\",\n                                    hjust = 0.5,\n                                    colour = text_col,\n                                    size = 2 * ts,\n                                    margin = margin(0,0,0.4,0,\n                                                    unit = \"cm\")),\n    plot.title   =     element_text(hjust = 0.5,\n                                    size = 11*ts,\n                                    family = \"title_font\",\n                                    face = \"bold\",\n                                    colour = text_hil,\n                                    margin = margin(1,0,0,0,\n                                                    unit = \"cm\")),\n    plot.subtitle    = element_text(hjust = 0.5,\n                                    size = 2.4 * ts,\n                                    family = \"body_font\",\n                                    colour = text_col,\n                                    margin = margin(0,0,0,0,\n                                                    unit = \"cm\"),\n                                    lineheight = 0.35),\n    plot.background =  element_rect(fill = bg_col,\n                                    color = bg_col,\n                                    linewidth = 0),\n    plot.title.position = \"plot\",\n    legend.text = element_text(size = 2 * ts,\n                               family = \"body_font\",\n                               colour = text_col,\n                               margin = margin(0,0,0,0),\n                               hjust = 0),\n    legend.title = element_text(size = 63,\n                               family = \"body_font\",\n                               colour = text_col,\n                               margin = margin(0,0,0,0,\n                                               unit = \"mm\"),\n                               hjust = 0.5),\n    legend.margin = margin(0, 0.3, 0.5, 0.3, \"cm\"),\n    legend.spacing.x = unit(1, \"mm\"),\n    legend.spacing.y = unit(1, \"mm\"),\n    legend.box = \"horizontal\",\n    legend.key = element_rect(fill = bg_col,\n                              colour = bg_col),\n    legend.background = element_rect(fill = bg_col)\n  )\n\nggsave(\n  filename = here::here(\"docs\", \"india_powerplants.png\"),\n  plot = g,\n  width = 20, \n  height = 26, \n  units = \"cm\",\n  bg = bg_col\n)\n\n\n\n\n\nFigure¬†2: Map of India with a look at Coal, Hydro and Nuclear Power Plants in India, overlaid on the terrain elevation map of India. The coal plants are concentrated in the deccan trap and central India - the site of coal beds. The Hydro-Electric Plants are mostly found in the northern part (Himalayas Mountains) or the southern hills (Western & Eastern Ghats)\n\n\n\n\nA Work in progress ‚Ä¶\nThe subsequent Code is credited to Milos Popovic in his tutorial Learn to Make 3D Maps with Light Bubbles using rayshader in R by\n\n\nCode\n# 6. POWER PLANT WITHIN BORDERS\n\n\n\n# 7. RENDER SCENE\n#----------------\n\nh &lt;- nrow(elmat)\nw &lt;- ncol(elmat)\n\nelmat |&gt;\n    rayshader::height_shade(\n        texture = colorRampPalette(\n            c(\n                \"grey90\",\n                \"grey60\"\n            )\n        )(128)\n    ) |&gt;\n    rayshader::plot_3d(\n        elmat,\n        zscale = 5,\n        solid = F,\n        shadow = T,\n        shadow_darkness = 1,\n        background = \"white\",\n        windowsize = c(w / 2, h / 2),\n        zoom = .65,\n        phi = 85,\n        theta = 0\n    )\n\n# 8. RENDER POINTS\n#-----------------\n\ncoords &lt;- sf::st_coordinates(\n    country_points\n)\n\nlong &lt;- coords[, \"X\"]\nlat &lt;- coords[, \"Y\"]\n\nrayshader::render_points(\n    lat = lat,\n    long = long,\n    extent = elev_lambert,\n    heightmap = elmat,\n    zscale = 1,\n    size = 5,\n    color = \"#F59F07\"\n)\n\n# 9. RENDER OBJECT\n#-----------------\n\nimgname &lt;- \"3d_power_plant_netherlands.png\"\n\nrayshader::render_highquality(\n    filename = imgname,\n    preview = T,\n    light = F,\n    point_radius = 7,\n    point_material = rayrender::light,\n    point_material_args = list(\n        color = \"#F59F07\",\n        intensity = 60,\n        gradient_color = \"#F5D014\"\n    ),\n    clamp_value = 2,\n    min_variance = 0,\n    sample_method = \"sobol\", #SAMPLE METHOD\n    interactive = F,\n    parallel = T\n)"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-4-educational-attainment-of-young-people-in-english-towns",
    "href": "projects/tidy_tuesday.html#week-4-educational-attainment-of-young-people-in-english-towns",
    "title": "Data Visualization Projects",
    "section": "Week 4: Educational attainment of young people in English towns",
    "text": "Week 4: Educational attainment of young people in English towns\nWhy do children and young people in smaller towns do better academically than those in larger towns? by The UK Office for National Statistics at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-4-educational-attainment-of-young-people-in-english-towns-1",
    "href": "projects/tidy_tuesday.html#week-4-educational-attainment-of-young-people-in-english-towns-1",
    "title": "Data Visualization Projects",
    "section": "Week 4: Educational attainment of young people in English towns",
    "text": "Week 4: Educational attainment of young people in English towns\nGroundhog predictions by groundhog-day.com at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-5-groundhog-day-predictions",
    "href": "projects/tidy_tuesday.html#week-5-groundhog-day-predictions",
    "title": "Data Visualization Projects",
    "section": "Week 5: Groundhog Day predictions",
    "text": "Week 5: Groundhog Day predictions\nGroundhog predictions by groundhog-day.com at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_groundhog.html",
    "href": "projects/tidy_groundhog.html",
    "title": "An interactive map of USA‚Äôs Groundhogs Day predictors",
    "section": "",
    "text": "Using data from Groundhog predictions by groundhog-day.com, first hosted at #TidyTuesday Data\n\nLoading data & libraries\n\n\nCode\nlibrary(tidyverse)      # Data Wrangling and Plotting\nlibrary(here)           # Files location and loading\nlibrary(showtext)       # Using Fonts More Easily in R Graphs\nlibrary(ggimage)        # Using Images in ggplot2\nlibrary(fontawesome)    # Social Media icons\nlibrary(ggtext)         # Markdown Text in ggplot2\nlibrary(patchwork)      # For compiling plots\nlibrary(magick)         # Work with Images and Logos\nlibrary(scales)         # ggplot2 labels and scaling\nlibrary(sf)             # Maps and converting coordinates\nlibrary(ggiraph)        # Interactive visualization\nlibrary(usmap)          # Easily plot map of USA\n\n# Loading Data\ngroundhogs &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-30/groundhogs.csv')\n\n\n# Using predictions data from 2024 (latest) with the cleaning script given \n# at https://github.com/rfordatascience/tidytuesday/blob/master/data/2024/2024-01-30/readme.md\n# Credits: @tidytuesday and @jonthegeek \n\npredictions &lt;- read_csv(here::here(\"data\", \"predictions2024.csv\"))\n\n\n\n\nData Wrangling\n\n\nCode\n# Finding the groundhogs who predicted in year 2024\nrelevant_groundhogs &lt;- predictions |&gt; \n  filter(year == 2024) |&gt; \n  pull(id) |&gt; \n  unique()\n\n# Improving tibble to use in plotting\ndf1 &lt;- groundhogs |&gt; \n  filter(id %in% relevant_groundhogs) |&gt; \n  left_join(predictions |&gt; \n            filter(year == 2024)) |&gt; \n  mutate(\n    predict = if_else(\n      shadow,\n      \"Groundhog saw its shadow: Extended Winters\",\n      \"No shadow: An Early Spring!\"),\n    predict = if_else(\n      is.na(predict),\n      \"No prediction\",\n      predict\n    )\n    )\n\n# Retaining only groundhogs within US borders + US Map transforming them\ndf2 &lt;- df1 |&gt; \n  usmap_transform(\n    input_names = c(\"longitude\", \"latitude\")\n  ) |&gt; \n  filter(country == \"USA\")\n\nimage1 &lt;- image_read(\"https://img.freepik.com/free-vector/adorable-groundhog-cartoon-with-groundhog-day-banner_1308-153480.jpg\")\n\n\n\nSome optional visualization parameters\n\n\nCode\n# Load fonts\nfont_add_google(\"Freckle Face\", \n                family = \"title_font\")       # Font for titles\nfont_add_google(\"Saira Extra Condensed\", \n                family = \"caption_font\")     # Font for the caption\nfont_add_google(\"Barlow Condensed\", \n                family = \"body_font\")        # Font for plot text\nshowtext_auto()\n\n# Icons to use in graph\n# Credits: Used code from\n\n# Creating a Colour Palette for the Visualization\nmypal &lt;- c(\"#0ab6f0\", \"grey\", \"#00990a\")\n\n# Define colours\nbg_col &lt;- \"white\"                     # Background Colour\ntext_col &lt;- \"#4f2b00\"                 # Colour for the text\ntext_hil &lt;- \"#c46c00\"                 # Colour for highlighted text\n\n\n# Define Text Size\nts = 24      # Text Size\n\n# Caption stuff\nsysfonts::font_add(family = \"Font Awesome 6 Brands\",\n                   regular = here::here(\"docs\", \"Font Awesome 6 Brands-Regular-400.otf\"))\ngithub &lt;- \"&#xf09b\"\ngithub_username &lt;- \"aditya-dahiya\"\nxtwitter &lt;- \"&#xe61b\"\nxtwitter_username &lt;- \"@adityadahiyaias\"\nsocial_caption &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{github_username}  &lt;/span&gt; &lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{xtwitter_username}&lt;/span&gt;\")\n\n# Add text to plot--------------------------------------------------------------\nplot_title &lt;- \"Groundhog Day: 2024\"\n\nsubtitle_text &lt;- \"Hover on a location to read about Groundhog's prediction.\"\nplot_subtitle &lt;- paste(strwrap(subtitle_text, 100), collapse = \"\\n\")\n\nplot_caption &lt;- paste0(\"**Data & Inspiration:** groundhog-day.com | \", \"**Graphics:** \", social_caption)\n\n\nBelow, in Figure¬†1, I use ggiraph package with usmaps package to make an interactive map of the Groundhogs in USA, along with their details and predictions.\n\n\nCode\ng1 &lt;- plot_usmap(\n  fill = \"white\",\n  col = \"darkgrey\",\n  alpha = 0.75,\n  exclude = c(\"AK\", \"HI\")\n  ) +\n  geom_point_interactive(\n    data = df2,\n    aes(\n      color = predict,\n      x = x,\n      y = y,\n      data_id = id,\n      tooltip = paste0(\n        name, \"\\n\",\n        \"(\", city, \", \", region, \")\\n\",\n        \"Predictions done so far: \", predictions_count, \"\\n\",\n        \"Prediction for 2024: \", predict\n      )\n    ),\n    size = 3,\n    alpha = 0.5\n  ) +\n  scale_colour_manual(\n    name = NULL,\n    values = mypal\n  ) +\n  guides(\n    colour = guide_legend(\n      override.aes = list(\n        size = 5,\n        keyheight = 0.5\n      )\n    )\n  ) +\n  labs(\n    title = plot_title,\n    subtitle = plot_subtitle,\n    caption = plot_caption,\n    size = NULL,\n    color = NULL\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(\n      hjust = 0.5,\n      size = 2 * ts,\n      family = \"title_font\",\n      face = \"bold\",\n      colour = text_hil,\n      margin = margin(\n        0.2, 0, 0, 0,\n        unit = \"cm\"\n      )\n    ),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      size = ts,\n      family = \"body_font\",\n      colour = text_col,\n      margin = margin(0, 0, 0, 0,\n        unit = \"cm\"\n      ),\n      lineheight = 0.9\n    ),\n    plot.background = element_rect(\n      fill = bg_col,\n      colour = bg_col,\n      linewidth = 0\n    ),\n    legend.text = element_text(\n      size = 0.7 * ts,\n      family = \"body_font\",\n      colour = text_col,\n      margin = margin(0, 0, 0, 0),\n      hjust = 0, \n      lineheight = 0.5\n    ),\n    plot.caption =  element_textbox(\n      family = \"caption_font\",\n      hjust = 0.5,\n      colour = text_col,\n      size = 0.5 * ts\n    ),\n    plot.margin = margin(0,0,0,0),\n    legend.key = element_rect(fill = \"transparent\"),\n    legend.background = element_rect(fill = \"transparent\"),\n    legend.box = \"horizontal\",\n    plot.title.position = \"plot\"\n  )\n\ng2 &lt;- df1 |&gt; \n  count(predict) |&gt; \n  as_tibble() |&gt; \n  mutate(percentage = round(100 * n / sum(n), 1)) |&gt; \n  mutate(\n    showpred = case_when(\n      predict == \"Groundhog saw its shadow: Extended Winters\" ~ \"Long Winter\",\n      predict == \"No shadow: An Early Spring!\" ~ \"Early Spring\",\n      .default = \"No prediction\"\n      )) |&gt; \n  ggplot(aes(\n    x = \"\",\n    y = n,\n    fill = showpred,\n    label = showpred,\n    data_id = predict,\n    tooltip = paste0(\n        predict, \"\\n\",\n        \"Number of Groundhogs: \", n, \"\\n\",\n        \"Percentage: \", percentage, \" %\"\n      )\n    )\n  ) +\n  geom_bar_interactive(\n    stat = \"identity\",\n    color = \"transparent\") +\n  geom_text(\n    position = position_stack(\n      vjust = 0.4\n      ),\n    size = 4.5,\n    family = \"body_font\",\n    col = text_col\n  ) +\n  coord_polar(theta = \"y\") +\n  scale_fill_manual(values = c(\"#00990a\", \"#0ab6f0\", \"grey\")) +\n  theme_void() +\n  theme(\n    legend.position = \"none\",\n    plot.background = element_rect(\n      fill = \"transparent\",\n      color = \"transparent\"\n    )\n  )\n\ng &lt;- g1 +\n  inset_element(\n    g2,\n    0, 0, 0.3, 0.3,\n    align_to = \"plot\",\n    ignore_tag = TRUE\n  ) &\n  theme()\n\ntooltip_css &lt;- \"background:white;font-family:Arial, Helvetica, sans-serif;\"\n\ngirafe(\n  ggobj = g,\n  options = list(\n    opts_hover(css = \"fill:yellow;stroke:black;stroke-width:2px;\"),\n    opts_tooltip(css = tooltip_css),\n    opts_zoom(max = 5)\n  )\n)\n\n\n\n\n\nFigure¬†1: An interactive map of USA with Groundhogs and their locations"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-5-groundhog-day-predictions-1",
    "href": "projects/tidy_tuesday.html#week-5-groundhog-day-predictions-1",
    "title": "Data Visualization Projects",
    "section": "Week 5: Groundhog Day predictions",
    "text": "Week 5: Groundhog Day predictions\nWorld heritage sites by UNESCO World Heritage Sites at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/dip_viz.html",
    "href": "projects/dip_viz.html",
    "title": "Data Visualizations from D.I.P.",
    "section": "",
    "text": "Welcome to this webpage showcasing visualizations created using ggplot2, tidyverse, and R programming language, utilizing publicly available datasets from the weekly newsletter Data Is Plural by Jeremy Singer-Vine. Here, you‚Äôll find open-source code detailing every step, from data acquisition to final rendering, with collapsible sections and annotations tailored to assist those new to ggplot2 and tidyverse. Feel free to explore the visualizations and delve into the code.\nYour feedback is greatly appreciated and can be shared at my Twitter, where these visualizations are periodically posted. Alternatively, you can click on the link provided for ‚ÄúEdit this page‚Äù or submit suggestions or pull requests on Github."
  },
  {
    "objectID": "presentations/inspections_16_feb_2024.html",
    "href": "presentations/inspections_16_feb_2024.html",
    "title": "Field Inspections for Engineering Works",
    "section": "",
    "text": "Link to the Presentation\n\n\n\nOther random useful videos:\n\nInspecting quality of steel bars (sariya): here and here\nInspecting quality of bricks: here and here.\nInspecting the quality of Interlocking Paver-Block Tiles (IPB Tiles): here and here.\n\n\n\n\nDocuments for nerds:\n\nCentral Vigilance Commission: Tender Guidelines\nManual for Procurement of Works (GoI, Ministry of Finance), updated June 2022\nCPWD - Rates (DSR) Manual and CPWD Works Manual (2012)\nHaryana Schedule of Rates HSR by PWD B&R Haryana"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-6-valentines-day-consumer-data",
    "href": "projects/tidy_tuesday.html#week-6-valentines-day-consumer-data",
    "title": "Data Visualization Projects",
    "section": "Week 6: Valentine‚Äôs Day Consumer Data",
    "text": "Week 6: Valentine‚Äôs Day Consumer Data\nValentine‚Äôs Day survey data by National Retail Federation‚Äôs Valentine‚Äôs Day Data Center at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/dip_viz.html#d.i.p-2016.09.28-county-level-and-precinct-level-results.",
    "href": "projects/dip_viz.html#d.i.p-2016.09.28-county-level-and-precinct-level-results.",
    "title": "Data Visualizations from D.I.P.",
    "section": "D.I.P 2016.09.28: County-level and precinct-level results.",
    "text": "D.I.P 2016.09.28: County-level and precinct-level results.\nFigure¬†1 shows data collected by OpenElections, supported by the Knight Foundation - a comprehensive and standardized election dataset for the United States on County-level elections results from 1990-2020.\n\n\nCode\n# Library Load-in-----------------------------------------------------------\nlibrary(tidyverse)      # Load the tidyverse package for data wrangling and plotting\nlibrary(here)           # Load the here package for managing file locations\nlibrary(showtext)       # Load showtext for easier font usage in R graphs\nlibrary(fontawesome)    # Load fontawesome for social media icons\nlibrary(ggtext)         # Load ggtext for Markdown text in ggplot2\nlibrary(ggstream)       # Load ggstream to use geom_stream()\nlibrary(colorspace)     # Load colorspace to manipulate colors\nlibrary(summarytools)   # Load summarytools to view summary information\n\n# Data Load-in-------------------------------------------------------------\n# Load the dataset either from a local file or a URL\n# uselections &lt;- read_csv(here(\"data\", \"ledb_candidatelevel.csv\"))\n\nurl &lt;- \"https://osf.io/download/tbwzd/\"\nuselections &lt;- read_csv(url)\n\n\n# Exploratory Data Analysis--------------------------------------------------\n\nuselections  # Display the contents of the 'uselections' dataset\ndfSummary(uselections) |&gt;  # Pipe the summary of 'uselections' dataset into 'view()' function for viewing in a nicer format\n  view()\n\n\n# Data Wrangling------------------------------------------------------------\n\n# Perform data wrangling operations on the 'uselections' dataset\nracedf &lt;- uselections |&gt; \n  mutate(party = case_when(\n    prob_democrat &gt; 0.5 ~ \"Democrat\",\n    prob_republican &gt; 0.5 ~ \"Republican\",\n    .default = \"Others\"\n  )) |&gt; \n  mutate(\n    race_est = case_when(\n      is.na(race_est) ~ \"other\",\n      .default = race_est\n    )\n  ) |&gt; \n  group_by(year, party, race_est) |&gt; \n  count() |&gt; \n  mutate(race_est = str_to_title(race_est)) |&gt; \n  ungroup() |&gt; \n  group_by(year) |&gt; \n  mutate(prop = n / sum(n)) |&gt; \n  mutate(party = fct(\n    party, \n    levels = c(\"Republican\", \"Democrat\", \"Others\")\n  ),\n  race_est = fct(\n    race_est,\n    levels = c(\"Caucasian\", \"Black\", \"Hispanic\", \n               \"Asian\", \"Other\")\n  )\n  )\n\n# Options & Visualization Parameters----------------------------------\n\n# Load fonts for the plot\nfont_add_google(\"Fira Sans Extra Condensed\", \n                family = \"title_font\")       # Add Fira Sans Extra Condensed font for titles\nfont_add_google(\"Saira Extra Condensed\", \n                family = \"caption_font\")     # Add Saira Extra Condensed font for captions\nfont_add_google(\"Anaheim\", \n                family = \"body_font\")        # Add Anaheim font for plot text\nshowtext_auto()  # Automatically enable showtext functionality\n\n# Define icons for use in the graph\n\n# Define colors\nbg_col &lt;- \"white\"                   # Define the background color\ntext_col &lt;- \"#655A5AFF\"             # Define the color for the text\ntext_hil &lt;- \"#655A5AFF\"             # Define the color for highlighted text\n\n# Define colors for stream graph\nfill_cols &lt;- paletteer::paletteer_d(\"fishualize::Anchoviella_lepidentostole\",\n                                    direction = -1) |&gt; \n  colorspace::lighten(0.2)\n\ncol_cols &lt;- paletteer::paletteer_d(\"fishualize::Anchoviella_lepidentostole\",\n                                   direction = -1) |&gt; \n  colorspace::darken(0.4)\n\n# Define text size\nts = unit(20, units = \"cm\")                             # Define the text size\n\n# Define caption text and social media icons\nsysfonts::font_add(family = \"Font Awesome 6 Brands\",\n                   regular = here::here(\"docs\", \"Font Awesome 6 Brands-Regular-400.otf\"))\ngithub &lt;- \"&#xf09b\"\ngithub_username &lt;- \"aditya-dahiya\"\nxtwitter &lt;- \"&#xe61b\"\nxtwitter_username &lt;- \"@adityadahiyaias\"\nsocial_caption_2 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{github_username}  &lt;/span&gt;\")\nsocial_caption_1 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{xtwitter_username}&lt;/span&gt;\")\n\n# Define plot title, subtitle, and caption\nplot_title &lt;- \"Ethnicity of candidates in USA's local elections.\"\nsubtitle_text &lt;- \"Percentage of candidates from different ethnicities fielded by the two dominant political parties in USA over last 20 years in local elections for posts of Prosecutor, Sheriff, County Executive, Mayor, School Board, County Legislature and City Council. As we can see, the share of non-Caucasian races has increased, but at different rates in different parties.\"\nplot_subtitle &lt;- paste(strwrap(subtitle_text, 100), collapse = \"\\n\")\n\nplot_caption &lt;- paste0(\n  \"**Data**: Justin de Benedictis-Kessner et al. **|** \", \n  \"**Graphics**:\",\n  social_caption_1, \n  \" **|** \",\n  \"**Code:**\", \n  social_caption_2\n)\n\n# Data Visualization----------------------------------------------------------\n\n# Create the main plot 'g' using ggplot with aesthetics defined\ng &lt;- racedf |&gt; \n  ggplot(mapping = aes(\n    x = year,\n    y = prop,\n    fill = race_est,\n    label = race_est,\n    color = race_est\n  )) +\n\n  # Add the stream geom to represent the data\n  geom_stream(\n    type = \"proportional\",\n    alpha = 0.3) +\n\n  # Add labels to the stream geom\n  geom_stream_label(\n    type = \"proportional\",\n    hjust = \"inward\",\n    size = 0.7 * ts,\n    family = \"body_font\"\n  ) +\n\n  # Add facets to split the data by 'party'\n  facet_wrap(~ party, nrow = 1) +\n\n  # Adjust the x-axis scale\n  scale_x_continuous(\n    expand = expansion(0),\n    breaks = seq(1990, 2020, 5)\n  ) +\n\n  # Adjust the y-axis scale\n  scale_y_continuous(\n    expand = expansion(0),\n    labels = scales::label_percent()\n  ) +\n\n  # Manually set color values for aesthetics\n  scale_color_manual(values = col_cols) +\n\n  # Manually set fill values for aesthetics\n  scale_fill_manual(values = fill_cols) +\n\n  # Add plot titles, subtitle, and caption\n  labs(\n    title = plot_title,\n    subtitle = plot_subtitle,\n    caption = plot_caption,\n    x = NULL,\n    y = \"Percentage of candidates fielded by the Party\"\n  ) +\n\n  # Apply minimal theme to the plot\n  theme_minimal() +\n\n  # Customize theme elements\n  theme(\n    legend.position = \"none\",\n    panel.grid.major.y = element_line(\n      linetype = 2\n    ),\n    panel.grid.minor.y = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    plot.caption =  element_textbox(family = \"caption_font\",\n                                    hjust = 0.5,\n                                    colour = text_col,\n                                    size = 1.5 * ts,\n                                    margin = margin(1,0,0,0,\n                                                    unit = \"cm\")),\n    plot.title   =     element_text(hjust = 0.5,\n                                    size = 6 * ts,\n                                    family = \"title_font\",\n                                    face = \"bold\",\n                                    colour = text_hil,\n                                    margin = margin(2,0,0.5,0,\n                                                    unit = \"cm\")),\n    plot.subtitle    = element_text(hjust = 0.5,\n                                    size = 3 * ts,\n                                    family = \"body_font\",\n                                    colour = text_col,\n                                    margin = margin(5,0,2,0),\n                                    lineheight = 0.35),\n    plot.background =  element_rect(fill = bg_col,\n                                    color = bg_col,\n                                    linewidth = 0),\n    axis.text.y = element_text(size = 2.5 * ts,\n                             family = \"title_font\",\n                             colour = text_col,\n                             face = \"bold\",\n                             margin = margin(0,0,0,0)),\n    axis.text.x = element_text(size = 1.5 * ts,\n                               family = \"body_font\",\n                               colour = text_col,\n                               face = \"bold\",\n                               margin = margin(0,0,0,0)),\n    axis.title = element_text(size = 3 * ts,\n                              family = \"body_font\",\n                              colour = text_col,\n                              face = \"bold\",\n                              margin = margin(0,0,0,0)),\n    strip.text = element_text(hjust = 0.5,\n                              family = \"title_font\",\n                              face = \"bold\",\n                              colour = text_col,\n                              size = 5 * ts,\n                              margin = margin(1,0,0,0,\n                                              unit = \"cm\")),\n    plot.title.position = \"plot\"\n)\n\n\n# Image Saving----------------------------------------------------------------\n\n# Save the plot as an image file\nggsave(\n  filename = here::here(\"docs\", \"dip_uselections.png\"),\n  plot = g,\n  width = 30, \n  height = 30, \n  units = \"cm\",\n  bg = bg_col\n)\n\n\n\n\n\n\n\n\nFigure¬†1: Share of different ethnicities amongst the candidates fielded by the major USA political parties in local elections."
  },
  {
    "objectID": "projects/dip_viz.html#d.i.p.-2024.01.31-edition-military-surplus",
    "href": "projects/dip_viz.html#d.i.p.-2024.01.31-edition-military-surplus",
    "title": "Data Visualizations from D.I.P.",
    "section": "D.I.P. 2024.01.31 edition: Military surplus",
    "text": "D.I.P. 2024.01.31 edition: Military surplus\nVisualizing the CRS Report for Congress: Excess Defense Articles: Grants and Sales to Allies and Friendly Countries in Figure¬†2\n\n\nCode\n# ==============================================================================#\n# Library Load-in---------------------------------------------------------------\n# ==============================================================================#\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(janitor)\nlibrary(rnaturalearth)\nlibrary(ggthemes)\nlibrary(scales)\nlibrary(sf)\nlibrary(patchwork)\nlibrary(fontawesome)\nlibrary(ggtext)\nlibrary(showtext)\n\n\n# ==============================================================================#\n# Data Load-in------------------------------------------------------------------\n# ==============================================================================#\nusdef &lt;- openxlsx::read.xlsx(\"https://www.dsca.mil/sites/default/files/EDA_Public_Report_2020-06-15.xlsx\") |&gt; \n  as_tibble()\n\n\n# ==============================================================================#\n# Data Wrangling----------------------------------------------------------------\n# ==============================================================================#\n\ndf &lt;- usdef |&gt; \n  clean_names() |&gt; \n  select(fiscal_year_of_request,\n         country_transfer_to,\n         total_delivered_qty,\n         total_current_value) |&gt; \n  mutate(total_delivered_qty = as.numeric(total_delivered_qty)) |&gt; \n  filter(!is.na(total_delivered_qty)) |&gt; \n  filter(total_delivered_qty &gt;= 1)\n\ncountries &lt;- df |&gt; \n  group_by(country_transfer_to) |&gt; \n  summarise(total_current_value = sum(total_current_value)) |&gt; \n  arrange(desc(total_current_value))\n\nselect_con &lt;- countries |&gt; \n  slice_head(n = 10) |&gt; \n  pull(country_transfer_to)\n\ndf1 &lt;- df |&gt; \n  mutate(country = if_else(\n    country_transfer_to %in% select_con,\n    country_transfer_to,\n    \"Others\"\n  )) |&gt; \n  group_by(fiscal_year_of_request, country) |&gt; \n  summarize(total = sum(total_current_value))\n\n\ndf2 &lt;- usdef |&gt; \n  clean_names() |&gt; \n  select(-c(\n    transfer_authority, implementing_agency, item_description, status, status_date,\n    qty_accepted, qty_allocated, qty_rejected, total_acquisition_value\n  )) |&gt; \n  mutate(total_delivered_qty = as.numeric(total_delivered_qty)) |&gt; \n  mutate(total_delivered_qty = if_else(\n    (is.na(total_delivered_qty) | total_delivered_qty == 0),\n    0,\n    total_delivered_qty\n  )) |&gt; \n  mutate(total_current_value = if_else(\n    total_delivered_qty == 0,\n    1,\n    total_current_value\n  )) |&gt; \n  rename(year = fiscal_year_of_request,\n         country = country_transfer_to) |&gt; \n  group_by(country) |&gt; \n  summarise(total_value = sum(total_current_value))\n\n\nmapdf &lt;- ne_countries(\n  type = \"countries\",\n  continent = c(\"asia\", \"africa\", \"europe\", \"oceania\", \n                \"north america\", \"south america\"),\n  returnclass = \"sf\",\n  scale = \"large\"\n) |&gt; \n  st_transform(crs = st_crs(\"ESRI:54030\")) |&gt; \n  mutate(country = admin)\n\n# ==============================================================================#\n# Options & Visualization Parameters--------------------------------------------\n# ==============================================================================#\n\n# Load fonts\nfont_add_google(\"Gotu\",\n                family = \"title_font\"\n) # Font for titles\nfont_add_google(\"Saira Extra Condensed\",\n                family = \"caption_font\"\n) # Font for the caption\nfont_add_google(\"Abel\",\n                family = \"body_font\"\n) # Font for plot text\nshowtext_auto()\n\n# Define colours\nbg_col &lt;- \"#fff1d4\"  # Background Colour\ntext_col &lt;- \"#753501\" # Colour for the text\ntext_hil &lt;- \"#b85200\" # Colour for highlighted text\n\n# Define Text Size\nts &lt;- unit(10, units = \"cm\") # Text Size\n\n# Caption stuff\nsysfonts::font_add(\n  family = \"Font Awesome 6 Brands\",\n  regular = here::here(\"docs\", \"Font Awesome 6 Brands-Regular-400.otf\")\n)\ngithub &lt;- \"&#xf09b\"\ngithub_username &lt;- \"aditya-dahiya\"\nxtwitter &lt;- \"&#xe61b\"\nxtwitter_username &lt;- \"@adityadahiyaias\"\nsocial_caption_1 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{github_username}  &lt;/span&gt;\")\nsocial_caption_2 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{xtwitter_username}&lt;/span&gt;\")\n\n# Add text to plot--------------------------------------------------------------\nplot_title &lt;- \"USA's Excess Defense Articles' global sales\"\nplot_caption &lt;- paste0(\"**Data:** CRS Report for Congress. Excess Defense Articles: Grants and Sales to Allies and Friendly Countries\", \" | \", \" **Code:** \", social_caption_1, \" | \", \" **Graphics:** \", social_caption_2)\nsubtitle_text &lt;- \"This map visualizes the distribution of U.S. Excess Defense Articles (EDA) sales at reduced prices to allied and friendly nations. Highlighting top recipients like Israel, Morocco, and the UAE, the graph illustrates the strategic allocation of military equipment to support modernization efforts, peacekeeping missions, and counter-narcotics operations worldwide.\"\nplot_subtitle &lt;- str_wrap(subtitle_text, width = 170)\n# ==============================================================================#\n# Data Visualization------------------------------------------------------------\n# ==============================================================================#\n\n# Combining the World Map data and Sales Data-----------------------------------\n\ng1 &lt;- mapdf |&gt; \n  left_join(\n    df2,\n    by = join_by(country == country)\n  ) |&gt; ggplot(aes(\n    fill = total_value\n  )) +\n  geom_sf(linewidth = 0.1) +\n  paletteer::scale_fill_paletteer_c(\n    \"ggthemes::Orange\",\n    na.value = \"white\",\n    trans = \"log10\",\n    labels = scales::label_number(\n      prefix = \"$\",\n      scale_cut = cut_short_scale()\n    ),\n    name = \"Total Value of items sold (2010-2019)\") +\n  guides(\n    fill = guide_colorbar(\n      title = \"Total Value of items sold (2010-2019)\",\n      title.position = \"top\",\n      title.theme = element_blank(),\n      label.theme = element_text(\n        family = \"body_font\",\n        colour = text_col,\n        size = 3 * ts,\n        margin = margin(0,0,0,0)\n      ),\n      title.hjust = 0.5,\n      barwidth = unit(7, \"cm\"),\n      barheight = unit(0.3, \"cm\"),\n      direction = \"horizontal\",\n      frame.colour = bg_col\n    )\n  ) +\n  labs(\n    title = plot_title,\n    subtitle = plot_subtitle,\n    caption = plot_caption\n  ) +\n  theme_map() +\n  theme(legend.position = c(0.45, 0.01)) +\n  theme(\n    plot.caption = element_textbox(\n      family = \"caption_font\",\n      hjust = 0.5,\n      colour = text_col,\n      size = 3 * ts,\n      margin = margin(0.4, 0, 0, 0.5,\n                      unit = \"cm\"\n      )\n    ),\n    plot.title = element_text(\n      hjust = 0.5,\n      size = 11 * ts,\n      family = \"title_font\",\n      face = \"bold\",\n      colour = text_hil,\n      margin = margin(0, 0, 0.5, 0,\n                      unit = \"cm\"\n      )\n    ),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      size = 4 * ts,\n      family = \"body_font\",\n      colour = text_col,\n      margin = margin(0, 0, 0, 0,\n                      unit = \"cm\"\n      ),\n      lineheight = 0.35\n    ),\n    plot.background = element_rect(\n      fill = bg_col,\n      color = bg_col,\n      linewidth = 0\n    ),\n    plot.margin = margin(0,0,0,0),\n    legend.background = element_rect(\n      fill = bg_col,\n      color = bg_col\n    ),\n    panel.background = element_rect(\n      fill = bg_col,\n      colour = bg_col\n    )\n  )\n\n\ng2 &lt;- countries |&gt; \n  slice_max(order_by = total_current_value, n = 10) |&gt; \n  mutate(country_transfer_to = if_else(\n    country_transfer_to == \"United Arab Emirates\",\n    \"UAE\",\n    country_transfer_to\n  )) |&gt; \n  ggplot(aes(x = total_current_value,\n             y = reorder(country_transfer_to,\n                         -total_current_value),\n             label = country_transfer_to,\n             fill = total_current_value)) +\n  geom_col(col = \"black\",\n           linewidth = 0.1) +\n  geom_text(\n    aes(x = 1e6),\n    hjust = 0,\n    vjust = 0.5,\n    family = \"caption_font\",\n    size = 1 * ts,\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    expand = expansion(0, 0),\n    labels = label_number(\n      prefix = \"$\",\n      scale_cut = cut_short_scale(),\n    ),\n    breaks = c(0, 2e8, 4e8),\n    limits = c(0, 4.5e8)\n  ) +\n  paletteer::scale_fill_paletteer_c(\n    \"ggthemes::Orange\",\n    na.value = \"white\",\n    trans = \"log10\",\n    labels = scales::label_number(\n      prefix = \"$\",\n      scale_cut = cut_short_scale()\n    ),\n    limits = c(1, 4e8)\n    ) +\n  labs(title = \"Highest sales\") +\n  theme_void() +\n  theme(\n    legend.position = \"none\",\n    plot.margin = margin(0,0,0,0),\n    plot.title = element_text(\n      hjust = 0,\n      size = 7 * ts,\n      family = \"body_font\",\n      colour = text_col,\n      margin = margin(0, 0, 0.2, 0,\n                      unit = \"cm\")\n    ),\n    axis.text.x = element_text(\n      family = \"body_font\",\n      size = 3 * ts,\n      color = text_col,\n      hjust = 0\n    ),\n    axis.ticks.x = element_line()\n  )\ng2\ng &lt;- g1 + \n  patchwork::inset_element(\n    g2,\n    top = 0.54,\n    left = 0,\n    right = 0.35,\n    bottom = 0\n  ) +\n  plot_annotation(\n    theme = theme(\n      plot.background = element_rect(\n        fill = bg_col,\n        colour = bg_col\n      )\n    )\n  )\n\n# =============================================================================#\n# Image Saving-----------------------------------------------------------------\n# =============================================================================#\n\n\nggsave(\n  filename = here::here(\"docs\", \"dip_us_arms_export.png\"),\n  plot = g,\n  width = 30,\n  height = 18,\n  units = \"cm\",\n  bg = bg_col\n)\n\n\n\n\n\n\n\n\nFigure¬†2: This world map visualizes the distribution of U.S. Excess Defense Articles (EDA) sales at reduced prices to allied and friendly nations. Highlighting top recipients like Israel, Morocco, and the UAE, the graph illustrates the strategic allocation of military equipment to support modernization efforts, peacekeeping missions, and counter-narcotics operations worldwide."
  },
  {
    "objectID": "projects/dip_viz.html#d.i.p.-2024.01.31-military-surplus",
    "href": "projects/dip_viz.html#d.i.p.-2024.01.31-military-surplus",
    "title": "Data Visualizations from D.I.P.",
    "section": "D.I.P. 2024.01.31: Military surplus",
    "text": "D.I.P. 2024.01.31: Military surplus\nVisualizing the CRS Report for Congress: Excess Defense Articles: Grants and Sales to Allies and Friendly Countries in Figure¬†2\n\n\nCode\n# ==============================================================================#\n# Library Load-in---------------------------------------------------------------\n# ==============================================================================#\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(janitor)\nlibrary(rnaturalearth)\nlibrary(ggthemes)\nlibrary(scales)\nlibrary(sf)\nlibrary(patchwork)\nlibrary(fontawesome)\nlibrary(ggtext)\nlibrary(showtext)\n\n\n# ==============================================================================#\n# Data Load-in------------------------------------------------------------------\n# ==============================================================================#\nusdef &lt;- openxlsx::read.xlsx(\"https://www.dsca.mil/sites/default/files/EDA_Public_Report_2020-06-15.xlsx\") |&gt;\n  as_tibble()\n\n\n# ==============================================================================#\n# Data Wrangling----------------------------------------------------------------\n# ==============================================================================#\n\ndf &lt;- usdef |&gt;\n  clean_names() |&gt;\n  select(\n    fiscal_year_of_request,\n    country_transfer_to,\n    total_delivered_qty,\n    total_current_value\n  ) |&gt;\n  mutate(total_delivered_qty = as.numeric(total_delivered_qty)) |&gt;\n  filter(!is.na(total_delivered_qty)) |&gt;\n  filter(total_delivered_qty &gt;= 1)\n\ncountries &lt;- df |&gt;\n  group_by(country_transfer_to) |&gt;\n  summarise(total_current_value = sum(total_current_value)) |&gt;\n  arrange(desc(total_current_value))\n\nselect_con &lt;- countries |&gt;\n  slice_head(n = 10) |&gt;\n  pull(country_transfer_to)\n\ndf1 &lt;- df |&gt;\n  mutate(country = if_else(\n    country_transfer_to %in% select_con,\n    country_transfer_to,\n    \"Others\"\n  )) |&gt;\n  group_by(fiscal_year_of_request, country) |&gt;\n  summarize(total = sum(total_current_value))\n\n\ndf2 &lt;- usdef |&gt;\n  clean_names() |&gt;\n  select(-c(\n    transfer_authority, implementing_agency, item_description, status, status_date,\n    qty_accepted, qty_allocated, qty_rejected, total_acquisition_value\n  )) |&gt;\n  mutate(total_delivered_qty = as.numeric(total_delivered_qty)) |&gt;\n  mutate(total_delivered_qty = if_else(\n    (is.na(total_delivered_qty) | total_delivered_qty == 0),\n    0,\n    total_delivered_qty\n  )) |&gt;\n  mutate(total_current_value = if_else(\n    total_delivered_qty == 0,\n    1,\n    total_current_value\n  )) |&gt;\n  rename(\n    year = fiscal_year_of_request,\n    country = country_transfer_to\n  ) |&gt;\n  group_by(country) |&gt;\n  summarise(total_value = sum(total_current_value))\n\n\nmapdf &lt;- ne_countries(\n  type = \"countries\",\n  continent = c(\n    \"asia\", \"africa\", \"europe\", \"oceania\",\n    \"north america\", \"south america\"\n  ),\n  returnclass = \"sf\",\n  scale = \"large\"\n) |&gt;\n  st_transform(crs = st_crs(\"ESRI:54030\")) |&gt;\n  mutate(country = admin)\n\n\n# =============================================================================#\n# Additional Data Wrangling-----------------------------------------------------\n# =============================================================================#\nlibrary(tidytext)\n\nadd_stop_words &lt;- tibble(\n  word = c(\n    \"AND\", \"EQUIPMENT\", \"CARGO\",\n    \"UTILITY\", \"TON\", \"5T\", \"CTG\",\n    \"1\", \"4\", \"W\", \"SUPPLIES\", \"COMPONENTS\",\n    \"CAL\", \"EQUIP\", \"T\", \"50\", \"PARTS\", \"2.5T\",\n    \"MRAP\", \"SUPPORT\", \"2\"\n  )\n)\n\narticles &lt;- usdef |&gt;\n  clean_names() |&gt;\n  select(item_description) |&gt;\n  unnest_tokens(\n    output = \"word\",\n    input = item_description,\n    to_lower = FALSE\n  ) |&gt;\n  anti_join(stop_words) |&gt;\n  anti_join(add_stop_words) |&gt;\n  count(word, sort = TRUE)\n\nimp_art &lt;- articles |&gt;\n  slice_max(order_by = n, n = 7) |&gt;\n  pull(word)\n\n# Preparing graphs for the top 7 articles of sale\nplot_item &lt;- function(i) {\n  pattern1 &lt;- c(\n    imp_art[i],\n    imp_art[i] |&gt; str_to_lower(),\n    imp_art[i] |&gt; str_to_title()\n  )\n  temp &lt;- usdef |&gt;\n    clean_names() |&gt;\n    filter(\n      str_detect(\n        string = item_description,\n        pattern = paste0(pattern1, collapse = \" | \")\n      )\n    )\n  tg1 &lt;- temp |&gt;\n    filter(total_delivered_qty &gt; 0) |&gt;\n    group_by(country_transfer_to) |&gt;\n    summarise(\n      total = sum(total_acquisition_value)\n    ) |&gt;\n    arrange(desc(total)) |&gt;\n    slice_max(order_by = total, n = 5) |&gt;\n    ggplot(aes(\n      x = total,\n      y = reorder(\n        country_transfer_to,\n        total\n      )\n    )) +\n    geom_col(\n      fill = text_col,\n      col = \"black\",\n      linewidth = 0.1\n    ) +\n    labs(\n      x = NULL,\n      y = NULL,\n      title = imp_art[i]\n    ) +\n    theme_minimal() +\n    theme(\n      axis.ticks.y = element_blank(),\n      legend.position = \"none\",\n      plot.margin = margin(0, 0, 0, 0),\n      plot.title = element_text(\n        hjust = 0,\n        size = 3 * ts,\n        family = \"body_font\",\n        colour = text_hil,\n        margin = margin(0.2, 0, 0, 0,\n          unit = \"cm\"\n        )\n      ),\n      axis.text.x = element_text(\n        family = \"body_font\",\n        size = 2 * ts,\n        color = text_col,\n        hjust = 0\n      ),\n      axis.ticks.x = element_line(),\n      axis.text.y = element_text(\n        vjust = 0.5,\n        hjust = 1,\n        family = \"caption_font\",\n        size = 2.5 * ts,\n        color = text_col\n      ),\n      panel.grid.minor.x = element_blank(),\n      panel.grid.major.x = element_line(\n        linetype = 2,\n        linewidth = 0.1,\n        color = text_hil\n      ),\n      panel.grid.major.y = element_blank(),\n      panel.grid.minor.y = element_blank()\n    )\n  return(tg1)\n}\n\n# =============================================================================#\n# Options & Visualization Parameters--------------------------------------------\n# =============================================================================#\n\n# Load fonts\nfont_add_google(\"Gotu\",\n  family = \"title_font\"\n) # Font for titles\nfont_add_google(\"Saira Extra Condensed\",\n  family = \"caption_font\"\n) # Font for the caption\nfont_add_google(\"Abel\",\n  family = \"body_font\"\n) # Font for plot text\nshowtext_auto()\n\n# Define colours\nbg_col &lt;- \"#fff1d4\" # Background Colour\ntext_col &lt;- \"#753501\" # Colour for the text\ntext_hil &lt;- \"#b85200\" # Colour for highlighted text\n\n# Define Text Size\nts &lt;- unit(10, units = \"cm\") # Text Size\n\n# Caption stuff\nsysfonts::font_add(\n  family = \"Font Awesome 6 Brands\",\n  regular = here::here(\"docs\", \"Font Awesome 6 Brands-Regular-400.otf\")\n)\ngithub &lt;- \"&#xf09b\"\ngithub_username &lt;- \"aditya-dahiya\"\nxtwitter &lt;- \"&#xe61b\"\nxtwitter_username &lt;- \"@adityadahiyaias\"\nsocial_caption_1 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{github_username}  &lt;/span&gt;\")\nsocial_caption_2 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{xtwitter_username}&lt;/span&gt;\")\n\n# Add text to plot--------------------------------------------------------------\nplot_title &lt;- \"USA's Excess Defense Articles' global sales\"\nplot_caption &lt;- paste0(\"**Data:** CRS Report for Congress. Excess Defense Articles: Grants and Sales to Allies and Friendly Countries\", \" | \", \" **Code:** \", social_caption_1, \" | \", \" **Graphics:** \", social_caption_2)\nsubtitle_text &lt;- \"This map visualizes the distribution of U.S. Excess Defense Articles (EDA) sales at reduced prices to allied and friendly nations. Highlighting top recipients like Israel, Morocco, and the UAE, the graph illustrates the strategic allocation of military equipment to support modernization efforts, peacekeeping missions, and counter-narcotics operations worldwide.\"\nplot_subtitle &lt;- str_wrap(subtitle_text, width = 170)\n\n# ==============================================================================#\n# Data Visualization------------------------------------------------------------\n# ==============================================================================#\n\n# Combining the World Map data and Sales Data-----------------------------------\n\ng1 &lt;- mapdf |&gt;\n  left_join(\n    df2,\n    by = join_by(country == country)\n  ) |&gt;\n  ggplot(aes(\n    fill = total_value\n  )) +\n  geom_sf(linewidth = 0.1) +\n  paletteer::scale_fill_paletteer_c(\n    \"ggthemes::Orange\",\n    na.value = \"white\",\n    trans = \"log10\",\n    labels = scales::label_number(\n      prefix = \"$\",\n      scale_cut = cut_short_scale()\n    ),\n    name = \"Total Value of items sold (2010-2019)\"\n  ) +\n  guides(\n    fill = guide_colorbar(\n      title = \"Total Value of items sold (2010-2019)\",\n      title.position = \"top\",\n      title.theme = element_blank(),\n      label.theme = element_text(\n        family = \"body_font\",\n        colour = text_col,\n        size = 3 * ts,\n        margin = margin(0, 0, 0, 0)\n      ),\n      title.hjust = 0.5,\n      barwidth = unit(7, \"cm\"),\n      barheight = unit(0.3, \"cm\"),\n      direction = \"horizontal\",\n      frame.colour = bg_col\n    )\n  ) +\n  labs(\n    title = plot_title,\n    subtitle = plot_subtitle,\n    caption = plot_caption\n  ) +\n  theme_map() +\n  theme(legend.position = c(0.45, 0.01)) +\n  theme(\n    plot.caption = element_textbox(\n      family = \"caption_font\",\n      hjust = 0.5,\n      colour = text_col,\n      size = 3 * ts,\n      margin = margin(0.4, 0, 0, 0.5,\n        unit = \"cm\"\n      )\n    ),\n    plot.title = element_text(\n      hjust = 0.5,\n      size = 11 * ts,\n      family = \"title_font\",\n      face = \"bold\",\n      colour = text_hil,\n      margin = margin(0, 0, 0.5, 0,\n        unit = \"cm\"\n      )\n    ),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      size = 4 * ts,\n      family = \"body_font\",\n      colour = text_col,\n      margin = margin(0, 0, 0, 0,\n        unit = \"cm\"\n      ),\n      lineheight = 0.35\n    ),\n    plot.background = element_rect(\n      fill = bg_col,\n      color = bg_col,\n      linewidth = 0\n    ),\n    plot.margin = margin(0, 0, 0, 0),\n    legend.background = element_rect(\n      fill = \"transparent\",\n      color = \"transparent\"\n    ),\n    panel.background = element_rect(\n      fill = \"transparent\",\n      colour = \"transparent\"\n    )\n  )\n\n\ng2 &lt;- countries |&gt;\n  slice_max(order_by = total_current_value, n = 10) |&gt;\n  mutate(country_transfer_to = if_else(\n    country_transfer_to == \"United Arab Emirates\",\n    \"UAE\",\n    country_transfer_to\n  )) |&gt;\n  ggplot(aes(\n    x = total_current_value,\n    y = reorder(\n      country_transfer_to,\n      total_current_value\n    )\n    )) +\n  geom_col(\n    col = \"black\",\n    linewidth = 0.1,\n    fill = text_col\n  ) +\n  scale_x_reverse(\n    expand = expansion(0, 0),\n    labels = label_number(\n      prefix = \"$\",\n      scale_cut = cut_short_scale(),\n    ),\n    position = \"top\"\n  ) +\n  scale_y_discrete(\n    position = \"right\"\n  ) +\n  labs(title = \"TOTAL SALES\", \n       x = NULL, y = NULL) +\n  theme_minimal() +\n  theme(\n    axis.ticks.y = element_blank(),\n    legend.position = \"none\",\n    plot.margin = margin(0, 0, 0, 0),\n    plot.title = element_text(\n      hjust = 1,\n      size = 5 * ts,\n      family = \"body_font\",\n      colour = text_hil,\n      margin = margin(0, 0, 0, 0,\n                      unit = \"cm\"\n      )\n    ),\n    axis.text.x = element_text(\n      family = \"body_font\",\n      size = 2 * ts,\n      color = text_col,\n      hjust = 0.5\n    ),\n    axis.ticks.x = element_line(),\n    axis.text.y = element_text(\n      vjust = 0.5,\n      hjust = 1,\n      family = \"caption_font\",\n      size = 2.5 * ts,\n      color = text_col\n    ),\n    panel.grid = element_blank()\n  )\n\n\ng3 &lt;- plot_item(6) +\n  theme(\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank()\n  ) +\n  scale_x_continuous(\n    expand = expansion(0),\n    labels = label_number(\n      prefix = \"$\",\n      scale_cut = cut_short_scale()\n    ),\n    limits = c(0, 3e8),\n    breaks = c(0, 1e8)\n  ) \ng4 &lt;- plot_item(7) +\n  theme(\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank()\n  ) +\n  scale_x_continuous(\n    expand = expansion(0),\n    labels = label_number(\n      prefix = \"$\",\n      scale_cut = cut_short_scale()\n    ),\n    limits = c(0, 3e8),\n    breaks = c(0, 1e8)\n  ) \ng5 &lt;- plot_item(1) + \n  theme(\n    axis.text.x = element_blank(), \n    axis.ticks.x = element_blank()\n  ) +\n  scale_x_continuous(\n    expand = expansion(0),\n    labels = label_number(\n      prefix = \"$\",\n      scale_cut = cut_short_scale()\n    ),\n    limits = c(0, 3e8),\n    breaks = c(0, 1e8, 2e8)\n  ) \ng6 &lt;- plot_item(2) +\n  scale_x_continuous(\n    expand = expansion(0),\n    labels = label_number(\n      prefix = \"$\",\n      scale_cut = cut_short_scale()\n    ),\n    limits = c(0, 3e8)\n  ) \n\ng7 &lt;- g3 + g4 + g5 + g6 +\n  plot_layout(ncol = 1)\n\ng &lt;- g1 +\n  patchwork::inset_element(\n    g7,\n    top = 0.95,\n    left = 0,\n    right = 0.3,\n    bottom = 0,\n    on_top = TRUE\n  ) +\n  patchwork::inset_element(\n    g2,\n    top = 0.95,\n    bottom = 0.2,\n    right = 1,\n    left = 0.86,\n    on_top = TRUE\n  ) +\n  plot_annotation(\n    theme = theme(\n      plot.background = element_rect(\n        colour = bg_col,\n        fill = bg_col\n      )\n    )\n  )\n\n# =============================================================================#\n# Image Saving-----------------------------------------------------------------\n# =============================================================================#\n\n\nggsave(\n  filename = here::here(\"docs\", \"dip_us_arms_export.png\"),\n  plot = g,\n  width = 30,\n  height = 18,\n  units = \"cm\",\n  bg = bg_col\n)\n\n\n\n\n\n\n\n\nFigure¬†2: This world map visualizes the distribution of U.S. Excess Defense Articles (EDA) sales at reduced prices to allied and friendly nations. Highlighting top recipients like Israel, Morocco, and the UAE, the graph illustrates the strategic allocation of military equipment to support modernization efforts, peacekeeping missions, and counter-narcotics operations worldwide."
  },
  {
    "objectID": "projects/dip_viz.html#d.i.p.-2024.02.21-self-driving-stats.",
    "href": "projects/dip_viz.html#d.i.p.-2024.02.21-self-driving-stats.",
    "title": "Data Visualizations from D.I.P.",
    "section": "D.I.P. 2024.02.21: Self-driving stats.",
    "text": "D.I.P. 2024.02.21: Self-driving stats.\nA graphical analysis of Autonomous Vehicles‚Äô (AV) Testing Data (released by the State of California‚Äôs Department of Motor Vehicles) in Figure¬†3 reveals the performance of various AV Manufacturers.\n\n\nCode\n# =============================================================================#\n# About the Dataset-------------------------------------------------------------\n# =============================================================================#\n\n# Credit: State of California, Department of Motor Vehicles\n# https://www.dmv.ca.gov/portal/\n# https://twitter.com/ca_dmv\n# @CA_DMV\n\n# To test or deploy self-driving cars on California's public roads, companies \n# must obtain a permit from the state DMV's Autonomous Vehicles Program. As part \n# of the permit requirements, these companies are obliged to submit yearly \n# reports detailing the frequency of instances where their vehicles exited \n# autonomous mode during tests. This includes cases resulting from technology \n# failures or situations demanding manual intervention by the test driver/\n# operator for safety reasons. These disengagement reports include information \n# such as the company name, permit number, VIN, monthly mileage, and annual\n#  disengagements for each vehicle, even if there were none. \n#  \n#  Additionally, for each disengagement, the reports provide details such as the \n#  vehicle involved, date of occurrence, initiator of the disengagement (whether \n#  it was the vehicle itself, the test driver, remote operator, or passenger),\n#  type of location, and a brief summary of the event.\n\n# Source: https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/disengagement-reports/\n\n# DISENGAGEMENT REPORTS\n# Autonomous vehicle makers participating in the Autonomous Vehicle Tester (AVT) \n# Program and AVT Driverless Program must annually submit reports detailing the \n# frequency of instances where their vehicles exited autonomous mode during \n# testing. This encompasses occurrences triggered by technological malfunctions \n# or scenarios necessitating manual intervention by the test driver/operator for \n# safe operation.\n\n\n# 2023 Disengagement Reports\n\n# 2023 Autonomous Vehicle Disengagement Reports (CSV)\nurl1 &lt;- \"https://www.dmv.ca.gov/portal/file/2023-autonomous-vehicle-disengagement-reports-csv/\"\n\n# 2023 Autonomous Mileage Reports (CSV)\nurl2 &lt;- \"https://www.dmv.ca.gov/portal/file/2023-autonomous-mileage-reports-csv/\"\n\n# 2022-23 Autonomous Vehicle Disengagement Reports (CSV)(first-time filers)\n# url3 &lt;- \"https://www.dmv.ca.gov/portal/file/2022-23-autonomous-vehicle-disengagement-reports-csvfirst-time-filers/\"\n\n# 2022-23 Autonomous Mileage Reports (CSV)(first-time filers)\n# url4 &lt;- \"https://www.dmv.ca.gov/portal/file/2022-23-autonomous-mileage-reports-csvfirst-time-filers/\"\n\n# 2023 Autonomous Vehicle Disengagement Reports (CSV)(driverless)\n# url5 &lt;- \"https://www.dmv.ca.gov/portal/file/2023-autonomous-vehicle-disengagement-reports-csvdriverless/\"\n\n# 2023 Autonomous Mileage Reports (CSV)(driverless)\n# url6 &lt;- \"https://www.dmv.ca.gov/portal/file/2023-autonomous-mileage-reports-csvdriverless/\"\n\n\n# =============================================================================#\n# Library Load-in---------------------------------------------------------------\n# =============================================================================#\n# Data Wrangling Tools\nlibrary(tidyverse)\nlibrary(janitor)\n\n# Final plot (ggplot2) tools\nlibrary(scales)\nlibrary(fontawesome)\nlibrary(ggtext)\nlibrary(showtext)\nlibrary(patchwork)\nlibrary(ggimage)\nlibrary(ggfittext)\nlibrary(colorspace)\n\n\n# ==============================================================================#\n# Data Load-in------------------------------------------------------------------\n# ==============================================================================#\n# {1} 2023 Autonomous Vehicle Disengagement Reports (CSV)\ndf1 &lt;- read_csv(url1) |&gt; remove_empty()\n\n# {2} 2023 Autonomous Mileage Reports (CSV)\ndf2 &lt;- read_csv(url2) |&gt; remove_empty()\n\n# ==============================================================================#\n# Data Wrangling----------------------------------------------------------------\n# ==============================================================================#\n# {1} 2023 Autonomous Vehicle Disengagement Reports (CSV)\n# Store full names of Variables\ncn_df1 &lt;- names(df1)\n# short names\nnames(df1) &lt;- c(\"manufacturer\",\n                \"permit_number\",\n                \"date\",\n                \"vin\",\n                \"driver_need\",\n                \"driver\",\n                \"disengagement_initiate\",\n                \"disengagement_location\",\n                \"description\")\n\n# Number of disengagements by AV vs. Test Driver for each manufacturer\nplot1df1 &lt;- df1 |&gt; \n  mutate(disengagement_initiate = if_else(\n    str_detect(disengagement_initiate, \"AV\"),\n    \"AV System\",\n    \"Test Driver\")) |&gt; \n  group_by(manufacturer) |&gt; \n  count(disengagement_initiate) |&gt; \n  # A minor nomenculature change to match data in all plots\n  mutate(manufacturer = if_else(\n    manufacturer == \"Nissan North America\",\n    \"Nissan\",\n    manufacturer\n  ))\n\n# Top 14 descriptions of reasons for disengagements\nsum_desc &lt;- df1 |&gt; \n  mutate(\n    description = fct(description),\n    description = fct_lump_n(description, n = 13)\n  ) |&gt; \n  count(description, sort = TRUE) |&gt; \n  pull(description)\n\n# Number of disengagements by reason for each manufacturer\nplot2df1 &lt;- df1 |&gt; \n  # A minor nomenculature change to match data in all plots\n  mutate(manufacturer = if_else(\n    manufacturer == \"Nissan North America\",\n    \"Nissan\",\n    manufacturer\n  )) |&gt; \n  mutate(\n    short_description = case_when(\n      description == sum_desc[1] ~ \"Wrongly predicted road user behavior\",\n      description == sum_desc[2] ~ \"Other Reasons\",\n      description == sum_desc[3] ~ \"Hardware issues\",\n      description == sum_desc[4] ~ \"Software issues\",\n      description == sum_desc[5] ~ \"Vehicle too close to road boundary\",\n      description == sum_desc[6] ~ \"Onboard map errors\",\n      description == sum_desc[7] ~ \"Unexpected braking\",\n      description == sum_desc[8] ~ \"Undesirable lane placement\",\n      description == sum_desc[9] ~ \"Too close to preceding vehicle\",\n      description == sum_desc[10] ~ \"Lane violation\",\n      description == sum_desc[11] ~ \"Motion plan error\",\n      description == sum_desc[12] ~ \"Unwanted maneuver by vehicle\",\n      description == sum_desc[13] ~ \"Lane violation\",\n      description == \"Prediction discrepancy. Adjacent vehicle made illegal maneuver from left turn only lane.\" ~ \"Other vehicles' fault\",\n      description == \"Prediction discrepancy. Late and illegal cut-in from other vehicle from adjacent lane.\" ~ \"Illegal cut by others\",\n      description == \"Prediction discrepancy. Late cut-in from other vehicle from adjacent lane.\" ~ \"Late cut by others\",\n      str_detect(description, \"Planning Logic\")  ~ \"Incorrect Planning Logic\",\n      str_detect(description, \"Object Perception\") ~ \"Incorrect Object Perception\",\n      str_detect(description, \"The lead vehicle stopped for stop sign was falsely identified\") ~ \"Incorrect Object Perception\",\n      str_detect(description, \"While traveling on a narrow road, an incoming vehicle approached\") ~ \"Other vehicles' fault\",\n      str_detect(description, \"The AV system exited autonomous mode due to hardware irregularity.\") ~ \"Hardware issues\",\n      str_detect(description, \"Manual disengagement as the AV had hardware irregularity. The HMI\") ~ \"Hardware issues\",\n      str_detect(description, \"Manual disengagement after a scooter made contact with the AV.\") ~ \"Other vehicles' fault\",\n      str_detect(description, \"Disengage for a perception discrepancy for which a component of the vehicle's perception system\") ~ \"Perception Error\",\n      str_detect(description, \"Disengage for a software discrepancy for which our vehicle's diagnostics received\") ~ \"Software issues\",\n      .default = \"Other Reasons\"\n    )\n  ) |&gt; \n  group_by(manufacturer) |&gt; \n  count(short_description, sort = TRUE) |&gt; \n  rename(snag = n)\n\n# {2} 2023 Autonomous Mileage Reports (CSV)\n# Store full names of variables\ncn_df2 &lt;- names(df2)\n\n# cleaner names\ndf2 &lt;- df2 |&gt; clean_names()\n\n# Tibble of Brands, total mileage and disengagements\nplotdf2 &lt;- df2 |&gt; \n  select(-c(vin_number, annual_total,permit_number)) |&gt; \n  pivot_longer(\n    cols = -c(manufacturer, annual_total_of_disengagements),\n    names_to = \"month\",\n    values_to = \"miles\"\n  ) |&gt; \n  group_by(manufacturer) |&gt; \n  summarise(total_miles = sum(miles, na.rm = TRUE),\n            total_disengagements = sum(annual_total_of_disengagements)) |&gt; \n  arrange(desc(total_miles)) |&gt; \n  mutate(diseng_p_100m = 100 * total_disengagements / total_miles ) |&gt; \n  # Adding logos of manufacturers for the plot\n  mutate(logo_url = c(\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Waymo_logo.svg/1200px-Waymo_logo.svg.png\",\n    \"https://upload.wikimedia.org/wikipedia/commons/5/5d/Zoox_logo_2021.png\",\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Cruise_logo.svg/2560px-Cruise_logo.svg.png\",\n    \"https://1000logos.net/wp-content/uploads/2016/10/Apple-Logo.png\",\n    \"https://seekvectorlogo.com/wp-content/uploads/2023/03/nuro-inc-vector-logo.png\",\n    \"https://media.designrush.com/inspiration_images/136995/conversions/_1524250340_590_Mercedes-Benz-Logo-Wordmark-mobile.jpg\",\n    \"https://mms.businesswire.com/media/20231108625285/en/1938556/23/ghost_combination_black_new.jpg\",\n    \"https://d1.awsstatic.com/customer-references-case-studies-logos/Customer-References-600x400-logos/600X400_WeRide_logo.8637603e647959947cbd83eded476566dd45ef46.png\",\n    \"https://cdn.cookielaw.org/logos/8c60fe9e-585e-46b1-8f92-eba17239401e/d3e43cda-e0a4-42f2-9c04-0e1900c3f68f/808c47fb-8484-44eb-b369-d90d6bb4733e/motional_logo_stack_colorrev_rgb_black.png\",\n    \"https://www.apollo.auto/abolo/images/logo.png\",\n    \"https://mma.prnewswire.com/media/777482/ai_motive_landscape_logo_Logo.jpg\",\n    \"https://s3-us-west-2.amazonaws.com/cbi-image-service-prd/original/fc97e73f-33bd-414e-a9ef-e4504451e4c0.png\",\n    \"https://upload.wikimedia.org/wikipedia/commons/8/8c/Nissan_logo.png\",\n    \"https://global.toyota/pages/news/images/2023/04/11/0800/20230411_02_01.png\",\n    \"https://s28.q4cdn.com/896456191/files/images/didi-logo.png\",\n    \"https://logos-world.net/wp-content/uploads/2022/11/Qualcomm-Emblem.png\",\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Bosch-logo.svg/2560px-Bosch-logo.svg.png\",\n    \"https://ces.vporoom.com/Imagry/image/imagry-logo-with-short-tagline.gif\",\n    \"https://d1io3yog0oux5.cloudfront.net/_e08a077351e2c1b3b2e6179a6ccad2db/aurora/logo.png\",\n    \"https://gatik.ai/wp-content/uploads/gatik-logo.png\",\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Valeo_Logo.svg/1200px-Valeo_Logo.svg.png\"\n  ))\n\n# Change levels of Manufacturer to have a common order in all plots\nmanufacturer_levels &lt;- c(plotdf2$manufacturer, \"Valeo\")\n\nplotdf2 &lt;- plotdf2 |&gt; \n  mutate(manufacturer = fct(manufacturer, levels = manufacturer_levels)) |&gt; \n  mutate(manufacturer = fct_rev(manufacturer))\nplot1df1 &lt;- plot1df1 |&gt; \n  mutate(manufacturer = fct(manufacturer, levels = manufacturer_levels)) |&gt; \n  mutate(manufacturer = fct_rev(manufacturer))\nplot2df1 &lt;- plot2df1 |&gt; \n  mutate(manufacturer = fct(manufacturer, levels = manufacturer_levels)) |&gt; \n  mutate(manufacturer = fct_rev(manufacturer))\n\n# Top n manufacturers by number of miles driven\ntop_manufacturers &lt;- plotdf2 |&gt; \n  slice_max(order_by = total_miles, n = 11) |&gt; \n  pull(manufacturer)\n\n# Common Manufacturers\ncommon_manufacturers &lt;- plot1df1 |&gt; \n  inner_join(plot2df1, relationship = \"many-to-many\") |&gt; \n  inner_join(plotdf2) |&gt; \n  distinct(manufacturer) |&gt; \n  pull(manufacturer) |&gt; \n  as.character()\n\n# =============================================================================#\n# Options & Visualization Parameters--------------------------------------------\n# =============================================================================#\n\n# Load fonts\nfont_add_google(\"Fredericka the Great\",\n  family = \"title_font\"\n) # Font for titles\nfont_add_google(\"Saira Extra Condensed\",\n  family = \"caption_font\"\n) # Font for the caption\nfont_add_google(\"Fira Sans Extra Condensed\",\n  family = \"body_font\"\n) # Font for plot text\nshowtext_auto()\n\n# Define colours\nbg_col &lt;- \"white\"   # Background Colour\ntext_col &lt;- \"#04225CFF\" # Colour for the text\ntext_hil &lt;- \"#309D96FF\" # Colour for higlighted text\n\n# Define Text Size\nts &lt;- unit(30, units = \"cm\") # Text Size\n\n# Caption stuff\nsysfonts::font_add(\n  family = \"Font Awesome 6 Brands\",\n  regular = here::here(\"docs\", \"Font Awesome 6 Brands-Regular-400.otf\")\n)\ngithub &lt;- \"&#xf09b\"\ngithub_username &lt;- \"aditya-dahiya\"\nxtwitter &lt;- \"&#xe61b\"\nxtwitter_username &lt;- \"@adityadahiyaias\"\nsocial_caption_1 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_hil}'&gt;{github_username}  &lt;/span&gt;\")\nsocial_caption_2 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_hil}'&gt;{xtwitter_username}&lt;/span&gt;\")\n\n# Add text to plot--------------------------------------------------------------\nplot_title &lt;- \"Behind the Wheel of Tomorrow:\\nCalifornia's Autonomous Vehicles Testing Data\"\nplot_caption &lt;- paste0(\"**Data:** State of California, Department of Motor Vehicles\", \" | \", \" **Code:** \", social_caption_1, \" | \", \" **Graphics:** \", social_caption_2)\nsubtitle_text &lt;- \"An analysis of Autonomous Vehicles‚Äô (AV) Testing Data (released by the State of California's Department of Motor Vehicles) reveals the performance of various AV Manufacturers. The number of total miles driven, disengagement rates (per 100 miles driven), and common reasons for autonomous mode exits (termed ‚Äúdisengagements‚Äù) indicate dominance & error-free tech of Google‚Äôs Waymo, and error-prone nature of Apple‚Äôs AV.\"\nplot_subtitle &lt;- str_wrap(subtitle_text, width = 115)\n\n# ==============================================================================#\n# Data Visualization------------------------------------------------------------\n# ==============================================================================#\ntempdf2 &lt;- plotdf2 |&gt; \n  filter(manufacturer %in% common_manufacturers) |&gt; \n  filter(manufacturer %in% top_manufacturers)\n\ng1 &lt;- tempdf2 |&gt; \n  ggplot(\n    mapping = aes(\n      x = total_miles,\n      y = manufacturer\n    )\n  ) +\n  geom_col(\n    fill = text_col,\n    color = \"black\",\n    alpha = 0.5\n    ) +\n  geom_text(\n    aes(\n      label = comma(total_miles),\n      colour = (total_miles &gt; 1e6)\n      ),\n    family = \"body_font\",\n    size = 1.8 * ts,\n    hjust = if_else(tempdf2$total_miles &gt; 1e6,\n                    1.1, -0.1)\n  ) +\n  geom_image(\n    aes(\n      x = -1.7e6,\n      image = logo_url\n    ),\n    by = \"height\",\n    hjust = 1\n  ) +\n  scale_colour_manual(values = c(text_col, \"white\")) +\n  scale_x_continuous(\n    expand = expansion(c(0.45, 0.2)),\n    breaks = c(1e5, 1e6, 2e6, 3e6),\n    labels = label_number(\n      scale_cut = cut_short_scale()\n    )\n  ) +\n  labs(\n    subtitle = \"Total AV miles driven by Manufacturer's\\nAutonomous Vehicles (2023))\",\n    y = NULL, x = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.grid = element_blank(),\n    panel.grid.major.x = element_line(\n      linetype = 2,\n      colour = text_hil,\n      linewidth = 1\n    ),\n    axis.text.x = element_text(\n      hjust = 0.5,\n      size = 4 * ts,\n      family = \"body_font\",\n      colour = text_col,\n      margin = margin(0, 0, 0, 0,\n                      unit = \"cm\"),\n      lineheight = 0.35\n    ),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      size = 4 * ts,\n      family = \"body_font\",\n      colour = text_col,\n      margin = margin(2, 0, 0, 0,\n                      unit = \"cm\"\n      ),\n      lineheight = 0.25\n    ),\n    legend.position = \"none\"\n  )\n\ng2 &lt;- tempdf2 |&gt; \n  ggplot(\n    mapping = aes(\n      x = diseng_p_100m,\n      y = manufacturer\n    )\n  ) +\n  geom_col(\n    fill = text_hil,\n    colour = \"black\",\n    alpha = 0.5\n  ) +\n  geom_text(\n    aes(\n      label = round(diseng_p_100m, 2),\n      colour = (diseng_p_100m &gt; 35)\n    ),\n    family = \"body_font\",\n    size = 1.8 * ts,\n    hjust = if_else(tempdf2$diseng_p_100m &gt; 35,\n                            1.1, -0.1)\n  ) +\n  scale_colour_manual(values = c(text_hil, \"white\")) +\n  scale_x_continuous(\n    expand = expansion(c(0, 0.2)),\n    breaks = c(0, 25, 50),\n    labels = c(0, 25, 50)\n  ) +\n  labs(\n    subtitle = \"Errors \\n(per 100 miles)\",\n    y = NULL, x = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.grid = element_blank(),\n    panel.grid.major.x = element_line(\n      linetype = 2,\n      colour = text_hil,\n      linewidth = 1\n    ),\n    axis.text.x = element_text(\n      hjust = 0.5,\n      size = 4 * ts,\n      family = \"body_font\",\n      colour = text_col,\n      margin = margin(0, 0, 0, 0,\n                      unit = \"cm\"),\n      lineheight = 0.35\n    ),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      size = 4 * ts,\n      family = \"body_font\",\n      colour = text_col,\n      margin = margin(2, 0, 0, 0,\n                      unit = \"cm\"\n      ),\n      lineheight = 0.25\n    ),\n    legend.position = \"none\"\n  )\n# Colours for third plot\ng3col &lt;- c(\"#43B48DFF\", \"#F5773AFF\")\n\ng3 &lt;- plot1df1 |&gt; \n  left_join(plotdf2) |&gt; \n  mutate(n = n / total_miles) |&gt; \n  filter(manufacturer %in% common_manufacturers) |&gt; \n  filter(manufacturer %in% top_manufacturers) |&gt; \n  ggplot(\n    mapping = aes(\n      y = manufacturer,\n      x = n,\n      fill = disengagement_initiate,\n      label = disengagement_initiate,\n      colour = disengagement_initiate\n    )\n  ) +\n  geom_col(\n    position = \"fill\",\n    col = \"white\"\n  ) +\n  geom_bar_text(\n    position = \"fill\",\n    hjust = 0.5,\n    vjust = 0.5,\n    reflow = TRUE,\n    place = \"center\",\n    min.size = 1,\n    grow = TRUE,\n    padding.y = unit(25, \"mm\"),\n    lineheight = 0.25\n  ) +\n  scale_x_continuous(\n    breaks = c(0, 1),\n    labels = label_percent()\n  ) +\n  scale_fill_manual(values = g3col |&gt; lighten(0.7)) +\n  scale_colour_manual(values = g3col |&gt; darken(0.5)) +\n  labs(\n    subtitle = \"Who stopped\\nthe AV?\",\n    x = NULL, y = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    panel.grid = element_blank(),\n    axis.text.y = element_blank(),\n    axis.text.x = element_blank(),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      size = 4 * ts,\n      family = \"body_font\",\n      colour = text_col,\n      margin = margin(2, 0, 0, 0,\n                      unit = \"cm\"\n      ),\n      lineheight = 0.25\n    )\n  )\n\ng4 &lt;- plot2df1 |&gt; \n  left_join(plotdf2) |&gt; \n  mutate(snag_p_100m = snag / total_miles) |&gt; \n  mutate(snag_fill = snag_p_100m / sum(snag_p_100m)) |&gt; \n  filter(manufacturer %in% common_manufacturers) |&gt; \n  filter(manufacturer %in% top_manufacturers) |&gt; \n  ggplot(\n    mapping = aes(\n      y = manufacturer,\n      x = snag_p_100m,\n      fill = short_description,\n      label = short_description,\n      color = short_description\n    )\n  ) +\n  geom_col(\n    position = \"fill\",\n    colour = \"darkgrey\"\n  ) +\n  geom_bar_text(\n    position = \"fill\",\n    hjust = 0.5,\n    vjust = 0.5,\n    reflow = TRUE,\n    place = \"center\",\n    min.size = 1,\n    lineheight = 0.25,\n    grow = TRUE,\n    padding.x = unit(15, \"mm\"),\n    padding.y = unit(15, \"mm\")\n  ) +\n  paletteer::scale_fill_paletteer_d(\"palettesForR::Lights\", \n                                    direction = -1) +\n  scale_color_manual(\n    values = paletteer::paletteer_d(\"palettesForR::Lights\",\n                                    direction = -1) |&gt; darken(0.4)\n  ) +\n  scale_x_continuous(\n    breaks = c(0, 0.5, 1),\n    labels = label_percent()\n  ) +\n  labs(\n    subtitle = \"Reasons for AV\\ndisengagement\",\n    x = NULL, y = NULL\n  ) +\n  theme_void() +\n  theme(\n    legend.position = \"none\",\n    panel.grid = element_blank(),\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(\n      colour = text_col,\n      hjust = 0,\n      family = \"body_font\",\n      size = 4 * ts,\n      margin = margin(0,0,0,0)\n      ),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      size = 4 * ts,\n      family = \"body_font\",\n      colour = text_col,\n      margin = margin(2, 0, 0, 0,\n                      unit = \"cm\"\n      ),\n      lineheight = 0.25\n    )\n    )\n\n# Composing the plots\nplot_design = \"AAABCDDD\"\n\ng &lt;- g1 + g2 + g3 + g4 +\n  plot_layout(design = plot_design)\n\n\ng_final &lt;- g  +\n  plot_annotation(\n    title = plot_title,\n    subtitle = plot_subtitle,\n    caption = plot_caption,\n    theme = theme(\n      plot.subtitle = element_text(\n        hjust = 0.5,\n        size = 4.8 * ts,\n        family = \"body_font\",\n        colour = text_col,\n        margin = margin(2, 0, 0, 0,\n                        unit = \"cm\"\n        ),\n        lineheight = 0.3\n      )\n    )\n  ) &\n  theme(\n    plot.caption = element_textbox(\n      family = \"caption_font\",\n      hjust = 0.5,\n      colour = text_hil,\n      size = 4 * ts,\n      margin = margin(1, 0, 2, 0,\n                      unit = \"cm\"\n      )\n    ),\n    plot.title = element_text(\n      hjust = 0.5,\n      size = 10 * ts,\n      family = \"title_font\",\n      face = \"bold\",\n      colour = text_hil,\n      margin = margin(2, 0, 0, 0,\n                      unit = \"cm\"\n      ),\n      lineheight = 0.35\n    ),\n    plot.background = element_rect(\n      fill = \"transparent\",\n      color = \"transparent\",\n      linewidth = 0\n    ),\n    plot.margin = margin(0, 0, 0, 0),\n    legend.background = element_rect(\n      fill = \"transparent\",\n      color = \"transparent\"\n    ),\n    panel.background = element_rect(\n      fill = \"transparent\",\n      colour = \"transparent\"\n    )\n  )\n\n# =============================================================================#\n# Image Saving-----------------------------------------------------------------\n# =============================================================================#\n\nggsave(\n  filename = here::here(\"docs\", \"dip_self_driving_cars.png\"),\n  plot = g_final,\n  width = 75,\n  height = 90,\n  units = \"cm\",\n  bg = bg_col\n)\n\n\n\n\n\n\n\n\nFigure¬†3: A graphical analysis of Autonomous Vehicles‚Äô (AV) Testing Data (released by the State of California‚Äôs Department of Motor Vehicles) reveals the performance of various AV Manufacturers. The number of total miles driven, disengagement rates (per 100 miles driven), and common reasons for autonomous mode exits (termed ‚Äúdisengagements‚Äù) indicate dominance & error-free tech of Google‚Äôs Waymo, and error-prone nature of Apple‚Äôs AV."
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-6-world-heritage-sites",
    "href": "projects/tidy_tuesday.html#week-6-world-heritage-sites",
    "title": "Data Visualization Projects",
    "section": "Week 6: World heritage sites",
    "text": "Week 6: World heritage sites\nWorld heritage sites by UNESCO World Heritage Sites at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-7-valentines-day-consumer-data",
    "href": "projects/tidy_tuesday.html#week-7-valentines-day-consumer-data",
    "title": "Data Visualization Projects",
    "section": "Week 7: Valentine‚Äôs Day Consumer Data",
    "text": "Week 7: Valentine‚Äôs Day Consumer Data\nValentine‚Äôs Day survey data by National Retail Federation‚Äôs Valentine‚Äôs Day Data Center at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-8-r-consortium-isc-grants",
    "href": "projects/tidy_tuesday.html#week-8-r-consortium-isc-grants",
    "title": "Data Visualization Projects",
    "section": "Week 8: R Consortium ISC Grants",
    "text": "Week 8: R Consortium ISC Grants\nR Consortium ISC Funded Projects‚Äô data by R Consortium at the Linux Foundation Projects at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-9-leap-day",
    "href": "projects/tidy_tuesday.html#week-9-leap-day",
    "title": "Data Visualization Projects",
    "section": "Week 9: Leap Day",
    "text": "Week 9: Leap Day\nData from the February 29 article on Wikipedia at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/dip_viz.html#d.i.p.-2024.02.28-climate-funding",
    "href": "projects/dip_viz.html#d.i.p.-2024.02.28-climate-funding",
    "title": "Data Visualizations from D.I.P.",
    "section": "D.I.P. 2024.02.28: Climate Funding",
    "text": "D.I.P. 2024.02.28: Climate Funding\nExploring the dataset from the Global Landscape of Climate Finance 2023 report by the Climate Policy Initiative reg. sources of ‚ÄúClimate Funds‚Äù ‚Äì funds for combating climate change, its mitigation, reversal; and, the regions where these go to in Figure¬†4 .\n\n\nCode\n# =============================================================================#\n# About the Dataset-------------------------------------------------------------\n# =============================================================================#\n\n# Credit: Climate Policy Initiative\n# Global Landscape of Climate Finance 2023\n# Barbara Buchner, Baysa Naran, Rajashree Padmanabhi, Sean Stout, Costanza \n# Strinati, Dharshan Wignarajah, Gaoyi Miao, Jake Connolly and Nikita Marini\n# November 2, 2023\n# https://www.climatepolicyinitiative.org/publication/global-landscape-of-climate-finance-2023/\n\n# Climate Policy Initiative collected data to produce its \"Global Landscape of \n# Climate Finance 2023\" report, examining various forms of primary financing \n# aimed at reducing greenhouse gas emissions and enhancing climate resilience in \n# real economy sectors. Released in November, the report disclosed approximately \n# $1.3 trillion in such financing worldwide during 2021‚Äì2022. Accompanying the \n# report is a spreadsheet detailing estimates by year, region, sector, focus on \n# mitigation versus adaptation, financial instrument type, funder sector (public \n# versus private), and funder type (development bank, corporation, institutional \n# investors, etc.). Previous reports offer downloadable data covering 2019‚Äì2020 \n# and 2017‚Äì2018, with earlier coverage on national climate funds \n# (DIP 2022.02.09) and climate finance projects (DIP 2023.06.14).\n\n# =============================================================================#\n# Findings ---------------------------------------------------------------------\n# =============================================================================#\n\n# Where the money comes from:\n# The share of public and private sources in the funding for climate change \n# mitigation activities has stayed almost the same. Both have increased \n# together, in same proportion. Within the various sources of funding, \n# largest increases in funding have come from ‚ÄúPublic Funds‚Äù and ‚ÄúState-Owned \n# Enterprises‚Äù. Amongst private sources of funds, Commercial Institutions and \n# Individual Households provide bulk of the funding.\n\n# Where the money goes:\n# The East Asia and Pacific region continue to get an ever-increasing share of \n# total funds dedicated to Climate Change. However, importantly, the Western \n# Europe region has increased its allotment by the maximum, a staggering 152%.\n\n# Global-Landscape-of-Climate-Finance-2023\n# GLCF 2023 ‚Äì Data Download\nurl1 &lt;- \"https://www.climatepolicyinitiative.org/wp-content/uploads/2023/11/GLCF-2023-Data-Download.xlsx\"\n\n# =============================================================================#\n# Library Load-in---------------------------------------------------------------\n# =============================================================================#\n# Data Wrangling Tools\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(janitor)\n\n# Final plot (ggplot2) tools\nlibrary(scales)\nlibrary(fontawesome)\nlibrary(ggtext)\nlibrary(showtext)\nlibrary(treemapify)\nlibrary(colorspace)\nlibrary(gganimate)\n\n# =============================================================================#\n# Data Load-in & Data Wrangling-------------------------------------------------\n# =============================================================================#\n\n# Breakdown of global climate finance by public and private actors (USD billion)\nfinance &lt;- read.xlsx(\n  url1,\n  sheet = 3,\n  colNames = TRUE,\n  rowNames = FALSE,\n  rows = c(4, 6:11, 13:21),\n  cols = 1:7\n  ) |&gt; \n  remove_empty() |&gt; \n  mutate(\n    funding_type = c(\n      rep(\"Private\", 6),\n      rep(\"Public\", 9)\n    )\n  ) |&gt; \n  rename(actors = Actors) |&gt; \n  as_tibble() |&gt; \n  pivot_longer(\n    cols = 2:7,\n    names_to = \"year\",\n    values_to = \"value\"\n  )\n\n# Breakdown of global climate finance by Use and Sector (USD billion)\nusage &lt;- read.xlsx(\n  url1,\n  sheet = 3,\n  colNames = TRUE,\n  rowNames = FALSE,\n  rows = c(56, 58:66, 68:77, 79:88, 90:91),\n  cols = 1:5\n  ) |&gt; \n  remove_empty() |&gt; \n  mutate(\n    usage_type = c(\n      rep(\"Adaptation\", 9),\n      rep(\"Mitigation\", 10),\n      rep(\"Dual Benefits\", 10),\n      rep(\"Unknown\", 2)\n    )\n  ) |&gt; \n  rename(sector = `Use/Sector`) |&gt; \n  as_tibble() |&gt; \n  pivot_longer(\n    cols = 2:5,\n    names_to = \"year\",\n    values_to = \"value\"\n  )\n\n# Breakdown of global climate finance by region of destination (USD billion)\n\nregions &lt;- read.xlsx(\n  url1,\n  sheet = 3,\n  colNames = TRUE,\n  rowNames = FALSE,\n  rows = 167:177,\n  cols = 1:7\n) |&gt; \n  remove_empty() |&gt; \n  rename(region = `Region`) |&gt; \n  as_tibble() |&gt; \n  pivot_longer(\n    cols = 2:7,\n    names_to = \"year\",\n    values_to = \"value\"\n  ) \n\n# Create a common tibble to join all data to use a faceted treemap\n\ndf &lt;- bind_rows(\n  regions |&gt; \n    rename(fill_var = region) |&gt; \n    mutate(\n      group_var = \" \",\n      table_type = \"Destination for funds\"\n    ),\n  finance |&gt; \n    rename(\n      fill_var = actors,\n      group_var = funding_type\n    ) |&gt; \n    mutate(table_type = \"Source of funds\")\n  ) |&gt; \n  mutate(year = as.numeric(year))\n\n# Get levels of categories fixed for nicer colours later on\nfill_var_levels &lt;- df |&gt; \n  group_by(table_type, group_var, fill_var) |&gt; \n  summarise(total_val = sum(value)) |&gt; \n  arrange(desc(total_val)) |&gt; \n  pull(fill_var)\n\nplotdf &lt;- df |&gt; \n  mutate(fill_var = fct(fill_var, levels = fill_var_levels)) |&gt; \n  mutate(table_type = fct(table_type,\n                          levels = c(\n                            \"Source of funds\",\n                            \"Destination for funds\"\n                          ))) |&gt; \n  ungroup()\n\n# Some EDA Plots to write the messages in actual plot\nplotdf |&gt; \n  filter(table_type == \"Usage of funds\") |&gt; \n  ggplot(aes(x = year, y = value, col = fill_var)) +\n  geom_line(linewidth = 2) +\n  scale_color_brewer(palette = \"Dark2\")\n\nplotdf |&gt; \n  filter(table_type == \"Usage of funds\") |&gt; \n  group_by(fill_var) |&gt; \n  summarise(increase = (100 * (max(value) - min(value)))/min(value))\n\nplotdf |&gt; \n  filter(table_type != \"Usage of funds\") |&gt; \n  group_by(group_var, year) |&gt; \n  summarise(value = sum(value, na.rm = TRUE)) |&gt; \n  ggplot(aes(x = year, y = value, col = group_var)) +\n  geom_line(linewidth = 2)\n\nplotdf |&gt; \n  filter(table_type != \"Usage of funds\") |&gt; \n  group_by(group_var, fill_var, year) |&gt;\n  summarise(value = sum(value, na.rm = TRUE)) |&gt; \n  ggplot(aes(x = year, y = value, \n             col = fill_var,\n             linetype = group_var)) +\n  geom_line(linewidth = 2) +\n  scale_color_brewer(palette = \"Dark2\")\n\nplotdf |&gt; \n  filter(table_type != \"Usage of funds\") |&gt; \n  group_by(group_var, fill_var) |&gt; \n  summarise(increase = (100 * (max(value) - min(value)))/min(value)) |&gt; \n  group_by(group_var) |&gt; \n  arrange(desc(increase))\n\n# =============================================================================#\n# Options & Visualization Parameters--------------------------------------------\n# =============================================================================#\n\n# Load fonts\n# Font for titles\nfont_add_google(\"Fjalla One\",\n  family = \"title_font\"\n) \n\n# Font for the caption\nfont_add_google(\"Saira Extra Condensed\",\n  family = \"caption_font\"\n) \n\n# Font for plot text\nfont_add_google(\"Anton\",\n  family = \"body_font\"\n) \n\nshowtext_auto()\n\n# Define colours\nbg_col &lt;- \"white\"   # Background Colour\ntext_col &lt;- \"#009270FF\" |&gt; darken(0.5) # Colour for the text\ntext_hil &lt;- \"#009270FF\" # Colour for higlighted text\n\n# Add text to plot--------------------------------------------------------------\nplot_title &lt;- \"Flow of Global Climate Funds\"\nplot_caption &lt;- paste0(\"Data: Climate Policy Initiative | Code & Graphics: GitHub @aditya-dahiya\")\nsubtitle_text &lt;- \"Exploring the sources of ‚ÄúClimate Funds‚Äù ‚Äì funds for combating climate change, its mitigation, reversal; and, the regions where these go to. From 2017 to 2022, share of public and private sources in the funding has stayed constant. Within the various sources of funding, largest increases in funding have come from ‚ÄúPublic Funds‚Äù and ‚ÄúState-Owned Enterprises‚Äù. Further, the East Asia and Pacific region continue to get an ever-increasing share of total funds dedicated to Climate Change. However, importantly, the Western Europe region has increased its allotment by the maximum, a staggering 152%, from 2017 to 2022.\"\nplot_subtitle &lt;- str_wrap(subtitle_text, width = 100)\n\n# ==============================================================================#\n# Data Visualization------------------------------------------------------------\n# ==============================================================================#\n\ng &lt;- ggplot(plotdf, \n  aes(\n    label = fill_var,\n    area = value,\n    subgroup = group_var,\n    fill = fill_var\n  )) +\n  geom_treemap(\n    layout = \"fixed\"\n  ) +\n  geom_treemap_subgroup_border(\n    layout = \"fixed\",\n    colour = \"white\",\n    alpha = 0.5\n  ) +\n  geom_treemap_subgroup_text(\n    layout = \"fixed\", \n    place = \"centre\",\n    colour = \"white\",\n    family = \"body_font\"\n  ) +\n  geom_treemap_text(\n    layout = \"fixed\", \n    place = \"center\", \n    grow = FALSE, \n    colour = text_col,\n    family = \"caption_font\",\n    reflow = TRUE\n  ) +\n  facet_wrap(~ table_type) +\n  scale_fill_manual(\n    values = paletteer::paletteer_d(\"khroma::stratigraphy\")[(115):(115 + 25)]\n  ) +\n  labs(\n    title = paste0(plot_title, \": {frame_time}\"),\n    subtitle = plot_subtitle,\n    caption = plot_caption\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    strip.text.x = element_text(\n      colour = text_col,\n      family = \"body_font\",\n      size = 18,\n      margin = margin(5, 0, 5, 0)\n    ),\n    plot.title = element_text(\n      hjust = 0.5,\n      family = \"title_font\",\n      size = 32,\n      colour = text_hil, \n      margin = margin(15, 0, 5, 0)\n    ),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      family = \"caption_font\",\n      size = 14,\n      colour = text_col,\n      lineheight = 1.1,\n      margin = margin(5, 0, 5, 0)\n    ),\n    plot.caption = element_text(\n      hjust = 0.5,\n      colour = text_hil,\n      size = 9,\n      family = \"caption_font\",\n      margin = margin(5, 0, 10, 0)\n    )\n  ) +\n  transition_time(as.integer(year)) +\n  ease_aes('linear')\n\n# =============================================================================#\n# Image Saving-----------------------------------------------------------------\n# =============================================================================#\n\nanim_save(\n  filename = here::here(\"docs\", \"dip_climate_funding.gif\"),\n  animation = g,\n  fps = 10,\n  duration = 20,\n  start_pause = 5,\n  end_pause = 10,\n  height = 650,\n  width = 600,\n  units = \"px\"\n)\n\nggview::ggview(\n  device = \"png\",\n  plot = g,\n  width = 23,\n  height = 30,\n  units = \"cm\",\n  bg = bg_col\n)\n\n\n\n\n\n\n\n\nFigure¬†4: From 2017 to 2022, share of public and private sources in the funding has stayed constant. Within the various sources of funding, largest increases in funding have come from ‚ÄúPublic Funds‚Äù and ‚ÄúState-Owned Enterprises‚Äù. Further, the East Asia and Pacific region continue to get an ever-increasing share of total funds dedicated to Climate Change. However, importantly, the Western Europe region has increased its allotment by the maximum, a staggering 152%, from 2017 to 2022."
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-10-trash-wheel-collection-data",
    "href": "projects/tidy_tuesday.html#week-10-trash-wheel-collection-data",
    "title": "Data Visualization Projects",
    "section": "Week 10: Trash Wheel Collection Data",
    "text": "Week 10: Trash Wheel Collection Data\nThis week‚Äôs Trash Wheel Collection Data comes from the Mr.¬†Trash Wheel at the Baltimore Healthy Harbor initiative at #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/dip_viz.html#d.i.p.-2024.03.06-fatal-police-pursuits.",
    "href": "projects/dip_viz.html#d.i.p.-2024.03.06-fatal-police-pursuits.",
    "title": "Data Visualizations from D.I.P.",
    "section": "D.I.P. 2024.03.06: Fatal police pursuits.",
    "text": "D.I.P. 2024.03.06: Fatal police pursuits.\nA Visualization at Figure¬†5 from the dataset that Journalists at the San Francisco Chronicle have assembled from a comprehensive record of over 3,300 deaths resulting from police car pursuits between 2017 and 2022 on a national scale using the federal government‚Äôs Fatality Analysis Reporting System\n\n\nCode\n# =============================================================================#\n# About the Dataset-------------------------------------------------------------\n# =============================================================================#\n\n# Data URL: https://github.com/sfchronicle/police_pursuits\n# Source: Fatality Analysis Reporting System (FARS)\n# https://www.nhtsa.gov/research-data/fatality-analysis-reporting-system-fars\n\n# Deadly police chases. Journalists at the San Francisco Chronicle have assembled \n# a comprehensive record of over 3,300 deaths resulting from police car pursuits\n# between 2017 and 2022 on a national scale. This compilation draws from various \n# sources including the federal government's Fatality Analysis Reporting System \n# (DIP 2016.08.31), studies conducted by research institutions, media coverage, \n# legal actions, and public information requests. Each entry in the dataset \n# provides details such as the individual's name, age, gender, race, and their \n# involvement in the pursuit (whether as a driver, passenger, bystander, or \n# officer). Additionally, it includes information about the date, location, \n# stated reason for the pursuit, and the primary law enforcement agency \n# responsible for the incident.\n\n# Credits:  Reporters at the San Francisco Chronicle\n#           The San Francisco Chronicle\n#           https://www.sfchronicle.com/projects/2024/police-chases/\n\n# =============================================================================#\n# Findings ---------------------------------------------------------------------\n# =============================================================================#\n\n\n# =============================================================================#\n# Library Load-in---------------------------------------------------------------\n# =============================================================================#\n\n# Data Wrangling Tools\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(janitor)\n\n# Final plot (ggplot2) tools\nlibrary(scales)\nlibrary(fontawesome)\nlibrary(ggtext)\nlibrary(showtext)\nlibrary(colorspace)\nlibrary(usmap)\nlibrary(usmapdata)\nlibrary(patchwork)\n\n# =============================================================================#\n# Data Load-in, EDA & Data Wrangling--------------------------------------------\n# =============================================================================#\n\npolice &lt;- read_csv(\"https://raw.githubusercontent.com/sfchronicle/police_pursuits/master/data/sfc_pursuit_fatalities.csv\")\n\n# summarytools::dfSummary(police) |&gt; summarytools::view()\n\nplotdf &lt;- police |&gt; \n  select(-c(unique_id, data_source, race_source)) |&gt; \n  mutate(\n    date = mdy(date),\n    race = case_when(\n      str_detect(race, \"black\") ~ \"Black\", # Disclaimer: a little bias introduced by data cleaning as data-rows with any one entry as black will be treated as \"Black\"\n      str_detect(race, \"white\") ~ \"White\", # Dislcaimer: Similar data bias\n      str_detect(race, \"latino\") ~ \"Latino\",\n      .default = \"Others\"\n    ),\n    race = fct(race, levels = c(\"Black\", \"White\", \"Latino\", \"Others\")),\n    person_role = case_when(\n      person_role %in% c(\"driver\", \"passenger\") ~ \"Driver/Passenger\",\n      person_role == \"bystander\" ~ \"Bystander\",\n      person_role == \"officer\" ~ \"Police Officer\",\n      .default = \"Others\"\n    ),\n    person_role = fct(\n      person_role,\n      levels = c(\"Driver/Passenger\", \"Bystander\", \"Police Officer\", \"Others\")\n    )\n  ) |&gt; \n  rename(lon = \"long\") |&gt;\n  filter(lat &gt; 0 & lat &lt; 90) |&gt; \n  filter(lon &gt; -150 & lon &lt; 0) |&gt; \n  usmap_transform() |&gt; \n  as_tibble() |&gt; \n  extract(\n    col = geometry, \n    into = c('x', 'y'), \n    regex = \"\\\\((.*), (.*)\\\\)\", \n    convert = TRUE) \n\nplotdf2 &lt;- bind_rows(\n  plotdf |&gt; \n    count(race) |&gt;\n    rename(var = race) |&gt; \n    mutate(type = \"Race of Person(s) killed\"),\n  plotdf |&gt; \n    count(person_role) |&gt; \n    rename(var = person_role) |&gt; \n    mutate(type = \"Role of Person(s) killed\")\n)\n\n# =============================================================================#\n# Options & Visualization Parameters--------------------------------------------\n# =============================================================================#\n\n# Load fonts\n# Font for titles\nfont_add_google(\"Faster One\",\n  family = \"title_font\"\n) \n\n# Font for the caption\nfont_add_google(\"Saira Extra Condensed\",\n  family = \"caption_font\"\n) \n\n# Font for plot text\nfont_add_google(\"Iceberg\",\n  family = \"body_font\"\n) \n\nshowtext_auto()\n\n# Define colours\nbg_col &lt;- \"white\" # Background Colour\ntext_col &lt;- \"#012169FF\" # Colour for the text\ntext_hil &lt;- \"#C8102EFF\" # Colour for highlighted text\n\n# Define Text Size\nts &lt;- unit(20, units = \"cm\") # Text Size\n\n# Caption stuff\nsysfonts::font_add(\n  family = \"Font Awesome 6 Brands\",\n  regular = here::here(\"docs\", \"Font Awesome 6 Brands-Regular-400.otf\")\n)\ngithub &lt;- \"&#xf09b\"\ngithub_username &lt;- \"aditya-dahiya\"\nxtwitter &lt;- \"&#xe61b\"\nxtwitter_username &lt;- \"@adityadahiyaias\"\nsocial_caption_1 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_hil}'&gt;{github_username}  &lt;/span&gt;\")\nsocial_caption_2 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_hil}'&gt;{xtwitter_username}&lt;/span&gt;\")\n\n\n# Add text to plot--------------------------------------------------------------\nplot_title &lt;- \"Deadly police chases\"\nplot_caption &lt;- paste0(\"**Data:** The San Francisco Chronicle\", \" | \", \" **Code:** \", social_caption_1, \" | \", \" **Graphics:** \", social_caption_2)\nsubtitle_text &lt;- \"Geographical distribution, race, age and role of persons killed in Police Chases in the United States (2017 - 2022)\"\nplot_subtitle &lt;- str_wrap(subtitle_text, width = 70)\n\n# ==============================================================================#\n# Data Visualization------------------------------------------------------------\n# ==============================================================================#\n\ng1 &lt;- plot_usmap(\n  \"states\",\n  col = \"darkgrey\",\n  fill = \"white\",\n  linewidth = 0.4\n  ) +\n  geom_point(\n    data = plotdf,\n    mapping = aes(\n      x = x,\n      y = y,\n      colour = person_role,\n      size = number_killed),\n    alpha = 0.5\n  ) +\n  scale_color_manual(\n    values = c(\"#FFC72CFF\", \"#1D4289FF\", \"#862633FF\", \"lightgrey\")\n  ) +\n  guides(\n    colour = guide_legend(\n      override.aes = list(size = 8)\n    )\n  ) +\n  labs(\n    title = plot_title,\n    subtitle = plot_subtitle,\n    caption = plot_caption,\n    colour = \"Role of person(s) killed\",\n    size = \"Number of persons killed\"\n  ) +\n  ggthemes::theme_map(\n    base_family = \"body_font\"\n  ) +\n  theme(\n    plot.title = element_text(\n      hjust = 0.5,\n      family = \"title_font\",\n      size = 12.5 * ts,\n      colour = text_hil, \n      margin = margin(15, 0, 0, 0, unit = \"mm\")\n    ),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      family = \"body_font\",\n      size = 6 * ts,\n      colour = text_col,\n      lineheight = 0.3,\n      margin = margin(0, 0, 0, 0, unit = \"mm\")\n    ),\n    plot.caption = element_textbox(\n      hjust = 0.5,\n      colour = text_hil,\n      size = 3 * ts,\n      family = \"caption_font\",\n      margin = margin(11, 0, 0, 0, unit = \"cm\")\n    ),\n    legend.position.inside = c(0.4, 0.),\n    legend.direction = \"horizontal\",\n    legend.spacing = unit(0, \"cm\"),\n    legend.title = element_text(\n      hjust = 1,\n      family = \"caption_font\",\n      size = 3.5 * ts,\n      colour = text_col,\n      lineheight = 0.35,\n      margin = margin(0, 5, 0, 0, unit = \"mm\")\n    ),\n    legend.text = element_text(\n      hjust = 1,\n      family = \"caption_font\",\n      size = 3.5 * ts,\n      colour = text_col,\n      lineheight = 0.35,\n      margin = margin(0, 5, 0, 0, unit = \"mm\")\n    )\n  )\n\ng2 &lt;- plotdf2 |&gt; \n  ggplot(aes(y = reorder(var, n), x = n, fill = type)) +\n  geom_col(\n    colour = \"black\",\n    fill = \"lightgrey\"\n  ) +\n  facet_wrap(~ type, scales = \"free\") +\n  scale_x_continuous(expand = expansion(0)) +\n  scale_y_discrete(expand = expansion(0)) +\n  theme_minimal(\n    base_family = \"body_font\"\n  ) +\n  labs(x = NULL, y = NULL) +\n  theme(\n    panel.grid = element_blank(),\n    panel.grid.major.x = element_line(\n      linetype = 2,\n      colour = \"lightgrey\"\n    ),\n    legend.position = \"none\",\n    strip.text = element_text(\n      hjust = 0,\n      family = \"body_font\",\n      size = 3.5 * ts,\n      colour = text_col,\n      lineheight = 0.35,\n      margin = margin(0, 0, 5, 0, unit = \"mm\")\n    ),\n    axis.text.x = element_text(\n      hjust = 0.5,\n      vjust = 0.5,\n      family = \"body_font\",\n      size = 3.5 * ts,\n      colour = text_col,\n      lineheight = 0.35,\n      margin = margin(0, 0, 0, 0, unit = \"mm\")\n    ),\n    axis.text.y = element_text(\n      hjust = 1,\n      vjust = 0.5,\n      family = \"caption_font\",\n      size = 4 * ts,\n      colour = text_col,\n      lineheight = 0.35,\n      margin = margin(0, 0, 0, 0, unit = \"mm\")\n    ),\n    plot.title.position = \"plot\"\n  )\n\ng3 &lt;- ggplot(plotdf, aes(age)) +\n  geom_histogram(\n    fill = \"lightgrey\",\n    colour = \"black\",\n    binwidth = 5\n  ) +\n  scale_y_continuous(\n    expand = expansion(0),\n    breaks = c(100, 300, 500)\n    ) +\n  scale_x_continuous(\n    expand = expansion(0)\n  ) +\n  coord_flip() +\n  theme_minimal() +\n  labs(\n    x = NULL, \n    y = NULL,\n    subtitle = \"Age Distribution of Victims\"\n    ) +\n  theme(\n    panel.grid = element_blank(),\n    panel.grid.major.x = element_line(\n      linetype = 2,\n      colour = \"lightgrey\"\n    ),\n    legend.position = \"none\",\n    axis.text = element_text(\n      hjust = 0.5,\n      family = \"body_font\",\n      size = 3.5 * ts,\n      colour = text_col,\n      lineheight = 0.35,\n      margin = margin(0, 5, 0, 0, unit = \"mm\")\n    ),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      family = \"body_font\",\n      size = 3.5 * ts,\n      colour = text_col,\n      lineheight = 0.35,\n      margin = margin(2, 0, 0, 0, unit = \"mm\")\n    )\n  )\n\ng &lt;- g1 +\n  patchwork::inset_element(\n    g2,\n    left = 0,\n    bottom = 0.02,\n    right = 0.67,\n    top = 0.25,\n    align_to = \"full\",\n    clip = FALSE,\n    on_top = TRUE\n  ) +\n  patchwork::inset_element(\n    g3,\n    left = 0.67,\n    bottom = 0.02,\n    right = 1,\n    top = 0.25,\n    align_to = \"full\",\n    clip = FALSE,\n    on_top = TRUE\n  ) \n\n# =============================================================================#\n# Image Saving-----------------------------------------------------------------\n# =============================================================================#\n\nggsave(\n  filename = here::here(\"docs\", \"dip_fatal_police_pursuits.png\"),\n  plot = g,\n  width = 40,\n  height = 45,\n  units = \"cm\",\n  bg = bg_col\n)\n\n\n\n\n\n\n\n\nFigure¬†5: Geographical distribution, race, age and role of persons killed in Police Chases in the United States (2017 - 2022)\n\n\n\nAnother map in Figure¬†6 shows the distribution of fatal police chases in California overlaid on major highways drawn from Open Street Maps ( et al. 2017).\n\n\nCode\n# Load additional libraries\nlibrary(osmdata)      # wrapper for Overpass API from Open Street Maps\nlibrary(sf)           # library for manipulating Simple features objects\n\n# Get California sf geomtetry map\ncal_map &lt;- usmapdata::us_map(\n  include = \"CA\",\n  regions = c(\"counties\")\n)\n\n# Get California Highway Data: Open Street Maps\ncal &lt;- opq(\"California\")\n\n# Get California Motorways\ncal_roads &lt;- cal |&gt;\n  add_osm_feature(\n    key = \"highway\",\n    value = \"motorway\") |&gt;\n  osmdata_sf()\n\nmain_roads &lt;- cal_roads$osm_lines |&gt;\n  st_transform(crs = st_crs(cal_map)) |&gt; \n  st_intersection(cal_map)\n\n# Get California Trunk Roads\ncal_trunk_roads &lt;- cal |&gt;\n  add_osm_feature(\n    key = \"highway\",\n    value = \"trunk\") |&gt;\n  osmdata_sf()\n\ntrunk_roads &lt;- cal_trunk_roads$osm_lines |&gt;\n  st_transform(crs = st_crs(cal_map)) |&gt; \n  st_intersection(cal_map)\n\n# Getting Fatal Police Chase Crashes data for California\ncal_crashes &lt;- police |&gt;\n  filter(state == \"CA\") |&gt; \n  filter(centroid_geo == 0) |&gt; \n  usmap_transform(\n    input_names = c(\"long\", \"lat\")\n  ) |&gt; \n  as_tibble() |&gt; \n  extract(\n    col = geometry, \n    into = c('x', 'y'), \n    regex = \"\\\\((.*), (.*)\\\\)\", \n    convert = TRUE) |&gt; \n  mutate(\n    race = case_when(\n      str_detect(race, \"unknown\") ~ \"Unknown\",\n      str_detect(race, \"black\") ~ \"Black\", # Disclaimer: a little bias introduced by data cleaning as data-rows with any one entry as black will be treated as \"Black\"\n      str_detect(race, \"white\") ~ \"White\", # Dislcaimer: Similar data bias\n      str_detect(race, \"latino\") ~ \"Latino\",\n      .default = \"Others\"\n    ),\n    race = fct(race, levels = c(\"Black\", \"White\", \"Latino\", \"Others\", \"Unknown\")),\n    person_role = case_when(\n      person_role %in% c(\"driver\") ~ \"Driver\",\n      person_role == \"bystander\" ~ \"Bystander\",\n      person_role == \"passenger\" ~ \"Passenger\",\n      .default = \"Unknown\"\n    ),\n    person_role = fct(\n      person_role,\n      levels = c(\"Driver\", \"Bystander\", \"Passenger\", \"Unknown\")\n    )\n  )\n# Ready some data for inset plot\n\nsideplotdf &lt;- bind_rows(\n  cal_crashes |&gt; \n    count(person_role) |&gt; \n    mutate(type = \"Role of Victim\", .before = everything()) |&gt; \n    rename(variable = person_role),\n  \n  cal_crashes |&gt; \n    mutate(initial_reason = case_when(\n      initial_reason == \"suspected nonviolent\" ~ \"Suspected\\nNon-Violent\",\n      initial_reason == \"suspected violent\" ~ \"Suspected\\nViolent\",\n      initial_reason == \"traffic stop\" ~ \"Traffic Stop\",\n      is.na(initial_reason) ~ \"Not Known\",\n      .default = \"Others\"\n    )) |&gt; \n    count(initial_reason) |&gt; \n    mutate(type = \"Reason of Police Chase\", .before = everything()) |&gt; \n    rename(variable = initial_reason),\n  \n  cal_crashes |&gt; \n    count(race) |&gt; \n    mutate(type = \"Race of Victim\", .before = everything()) |&gt; \n    rename(variable = race)\n)\n\n# Changing some colours for caption\nsocial_caption_1 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{github_username}  &lt;/span&gt;\")\nsocial_caption_2 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{xtwitter_username}&lt;/span&gt;\")\nplot_caption &lt;- paste0(\"**Data:** The San Francisco Chronicle\", \" | \", \" **Code:** \", social_caption_1, \" | \", \" **Graphics:** \", social_caption_2)\n\np1 &lt;- ggplot() +\n  geom_sf(\n    data = cal_map,\n    colour = \"white\",\n    fill = \"#e8e8e8\"\n  ) +\n  geom_sf(\n    data = trunk_roads,\n    linewidth = 0.3,\n    alpha = 0.5\n  ) +\n  geom_sf(\n    data = main_roads,\n    linewidth = 0.6,\n    alpha = 0.6\n  ) +\n  geom_point(\n    data = cal_crashes,\n    aes(\n      x = x,\n      y = y,\n      size = number_killed,\n      fill = race\n    ),\n    alpha = 0.3,\n    colour = \"black\",\n    pch = 21\n  ) +\n  scale_x_continuous(expand = expansion(c(0.05, 0.5))) +\n  scale_fill_manual(\n    values = c(\"black\", \"orange\", \"darkgreen\", \"#949494\", \"#bfbfbf\")\n  ) +\n  scale_size(\n    range = c(5, 8)\n  ) +\n  guides(\n    fill = guide_legend(\n      override.aes = list(\n        size = 8\n      )\n    ),\n    size = guide_legend(\n      override.aes = list(\n        colour = \"black\",\n        alpha = 1\n      )\n    )\n  ) +\n  labs(\n    title = \"Fatal Police Chases\",\n    caption = plot_caption,\n    fill = \"Race of Victim\",\n    size = \"Fatalities\"\n  ) +\n  ggthemes::theme_map() +\n  theme(\n    legend.position.inside = c(0, 0.08),\n    legend.direction = \"vertical\",\n    legend.box = \"vertical\",\n    plot.title = element_text(\n      colour = text_hil,\n      size = 12 * ts,\n      family = \"title_font\",\n      hjust = 0.5,\n      margin = margin(1, 0, 0, 0, unit = \"cm\")\n    ),\n    plot.subtitle = element_text(\n      colour = text_col,\n      size = 4 * ts,\n      family = \"body_font\",\n      hjust = 0.5,\n      lineheight = 0.35\n    ),\n    plot.caption = element_textbox(\n      colour = text_col,\n      hjust = 0.5,\n      family = \"caption_font\",\n      size = 3 * ts\n    ),\n    legend.title = element_text(\n      colour = text_col,\n      hjust = 0,\n      size = 4 * ts,\n      family = \"body_font\",\n      margin = margin(2,0,2,2, unit = \"mm\")\n    ),\n    legend.text = element_text(\n      colour = text_col,\n      hjust = 0,\n      size = 3 * ts,\n      family = \"body_font\",\n      margin = margin(2,0,2,2, unit = \"mm\")\n    ),\n    legend.background = element_rect(\n      fill = \"transparent\"\n    )\n  )\n\n\np2 &lt;- sideplotdf |&gt; \n  ggplot(aes(x = n, y = reorder(variable, n))) +\n  geom_col(\n    colour = \"#525252\",\n    fill = \"grey\",\n    alpha = 0.4\n  ) +\n  facet_wrap(~ type, scales = \"free_y\", ncol = 1) +\n  scale_x_reverse(\n    expand = expansion(0),\n    breaks = c(0, 50, 100)\n  ) +\n  scale_y_discrete(\n    position = \"right\"\n  ) +\n  labs(\n    x = NULL, \n    y = NULL,\n    subtitle = str_wrap(\"Most deaths in police car chases in California occurred on Highways in and around major cities. The race, role and reasons for deaths are:\",  40),\n    title = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    plot.subtitle = element_text(\n      colour = text_col,\n      size = 5.5 * ts,\n      family = \"body_font\",\n      hjust = 1,\n      lineheight = 0.3,\n      margin = margin(10, 0, 0, 0, unit = \"mm\")\n    ),\n    strip.text = element_text(\n      colour = text_col,\n      hjust = 0.5,\n      size = 5 * ts,\n      family = \"body_font\",\n      margin = margin(3,0,0,0, unit = \"mm\")\n    ),\n    axis.text.y = element_text(\n      colour = text_col,\n      hjust = 0,\n      size = 3 * ts,\n      family = \"caption_font\",\n      margin = margin(3,0,0,0, unit = \"mm\"),\n      lineheight = 0.19\n    ),\n    axis.text.x = element_text(\n      colour = text_col,\n      hjust = 0.5,\n      size = 4 * ts,\n      family = \"body_font\",\n      margin = margin(3,0,0,0, unit = \"mm\"),\n      lineheight = 0.18\n    ),\n    panel.grid = element_blank(),\n    panel.grid.major.x = element_line(\n      linetype = 2,\n      colour = text_col,\n      linewidth = 0.3\n    ),\n    plot.title.position = \"plot\"\n  )\n\n\np &lt;- p1 +\n  inset_element(\n    p2, \n    left = 0.5,\n    top = 1,\n    bottom = 0.25,\n    right = 1,\n    align_to = \"panel\"\n  )\n\nggsave(\n  filename = here::here(\"docs\", \"dip_fpp_cal.png\"),\n  plot = p,\n  width = 38,\n  height = 45,\n  units = \"cm\",\n  bg = \"white\"\n)\n\n\n\n\n\n\n\n\nFigure¬†6: Most deaths in police car chases in California occurred on Highways in and around major cities. The bar-plots on the right show distribution of race, role and reasons for the victims. We conclude that most commonly victims are white, drivers and reasons are not known. An important insight is that Blacks (and, to some extent, whites) are disproportionately high in victims of police car chase crashes compared to their population.\n\n\n\nAnd, finally, the Figure¬†7 shows similar analysis for the State of Texas, in a different colour theme.\n\n\nCode\ntb1 &lt;- police |&gt; \n  select(-c(unique_id, year, news_urls)) |&gt; \n  mutate(\n    date = mdy(date),\n    month = month(date, label = TRUE),\n    year = year(date)\n  ) |&gt; \n  mutate(\n    race = case_when(\n      str_detect(race, \"unknown\") ~ \"Unknown\",\n      str_detect(race, \"black\") ~ \"Black\", # Disclaimer: a little bias introduced by data cleaning as data-rows with any one entry as black will be treated as \"Black\"\n      str_detect(race, \"white\") ~ \"White\", # Dislcaimer: Similar data bias\n      str_detect(race, \"latino\") ~ \"Latino\",\n      .default = \"Others\"\n    ),\n    race = fct(race, levels = c(\"Black\", \"White\", \"Latino\", \"Others\", \"Unknown\")),\n    person_role = case_when(\n      person_role %in% c(\"driver\") ~ \"Driver\",\n      person_role == \"bystander\" ~ \"Bystander\",\n      person_role == \"passenger\" ~ \"Passenger\",\n      person_role == \"officer\" ~ \"Officer\",\n      .default = \"Unknown\"\n    ),\n    person_role = fct(\n      person_role,\n      levels = c(\"Driver\", \"Bystander\", \"Passenger\", \"Officer\", \"Unknown\")\n    )\n  )\n\n# Doing some exploratory data analysis to get trends\ntb1 |&gt; \n  group_by(month) |&gt; \n  count(race, wt = number_killed) |&gt; \n  ggplot(aes(x = month, y = n, fill = race)) +\n  geom_col()\n\ntb1 |&gt; \n  group_by(race_source) |&gt; \n  count(race) |&gt; \n  ggplot(aes(x = race_source, y = n, fill = race)) +\n  geom_col()\n\ntb1 |&gt; \n  group_by(state) |&gt; \n  count(race) |&gt; \n  mutate(total = sum(n)) |&gt; \n  filter(total &gt;= 100) |&gt; \n  ggplot(aes(x = state, y = n, fill = race)) +\n  geom_col(position = \"fill\")\n\ntb1 |&gt; \n  group_by(state) |&gt; \n  count(person_role, wt = number_killed) |&gt; \n  mutate(total = sum(n)) |&gt; \n  filter(total &gt; 50) |&gt; \n  filter(person_role != \"Unknown\") |&gt; \n  ggplot(aes(x = state, y = n, fill = person_role)) +\n  geom_col(position = \"fill\")\n\ntb1 |&gt; \n  group_by(year) |&gt; \n  count(gender, wt = number_killed) |&gt; \n  mutate(total = sum(n)) |&gt; \n  filter(total &gt; 50) |&gt; \n  ggplot(aes(x = year, y = n, fill = gender)) +\n  geom_col(position = \"fill\")\n\n\n# Load additional libraries\nlibrary(osmdata)      # wrapper for Overpass API from Open Street Maps\nlibrary(sf)           # library for manipulating Simple features objects\n\n# Get California sf geomtetry map\ntx_map &lt;- usmapdata::us_map(\n  include = \"TX\",\n  regions = c(\"counties\")\n)\n\n# Get California Highway Data: Open Street Maps\ncal &lt;- opq(\"Texas\")\n\n# Get California Motorways\ntx_roads &lt;- cal |&gt;\n  add_osm_feature(\n    key = \"highway\",\n    value = \"motorway\") |&gt;\n  osmdata_sf()\n\nmain_roads &lt;- tx_roads$osm_lines |&gt;\n  st_transform(crs = st_crs(tx_map)) |&gt; \n  st_intersection(tx_map)\n\n# Get California Trunk Roads\ntx_trunk_roads &lt;- cal |&gt;\n  add_osm_feature(\n    key = \"highway\",\n    value = \"trunk\") |&gt;\n  osmdata_sf()\n\ntrunk_roads &lt;- tx_trunk_roads$osm_lines |&gt;\n  st_transform(crs = st_crs(tx_map)) |&gt; \n  st_intersection(tx_map)\n\n# Getting Fatal Police Chase Crashes data for California\ntx_crashes &lt;- police |&gt;\n  filter(state == \"TX\") |&gt; \n  filter(centroid_geo == 0) |&gt; \n  usmap_transform(\n    input_names = c(\"long\", \"lat\")\n  ) |&gt; \n  as_tibble() |&gt; \n  extract(\n    col = geometry, \n    into = c('x', 'y'), \n    regex = \"\\\\((.*), (.*)\\\\)\", \n    convert = TRUE) |&gt; \n  mutate(\n    race = case_when(\n      str_detect(race, \"unknown\") ~ \"Unknown\",\n      str_detect(race, \"black\") ~ \"Black\", # Disclaimer: a little bias introduced by data cleaning as data-rows with any one entry as black will be treated as \"Black\"\n      str_detect(race, \"white\") ~ \"White\", # Dislcaimer: Similar data bias\n      str_detect(race, \"latino\") ~ \"Latino\",\n      .default = \"Others\"\n    ),\n    race = fct(race, levels = c(\"Black\", \"White\", \"Latino\", \"Others\", \"Unknown\")),\n    person_role = case_when(\n      person_role %in% c(\"driver\") ~ \"Driver\",\n      person_role == \"bystander\" ~ \"Bystander\",\n      person_role == \"passenger\" ~ \"Passenger\",\n      .default = \"Unknown\"\n    ),\n    person_role = fct(\n      person_role,\n      levels = c(\"Driver\", \"Bystander\", \"Passenger\", \"Unknown\")\n    )\n  )\n# Ready some data for inset plot\n\nsideplotdf &lt;- bind_rows(\n  tx_crashes |&gt; \n    count(person_role) |&gt; \n    mutate(type = \"Role of Victim\", .before = everything()) |&gt; \n    rename(variable = person_role),\n  \n  tx_crashes |&gt; \n    mutate(initial_reason = case_when(\n      initial_reason == \"suspected nonviolent\" ~ \"Suspected\\nNon-Violent\",\n      initial_reason == \"suspected violent\" ~ \"Suspected\\nViolent\",\n      initial_reason == \"traffic stop\" ~ \"Traffic Stop\",\n      is.na(initial_reason) ~ \"Not Known\",\n      .default = \"Not Known\"\n    )) |&gt; \n    count(initial_reason) |&gt; \n    mutate(type = \"Reason of Police Chase\", .before = everything()) |&gt; \n    rename(variable = initial_reason),\n  \n  tx_crashes |&gt; \n    count(race) |&gt; \n    mutate(type = \"Race of Victim\", .before = everything()) |&gt; \n    rename(variable = race)\n) |&gt; \n  group_by(type) |&gt; \n  mutate(n = n / sum(n)) |&gt; \n  ungroup() |&gt; \n  mutate(per_pop = c(rep(NA, 9), 0.12, 0.40, 0.40, 0.08, 0.0))\n\n# Changing some colours for caption\nsocial_caption_1 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{github_username}  &lt;/span&gt;\")\nsocial_caption_2 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_col}'&gt;{xtwitter_username}&lt;/span&gt;\")\nplot_caption &lt;- paste0(\"**Data:** The San Francisco Chronicle\", \" | \", \" **Code:** \", social_caption_1, \" | \", \" **Graphics:** \", social_caption_2)\n\n# Changing some colours\nbg_col = \"black\"\ntext_col = \"#ffe6e3\"\ntext_hil &lt;- \"#ff6a59\"\n\np1 &lt;- ggplot() +\n  geom_sf(\n    data = tx_map,\n    colour = \"#636363\",\n    fill = \"#404040\"\n  ) +\n  geom_sf(\n    data = trunk_roads,\n    linewidth = 0.3,\n    alpha = 0.5,\n    colour = \"white\"\n  ) +\n  geom_sf(\n    data = main_roads,\n    linewidth = 0.6,\n    alpha = 0.6,\n    colour = \"white\"\n  ) +\n  geom_point(\n    data = tx_crashes,\n    aes(\n      x = x,\n      y = y,\n      size = number_killed,\n      fill = race\n    ),\n    alpha = 0.3,\n    colour = \"white\",\n    pch = 21\n  ) +\n  scale_x_continuous(\n    expand = expansion(c(0.05, 0.55))\n  ) +\n  scale_y_continuous(\n    expand = expansion(c(0, 0.05))\n  ) +\n  scale_fill_manual(\n    values = c(\"#F5433FFF\",\"#F8DE02FF\", \"#579CE9FF\", \"#CAC7BBFF\", \"#CAC7BBFF\")\n  ) +\n  scale_size(\n    range = c(5, 8)\n  ) +\n  guides(\n    fill = guide_legend(\n      override.aes = list(\n        size = 8,\n        alpha = 1\n      )\n    ),\n    size = guide_legend(\n      override.aes = list(\n        colour = \"white\",\n        alpha = 1\n      )\n    )\n  ) +\n  labs(\n    title = \"Police Chase Deaths\",\n    caption = plot_caption,\n    fill = \"Race of Victim\",\n    size = \"Fatalities\"\n  ) +\n  ggthemes::theme_map() +\n  theme(\n    legend.position.inside = c(0, 0),\n    legend.direction = \"vertical\",\n    legend.box = \"horizontal\",\n    plot.title = element_text(\n      colour = text_hil,\n      size = 15 * ts,\n      family = \"title_font\",\n      hjust = 0.5,\n      margin = margin(1, 0, 0, 0, unit = \"cm\")\n    ),\n    plot.subtitle = element_text(\n      colour = text_col,\n      size = 4 * ts,\n      family = \"body_font\",\n      hjust = 0.5,\n      lineheight = 0.35\n    ),\n    plot.caption = element_textbox(\n      colour = text_col,\n      hjust = 0.5,\n      family = \"caption_font\",\n      size = 3 * ts\n    ),\n    legend.title = element_text(\n      colour = text_col,\n      hjust = 0,\n      size = 4 * ts,\n      family = \"body_font\",\n      margin = margin(0,0,0,2, unit = \"mm\")\n    ),\n    legend.text = element_text(\n      colour = text_col,\n      hjust = 0,\n      size = 3 * ts,\n      family = \"body_font\",\n      margin = margin(0,0,0,2, unit = \"mm\")\n    ),\n    legend.background = element_rect(\n      fill = \"transparent\"\n    ),\n    plot.background = element_rect(\n      fill = bg_col,\n      colour = bg_col\n    )\n  )\n\np2 &lt;- sideplotdf |&gt; \n  ggplot(aes(\n    x = n, \n    y = reorder(variable, n))) +\n  geom_col(\n    colour = \"white\",\n    fill = \"grey\",\n    alpha = 0.5\n  ) +\n  ungeviz::geom_vpline(\n    aes(\n      x = per_pop\n    ),\n    height = 0.8,\n    size = 2,\n    col = \"white\"\n  ) +\n  facet_wrap(~ type, scales = \"free_y\", ncol = 1) +\n  scale_x_reverse(\n    label = label_percent(),\n    breaks = c(0, 0.25, 0.5),\n    expand = expansion(c(0.5, 0))\n  ) +\n  scale_y_discrete(\n    position = \"right\"\n  ) +\n  labs(\n    x = NULL, \n    y = NULL,\n    subtitle = str_wrap(\"Most deaths in police car chases in Texas occurred on Highways and near major cities. Fatalities involving blacks were mostly concentrated in urban areas.\",  55),\n    title = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    plot.subtitle = element_text(\n      colour = text_col,\n      size = 4 * ts,\n      family = \"body_font\",\n      hjust = 1,\n      lineheight = 0.3,\n      margin = margin(10, 25, 0, 0, unit = \"mm\")\n    ),\n    strip.text = element_text(\n      colour = text_col,\n      hjust = 1,\n      size = 4.5 * ts,\n      family = \"body_font\",\n      margin = margin(3,0,0,0, unit = \"mm\")\n    ),\n    axis.text.y = element_text(\n      colour = text_col,\n      hjust = 0,\n      size = 3 * ts,\n      family = \"caption_font\",\n      margin = margin(3,0,0,0, unit = \"mm\"),\n      lineheight = 0.19\n    ),\n    axis.text.x = element_text(\n      colour = text_col,\n      hjust = 0.5,\n      size = 4 * ts,\n      family = \"body_font\",\n      margin = margin(3,0,0,0, unit = \"mm\"),\n      lineheight = 0.18\n    ),\n    panel.grid = element_blank(),\n    panel.grid.major.x = element_line(\n      linetype = 2,\n      colour = text_col,\n      linewidth = 0.3\n    ),\n    plot.title.position = \"plot\"\n  )\n\n# A Third Annotation plot\np3 &lt;- tibble(\n  label = \"This White bar shows the % Population\\nof each race in Texas (2022)\"\n) |&gt; \n  ggplot(aes(x = 1, y = 1, label = label)) +\n  geom_text(\n    colour = \"white\",\n    hjust = 0.5,\n    family = \"caption_font\",\n    size = ts,\n    lineheight = 0.25\n  ) +\n  theme_void() +\n  theme(plot.background = element_rect(\n    fill = \"transparent\",\n    colour = \"transparent\"\n  ))\n\n# A fourth plot to Label Texas\np4 &lt;- tibble(\n  label = \"Texas\"\n) |&gt; \n  ggplot(aes(x = 1, y = 1, label = label)) +\n  geom_text(\n    colour = text_hil,\n    hjust = 0.5,\n    family = \"title_font\",\n    size = 3.5 * ts,\n    lineheight = 0.25\n  ) +\n  theme_void() +\n  theme(plot.background = element_rect(\n    fill = \"transparent\",\n    colour = \"transparent\"\n  ))\n\np &lt;- p1 +\n  inset_element(\n    p2, \n    left = 0.55,\n    top = 1,\n    bottom = 0.0,\n    right = 1,\n    align_to = \"panel\"\n  ) +\n  inset_element(\n    p3, \n    left = 0.66,\n    right = 0.89,\n    top = 0.63,\n    bottom = 0.59,\n    align_to = \"panel\"\n  ) +\n  inset_element(\n    p4, \n    left = 0,\n    right = 0.2,\n    top = 1,\n    bottom = 0.8,\n    align_to = \"panel\"\n  ) +\n  plot_annotation(\n    theme = theme(\n      plot.background = element_rect(\n        fill = \"transparent\",\n        colour = \"black\"\n      )\n    )\n  )\n\nggsave(\n  filename = here::here(\"docs\", \"dip_fpp_tx.png\"),\n  plot = p,\n  width = 45,\n  height = 35,\n  units = \"cm\",\n  bg = \"black\"\n)\n\n\n\n\n\n\n\n\nFigure¬†7: Most deaths in police car chases in Texas occurred on Highways and near major cities. Fatalities involving blacks were mostly concentrated in urban areas."
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-11-fiscal-sponsors",
    "href": "projects/tidy_tuesday.html#week-11-fiscal-sponsors",
    "title": "Data Visualization Projects",
    "section": "Week 11: Fiscal Sponsors",
    "text": "Week 11: Fiscal Sponsors\nThe dataset comes from the Fiscal Sponsor Directory, which analyzed their directory in March 2023. | #TidyTuesday | Code | Data\n\n\n\nThe stream-plots show the popularity of different fiscal sponsorship models over the years amongst 4 major fields of project-sponsorship. Of late, the Model C (Pre-approved Grant Relationship) has become most popular."
  },
  {
    "objectID": "projects/dip_viz.html#d.i.p.-2024.03.13-humanitarian-emergency-mapping.",
    "href": "projects/dip_viz.html#d.i.p.-2024.03.13-humanitarian-emergency-mapping.",
    "title": "Data Visualizations from D.I.P.",
    "section": "D.I.P. 2024.03.13: Humanitarian emergency mapping.",
    "text": "D.I.P. 2024.03.13: Humanitarian emergency mapping.\nUtilizing R, ggplot2, and sf packages, Figure¬†8 depicts the extensive building damage across the Gaza Strip, leveraging satellite data sourced from the United Nations Satellite Centre (UNOSAT) and United Nations Institute for Training and Research (UNITAR). Additionally, significant agricultural field devastation, notably concentrated around Gaza City in the north, is highlighted.\n\n\nCode\n# =============================================================================#\n# About the Dataset-------------------------------------------------------------\n# =============================================================================#\n\n# URL: https://unosat.org/products/3793\n# The UNOSAT Gaza Strip Comprehensive Damage Assessment for January 2024 \n# presents a thorough evaluation of structural damage and destruction based \n# on satellite imagery. The assessment compares images from January 6 and 7, \n# 2024, with those taken on May 1, 2023, May 10, 2023, September 18, 2023, \n# October 15, 2023, November 7, 2023, and November 26, 2023. According to the \n# analysis, 22,130 structures were destroyed, 14,066 severely damaged, and \n# 32,950 moderately damaged, totaling 69,146 structures. This represents \n# approximately 30% of all structures in the Gaza Strip, estimating 93,800 \n# damaged housing units. Notably, Gaza and Khan Yunis governorates experienced \n# significant damage increases, with 10,319 and 11,893 structures newly damaged,\n# respectively. Gaza City saw the highest number of newly destroyed structures, \n# totaling 8,926. It's important to note that this analysis is preliminary \n# and awaits field validation.\n\n\n# =============================================================================#\n# Findings ---------------------------------------------------------------------\n# =============================================================================#\n\n# Most damage is concentrated around two major cities: Gaza City and Khan \n# Younis; and in the agricultural fields surrounding it.\n\n# =============================================================================#\n# Library Load-in---------------------------------------------------------------\n# =============================================================================#\n\n# Data Wrangling Tools\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\nlibrary(sf)\n\n# Final plot (ggplot2) tools\nlibrary(scales)\nlibrary(fontawesome)\nlibrary(ggtext)\nlibrary(showtext)\nlibrary(colorspace)\nlibrary(usmap)\nlibrary(usmapdata)\nlibrary(ggthemes)\nlibrary(patchwork)\n\n# =============================================================================#\n# Data Load-in, EDA & Data Wrangling--------------------------------------------\n# =============================================================================#\n\ngaza1 &lt;- read_sf(here(\"data\", \"UNOSAT_GazaStrip_Agriculture_DA_GDB_January2024.zip\"))\n\n\ngaza2 &lt;- read_sf(here(\"data\", \"UNOSAT_GazaStrip_CDA_January2024_GDB_V2.zip\")) \n\ngaza2 &lt;- gaza2 |&gt; \n  filter(Damage_Status_4 == 3 | Damage_Status_4 == 0)\n\n\ngaza_b &lt;- read_sf(here(\"data\", \"gazastrip_municipalboundaries\", \"GazaStrip_MunicipalBoundaries.shp\"))\n\n# =============================================================================#\n# Options & Visualization Parameters--------------------------------------------\n# =============================================================================#\n\n# Load fonts\n# Font for titles\nfont_add_google(\"Road Rage\",\n  family = \"title_font\"\n) \n\n# Font for the caption\nfont_add_google(\"Saira Extra Condensed\",\n  family = \"caption_font\"\n) \n\n# Font for plot text\nfont_add_google(\"Bubbler One\",\n  family = \"body_font\"\n) \n\nshowtext_auto()\n\n# Define colours\nmypal &lt;- paletteer::paletteer_d(\"lisa::FridaKahlo\")\nmypal2 &lt;- c(\"#121510FF\", \"#6D8325FF\", \"#D6CFB7FF\", \"#E5AD4FFF\", \"#BD5630FF\")\n\nbg_col &lt;- mypal[3] # Background Colour\ntext_col &lt;- mypal[1] # Colour for the text\ntext_hil &lt;- mypal[5] |&gt; darken(0.3) # Colour for highlighted text\n\n# Define Text Size\nts &lt;- unit(20, units = \"cm\") # Text Size\n\n# Caption stuff\nsysfonts::font_add(\n  family = \"Font Awesome 6 Brands\",\n  regular = here::here(\"docs\", \"Font Awesome 6 Brands-Regular-400.otf\")\n)\ngithub &lt;- \"&#xf09b\"\ngithub_username &lt;- \"aditya-dahiya\"\nxtwitter &lt;- \"&#xe61b\"\nxtwitter_username &lt;- \"@adityadahiyaias\"\nsocial_caption_1 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_hil}'&gt;{github_username}  &lt;/span&gt;\")\nsocial_caption_2 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_hil}'&gt;{xtwitter_username}&lt;/span&gt;\")\n\n\n# Add text to plot--------------------------------------------------------------\nplot_title &lt;- \"Gaza's Shattered Spaces\"\nplot_caption &lt;- paste0(\"**Data:** UNOSAT by United Nations Institute for Training and Research (UNITAR)\", \" | \", \" **Code:** \", social_caption_1, \" | \", \" **Graphics:** \", social_caption_2)\nsubtitle_text &lt;- \"Utilizing R, ggplot2, and sf packages, we depict\\nextensive building damage in Gaza Strip\\nusing satellite data from UNOSAT and\\nUNITAR. Significant agricultural field\\ndevastation,especially in\\nnorthern Gaza Strip,\\nis also highlighted.\"\nplot_subtitle &lt;- subtitle_text\n\n# ==============================================================================#\n# Data Visualization------------------------------------------------------------\n# ==============================================================================#\n\ng &lt;- ggplot() +\n  geom_sf(\n    data = gaza1,\n    aes(fill = Classname),\n    colour = bg_col\n  ) +\n  scale_fill_manual(\n    values = c(mypal[1], mypal[2]),\n    labels = c(\n      \"Damaged agricultural land\",\n      \"Unaffected agricultural land\"\n    )\n    ) +\n  geom_sf(\n    data = gaza2,\n    aes(colour = factor(Damage_Status_4)),\n    alpha = 0.5,\n    size = 0.9,\n    pch = 20\n  ) +\n  scale_colour_manual(\n    values = c(mypal[4], mypal[5]),\n    labels = c(\"Partial Building Damage\", \"Severe Building Damage\")\n  ) +\n  scale_x_continuous(expand = expansion(0)) +\n  scale_y_continuous(expand = expansion(0)) +\n  labs(\n    x = NULL, \n    y = NULL,\n    fill = \"Agricultural land status\",\n    colour = \"Buildings' damage status\",\n    caption = plot_caption) +\n  geom_sf(\n    data = gaza_b,\n    colour = mypal[1],\n    fill = \"transparent\",\n    linewidth = 0.5\n  ) +\n  geom_sf_label(\n    data = gaza_b,\n    aes(label = NAME),\n    size = ts,\n    colour = text_col,\n    hjust = 0.5,\n    family = \"body_font\",\n    fill = bg_col,\n    alpha = 0.7,\n    na.rm = TRUE,\n    label.padding = unit(0.1, \"lines\")\n  ) +\n  guides(\n    fill = guide_legend(\n      override.aes = list(\n        size = 10\n      )\n    ),\n    colour = guide_legend(\n      override.aes = list(\n        size = 20,\n        alpha = 1\n      )\n    )\n  ) +\n  annotate(\n    geom = \"text\",\n    x = 34.20, y = 31.57,\n    label = plot_title,\n    family = \"title_font\",\n    size = 6 * ts,\n    colour = text_hil,\n    hjust = 0,\n    vjust = 1\n  ) +\n  annotate(\n    geom = \"text\",\n    x = 34.20, y = 31.53,\n    label = plot_subtitle,\n    family = \"body_font\",\n    size = 2 * ts,\n    colour = text_col,\n    hjust = 0,\n    vjust = 1,\n    lineheight = 0.4\n  ) +\n  theme_map() +\n  theme(\n    legend.position.inside = c(0.6, 0.2),\n    plot.background = element_rect(\n      fill = mypal[3],\n      colour = mypal[3]\n    ),\n    legend.title = element_text(\n      family = \"body_font\",\n      size = 7 * ts,\n      hjust = 0,\n      colour = text_col,\n      margin = margin(5, 0, 5, 0, unit = \"mm\")\n    ),\n    legend.text = element_text(\n      family = \"body_font\",\n      size = 5 * ts,\n      hjust = 0,\n      vjust = 0.5,\n      colour = text_col,\n      margin = margin(5, 0, 5, 5, unit = \"mm\")\n    ),\n    legend.background = element_rect(\n      fill = \"transparent\",\n      colour = \"transparent\"\n    ),\n    legend.box.background = element_rect(\n      fill = \"transparent\",\n      colour = \"transparent\"\n    ),\n    legend.box.spacing = unit(4, \"cm\"),\n    plot.caption = element_textbox(\n      family = \"caption_font\",\n      size = 3 * ts,\n      hjust = 0.5,\n      colour = text_hil\n    )\n  )\n\n# =============================================================================#\n# Image Saving-----------------------------------------------------------------\n# =============================================================================#\n\nggsave(\n  filename = here::here(\"docs\", \"dip_gaza_agri.png\"),\n  plot = g,\n  width = 40,\n  height = 45,\n  units = \"cm\",\n  bg = mypal[3]\n)\n\n\n\n\n\n\n\n\nFigure¬†8: Building Damage and Agricultural Fields destruction in Gaza city - using ggplot2 and sf packages"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-12-x-men-mutant-moneyball",
    "href": "projects/tidy_tuesday.html#week-12-x-men-mutant-moneyball",
    "title": "Data Visualization Projects",
    "section": "Week 12: X-Men Mutant Moneyball",
    "text": "Week 12: X-Men Mutant Moneyball\nThis week‚Äôs data is X-Men Mutant Moneyball from Rally‚Äôs Mutant moneyball: a data driven ultimate X-men by Anderson Evans | #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-12-x-men-mutant-money-ball",
    "href": "projects/tidy_tuesday.html#week-12-x-men-mutant-money-ball",
    "title": "Data Visualization Projects",
    "section": "Week 12: X-Men Mutant Money-Ball",
    "text": "Week 12: X-Men Mutant Money-Ball\nThis week‚Äôs data is X-Men Mutant Moneyball from Rally‚Äôs Mutant moneyball: a data driven ultimate X-men by Anderson Evans | #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/tidy_tuesday.html#week-13-ncaa-mens-march-madness",
    "href": "projects/tidy_tuesday.html#week-13-ncaa-mens-march-madness",
    "title": "Data Visualization Projects",
    "section": "Week 13: NCAA Men‚Äôs March Madness",
    "text": "Week 13: NCAA Men‚Äôs March Madness\nThis week‚Äôs data is NCAA Men‚Äôs March Madness data from Nishaan Amin‚Äôs Kaggle dataset and analysis Bracketology: predicting March Madness | #TidyTuesday | Code | Data"
  },
  {
    "objectID": "projects/dip_viz.html#d.i.p.-2024.03.27-human-development-indexed.",
    "href": "projects/dip_viz.html#d.i.p.-2024.03.27-human-development-indexed.",
    "title": "Data Visualizations from D.I.P.",
    "section": "D.I.P. 2024.03.27: Human development, indexed.",
    "text": "D.I.P. 2024.03.27: Human development, indexed.\nIn Figure¬†9, we explore one of the most widely recognized measures, the United Nations‚Äô Human Development Index. It amalgamates data on life expectancy, per capita income, and educational attainment into a singular value for each country-year. The UN offers downloadable files for all yearly HDI rankings and sub-indicators spanning from 1990 to 2022. The best and worst performers are highlighted.\n\n\nCode\n# =============================================================================#\n# About the Dataset-------------------------------------------------------------\n# =============================================================================#\n\n# Source URL: https://hdr.undp.org/data-center/documentation-and-downloads\n# Credits: UNDP Human Development Reports\n# Human development, quantified. One of the most widely recognized measures, \n# the United Nations' Human Development Index amalgamates data on life \n# expectancy, per capita income, and educational attainment into a singular \n# value for each country-year. The UN offers downloadable files and an API \n# encompassing all yearly HDI rankings and sub-indicators spanning from 1990 to\n# 2022. These resources also encompass information from correlated indices like \n# the Inequality-adjusted Human Development Index, Gender Development Index, and \n# Gender Inequality Index.\n\n# =============================================================================#\n# Findings ---------------------------------------------------------------------\n# =============================================================================#\n\n# The best performing countries, in terms of HDI improvement between 1990 and \n# 2022 are: China, Myanmar, Bangladesh, Turkiye, and, Morocco\n# The wrost performing countries, in terms of HDI reduction / least increase\n# between 1990 and 2022 are: Syria, Ukraine, Namibia, Libya, and, San Marino\n\n# =============================================================================#\n# Library Load-in---------------------------------------------------------------\n# =============================================================================#\n\n# Data Wrangling Tools\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\nlibrary(sf)\n\n# Final plot (ggplot2) tools\nlibrary(scales)\nlibrary(fontawesome)\nlibrary(ggtext)\nlibrary(showtext)\nlibrary(colorspace)\n\n\n# =============================================================================#\n# Data Load-in, EDA & Data Wrangling--------------------------------------------\n# =============================================================================#\n\n# Read in the UNDP data\nurl &lt;- \"https://hdr.undp.org/sites/default/files/2023-24_HDR/HDR23-24_Composite_indices_complete_time_series.csv\"\n\nhdi &lt;- read_csv(url)\n\n# Number of countries to highlight in each\nnos &lt;- 5\n\n# A wide format and housekeeping to filter out relevant variables, and also\n# change names of some countries to easily recognizable names\ndfwide &lt;- hdi |&gt; \n  select(iso3, \n         country, \n         region, \n         (contains(\"hdi_\") & !(contains(\"_m_\")) & !(contains(\"_f_\")) & !(contains(\"ihdi\")) & !(contains(\"phdi\")) & !(contains(\"rank\"))\n          )\n         ) |&gt; \n  filter(!(country %in% c(\"East Asia and the Pacific\"))) |&gt; \n  mutate(country = if_else(country == \"T\\xfcrkiye\", \"Turkiye\", country),\n         country = if_else(country == \"Syrian Arab Republic\", \"Syria\", country))\n\n# Long (tidy) format of the data (needed for plotting facets in ggplot2)\ndf1 &lt;- dfwide |&gt; \n  pivot_longer(\n    cols = contains(\"hdi\"),\n    names_to = \"year\",\n    values_to = \"value\"\n  ) |&gt; \n  mutate(year = parse_number(year))\n\n# Improvement amongst countries\ndf_imp &lt;- dfwide |&gt; \n  mutate(improvement = hdi_2022 - hdi_1990) |&gt; \n  select(country, improvement)\n\n# Worst off countries\nleast_imp &lt;- df_imp |&gt; \n  slice_min(order_by = improvement, n = nos) |&gt; \n  pull(country)\n\n# Best improvement countries\nmost_imp &lt;- df_imp |&gt; \n  slice_max(order_by = improvement, n = nos) |&gt; \n  pull(country)\n\nleast_imp\nmost_imp\n# A tibble for actual percentage change in HDI - to show in graph\nchanges &lt;- bind_rows(\n  df_imp |&gt; \n    slice_min(order_by = improvement, n = nos),\n  df_imp |&gt; \n    slice_max(order_by = improvement, n = nos)\n) |&gt; \n  mutate(\n    improvement = round(100 * improvement, 1)\n  )\n\n# Tibble to actually use in plotting\nplotdf &lt;- df1 |&gt; \n  mutate(\n    most_improved = if_else(country %in% most_imp, country, NA),\n    least_improved= if_else(country %in% least_imp, country, NA)\n  ) |&gt; \n  pivot_longer(\n    cols = c(most_improved, least_improved),\n    names_to = \"facet_var\",\n    values_to = \"colour_var\"\n  ) |&gt; \n  mutate(colour_var = fct(colour_var, levels = c(least_imp, most_imp))) |&gt; \n  left_join(changes)\n# =============================================================================#\n# Options & Visualization Parameters--------------------------------------------\n# =============================================================================#\n\n# Load fonts\n# Font for titles\nfont_add_google(\"Racing Sans One\",\n  family = \"title_font\"\n) \n\n# Font for the caption\nfont_add_google(\"Saira Extra Condensed\",\n  family = \"caption_font\"\n) \n\n# Font for plot text\nfont_add_google(\"Jockey One\",\n  family = \"body_font\"\n) \n\nshowtext_auto()\n\n# Define colours\nreds &lt;- paletteer::paletteer_d(\"RColorBrewer::Reds\", direction = -1)[1:nos]\ngreens &lt;- paletteer::paletteer_d(\"RColorBrewer::Greens\", direction = -1)[1:nos]\nmypal &lt;- c(reds, greens)\n\n\nbg_col &lt;- \"#ffffff\"   # Background Colour\ntext_col &lt;- \"#404040\" # Colour for the text\ntext_hil &lt;- '#757575' # Colour for highlighted text\n\n# Define Text Size\nts &lt;- unit(20, units = \"cm\") # Text Size\n\n# Caption stuff\nsysfonts::font_add(\n  family = \"Font Awesome 6 Brands\",\n  regular = here::here(\"docs\", \"Font Awesome 6 Brands-Regular-400.otf\")\n)\ngithub &lt;- \"&#xf09b\"\ngithub_username &lt;- \"aditya-dahiya\"\nxtwitter &lt;- \"&#xe61b\"\nxtwitter_username &lt;- \"@adityadahiyaias\"\nsocial_caption_1 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{github};&lt;/span&gt; &lt;span style='color: {text_hil}'&gt;{github_username}  &lt;/span&gt;\")\nsocial_caption_2 &lt;- glue::glue(\"&lt;span style='font-family:\\\"Font Awesome 6 Brands\\\";'&gt;{xtwitter};&lt;/span&gt; &lt;span style='color: {text_hil}'&gt;{xtwitter_username}&lt;/span&gt;\")\n\n\n# Add text to plot--------------------------------------------------------------\nplot_title &lt;- \"Human Development Index\\n(Changes: 1990 - 2022)\"\nplot_caption &lt;- paste0(\"**Data:** UNDP Human Development Reports\", \" | \", \" **Code:** \", social_caption_1, \" | \", \" **Graphics:** \", social_caption_2)\nsubtitle_text &lt;- \"Since the 1990s, HDI has been used for gauging development. While most nations have seen an enhancement in living standards, the pace of improvement varies. This graph illustrates both the top and bottom performers (% change from 1990 to 2022 in brackets).\"\nplot_subtitle &lt;- str_wrap(subtitle_text, 90)\n\n# ==============================================================================#\n# Data Visualization------------------------------------------------------------\n# ==============================================================================#\n\nstrip_text &lt;- c(\n  \"&lt;b style='color:#CB181DFF'&gt;Least Improvement&lt;/b&gt;\", \n  \"&lt;b style='color:#006D2CFF'&gt;Highest improvement&lt;/b&gt;\"\n  )\nnames(strip_text) &lt;- c(\"least_improved\", \"most_improved\")\n\ng &lt;- plotdf |&gt; \n  ggplot(\n    aes(\n      x = year,\n      y = value,\n      group = country,\n      color = colour_var,\n      alpha = is.na(colour_var),\n      linewidth = is.na(colour_var)\n    )\n  ) +\n  geom_line() +\n  ggrepel::geom_text_repel(\n    data = (plotdf |&gt; filter(year == 2022)),\n    mapping = aes(\n      label = if_else(\n        !is.na(colour_var),\n        paste0(colour_var, \"\\n\", improvement, \" %\"),\n        NA\n      )\n    ),\n    force        = 10,\n    nudge_x      = 2.5,\n    direction    = \"y\",\n    hjust        = 0,\n    segment.size = 0.2,\n    size = 30,\n    lineheight = 0.25,\n    family = \"caption_font\",\n    fontface = \"bold\",\n    box.padding = 0\n  ) +\n  facet_wrap(\n    ~ facet_var,\n    labeller = labeller(facet_var = strip_text)\n  ) +\n  scale_x_continuous(\n    expand = expansion(c(0, 0.35)),\n    breaks = seq(1990, 2022, 8)\n  ) +\n  scale_y_continuous(\n    expand = expansion(0)\n  ) +\n  scale_alpha_discrete(range = c(1, 0.5)) +\n  scale_linewidth_discrete(range = c(2, 0.5)) +\n  scale_colour_manual(\n    values = mypal,\n    na.value = \"lightgrey\"\n  ) +\n  labs(\n    title = plot_title,\n    subtitle = plot_subtitle,\n    caption = plot_caption,\n    x = NULL,\n    y = \"H.D.I  (Human Development Index)\"\n  ) +\n  theme_minimal(\n     base_family = \"body_font\"\n  ) +\n  theme(\n    legend.position = \"none\",\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_line(\n      linewidth = 0.5,\n      colour = \"transparent\"\n    ),\n    panel.grid.major.x = element_line(\n      linewidth = 0.5,\n      linetype = 2,\n      colour = text_hil\n    ),\n    axis.line.x = element_line(\n      colour = text_hil,\n      linewidth = 0.5\n    ),\n    axis.line.y = element_line(\n      colour = text_hil,\n      linewidth = 0.5,\n      arrow = arrow(length = unit(0.4, \"cm\"))\n    ),\n    plot.title.position = \"plot\",\n    plot.title = element_text(\n      colour = text_hil,\n      hjust = 0.5,\n      family = \"title_font\",\n      size = 12 * ts,\n      margin = margin(2,0,0.25,0, \"cm\"),\n      lineheight = 0.25\n    ),\n    plot.subtitle = element_text(\n      hjust = 0.5,\n      lineheight = 0.3,\n      colour = text_hil,\n      size = 5 * ts,\n      margin = margin(0,0,1,0, \"cm\")\n    ),\n    axis.text = element_text(\n      colour = text_col,\n      hjust = 0.5,\n      margin = margin(0,0,0,0),\n      size = 4 * ts\n    ),\n    axis.title = element_text(\n      colour = text_col,\n      hjust = 0.5,\n      margin = margin(0,0,0,0),\n      size = 4 * ts\n    ),\n    plot.caption = element_textbox(\n      family = \"caption_font\",\n      colour = text_hil,\n      size = 3 * ts,\n      hjust = 0.5,\n      margin = margin(0.5,0,0.8,0, \"cm\")\n    ),\n    strip.text = element_markdown(\n      family = \"body_font\",\n      size = 7 * ts,\n      margin = margin(0,0,0.5,0, \"cm\")\n    )\n  )\n\n\n# =============================================================================#\n# Image Saving-----------------------------------------------------------------\n# =============================================================================#\n\nggsave(\n  filename = here::here(\"docs\", \"dip_hdi.png\"),\n  plot = g,\n  width = 40,\n  height = 45,\n  units = \"cm\",\n  bg = bg_col\n)\n\n\n\n\n\n\n\n\nFigure¬†9: Line plot for HDI for different countries over time. Worst performers (red) and best performers (green) are highlighted.\n\n\n\n\nAn animated scatter plot to show trends over time\nFurther, in Figure¬†10, I use {gganimate} (Pedersen and Robinson 2024) to show a scatter-plot (for 6 different regions), where each dot represents a country, showing political representation (% seats by women in parliament) on Y-axis vs.¬†mean years of schooling for females on X-axis, shows positive correlation in Europe, Latin America and Sub-Saharan Africa. However, there is a negative correlation in East Asia and South Asia, and its worsening over time in these regions.\n\n\nCode\n# Note this code picks up from the previous chunk of code\n\n\n# =============================================================================#\n# Animation: Female Schooling vs. Female Political Participation ---------------\n# =============================================================================#\n\n# Another EDA: Schooling years of females vs. Share of Seats in parliament held by women\ndf3 &lt;- hdi |&gt; \n  select(country, region, contains(\"mys_f_\"), (contains(\"pr_f_\") & !contains(\"lfpr_f\"))) |&gt; \n  pivot_longer(\n    cols = -c(country, region),\n    names_to = \"var_full\",\n    values_to = \"value\"\n  ) |&gt; \n  separate_wider_delim(\n    cols = var_full,\n    delim = \"_\",\n    names = c(\"indicator\", NA, \"year\")\n  ) |&gt; \n  mutate(\n    year = as.numeric(year),\n    indicator = case_when(\n      indicator == \"mys\" ~ \"mean_yrs_school\",\n      indicator == \"pr\" ~ \"parl_rep\",\n      .default = NA\n    )\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(country, year, region),\n    names_from = indicator,\n    values_from = value\n  )\n\n###### Start Making animation: Parameters ######  \nlibrary(gganimate)\n\npalcol2 &lt;- \"grey\"\nmypal1 &lt;- paletteer::paletteer_d(\"ggthemes::excel_Ion_Boardroom\")\nfont_add_google(\"Dosis\", family = \"anim_font\")\nfont_add_google(\"Saira Extra Condensed\", family = \"caption_font\") \n\nshowtext_auto()\n\nregions &lt;- c(\n  \"Arab States\",\n  \"East Asia & Pacific\",\n  \"Europe and Central Asia\",\n  \"Latin America & Caribbean\",\n  \"South Asia\",\n  \"Sub-Saharan Africa\"\n)\nabbr_regions &lt;- c(\"AS\", \"EAP\", \"ECA\", \"LAC\", \"SA\", \"SSA\")\n\nstrip_region_labels &lt;- paste0(\n  \"&lt;b style='color:\",\n  mypal1,\n  \"'&gt;\", \n  regions,\n  \"&lt;/b&gt;\"\n  )\nnames(strip_region_labels) &lt;- abbr_regions\n\nsimple_labels &lt;- regions\nnames(simple_labels) &lt;- abbr_regions\n\n##### The Plot to animate ########\n\nganim &lt;- ggplot(\n  data = df3 |&gt; filter(!is.na(region)),\n  mapping = aes(\n    x = mean_yrs_school,\n    y = parl_rep,\n    colour = region\n    )\n  ) +\n  geom_point(\n    aes(group = country),\n    size = 4\n  ) +\n  geom_smooth(\n    method = \"lm\", \n    se = FALSE,\n    colour = \"darkgrey\",\n    linewidth = 1\n    ) +\n  facet_wrap(~ region,labeller = labeller(region = simple_labels)) +\n  scale_x_continuous(\n    limits = c(0, 14),\n    breaks = seq(0, 12, 4),\n    expand = expansion(0)\n  ) +\n  scale_y_continuous(\n    limits = c(0, 55),\n    breaks = seq(0, 50, 10),\n    labels = label_number(suffix = \" %\"),\n    expand = expansion(c(0.05, 0))\n  ) +\n  labs(\n    title = \"Female Schooling vs. Political Representation: Year {frame_time}\",\n    subtitle = \"Each dot represents a Country over time\",\n    y = \"Females' Representation in Parliament\",\n    x = \"Mean years of Schooling for females\",\n    caption = \"Data: UNDP  |  Code: (GitHub) @aditya-dahiya\"\n  ) +\n  scale_color_manual(values = mypal1) +\n  theme_bw(\n    base_family = \"anim_font\",\n    base_size = 16\n  ) +\n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(\n      linewidth = 0.5,\n      linetype = 2,\n      colour = \"lightgrey\"\n    ),\n    plot.title = element_text(\n      face = \"bold\",\n      family = \"anim_font\",\n      hjust = 0.5\n    ),\n    plot.subtitle = element_text(\n      hjust = 0.5\n    ),\n    legend.position = \"none\",\n    plot.caption = element_text(\n      hjust = 1, \n      family = \"caption_font\"\n    ),\n    strip.text = element_text(\n      family = \"caption_font\",\n      face = \"bold\",\n      colour = \"black\",\n      size = 16, \n      margin = margin(10, 0, 10, 0, \"pt\")\n    ),\n    strip.background = element_rect(\n      fill = \"transparent\"\n    ),\n    axis.text = element_text(\n      colour = \"black\"\n    ),\n    axis.title = element_text(\n      margin = margin(5, 5, 5, 5, \"pt\")\n    )\n  ) +\n  transition_time(as.integer(year)) +\n  ease_aes('linear') \n\nanim_save(\n  filename = \"dip_hdi_anim.gif\",\n  animation = ganim,\n  path = here(\"docs\"),\n  nframes = 200,\n  end_pause = 10,\n  start_pause = 2,\n  width = 675,\n  height = 750\n  \n)\n\n\n\n\n\n\n\n\nFigure¬†10: Animated scatterplot of political representation (% seats by women in parliament) on Y-axis vs.¬†mean years of schooling for females on X-axis.\n\n\n\n\n\nAnimation with Country Flags\nLastly, the Figure¬†11 shows another animation using {ggflags} package by James Goldie on changing CO2 emissions compared with changing per capita national incomes from 1990 to 2022 for some countries. The annotation adds the message.\n\n\nCode\ndf4 &lt;- hdi |&gt;\n  mutate(country = if_else(country == \"T\\xfcrkiye\", \"Turkiye\", country),\n         country = if_else(country == \"Syrian Arab Republic\", \"Syria\", country),\n         country = if_else(country == \"'C&lt;f4&gt;te d'Ivoire'\", \"Ivory Coast\", country)\n         ) |&gt; \n  select(\n    iso3,\n    country,\n    contains(\"co2_prod\"),\n    contains(\"gnipc\")\n  ) |&gt; \n  pivot_longer(\n    cols = -c(iso3, country),\n    names_to = \"variable\",\n    values_to = \"value\"\n  ) |&gt; \n  separate_wider_delim(\n    cols = variable,\n    delim = \"_\",\n    names = c(NA, \"variable\", \"year\"),\n    too_few = \"align_end\"\n  ) |&gt; \n  mutate(variable = if_else(variable == \"prod\", \"co2prod\", variable)) |&gt; \n  fill(value, .direction = \"downup\")\n\n# Code to find out which countries have changed the most\n# library(ggiraph)\n# tempg &lt;- df4 |&gt;\n#   mutate(com_var = paste0(variable, \"_\", year), .keep = \"unused\") |&gt;\n#   pivot_wider(\n#     id_cols = c(iso3, country),\n#     names_from = com_var,\n#     values_from = value\n#   ) |&gt;\n#   mutate(\n#     iso3 = iso3,\n#     country = country,\n#     change_co2 = co2prod_2022 - co2prod_1990,\n#     change_inc = gnipc_2022 - gnipc_1990,\n#     .keep = \"none\"\n#   ) |&gt;\n#   filter(change_co2 &gt; -100) |&gt;\n#   ggplot(aes(\n#     x = change_inc,\n#     y = change_co2,\n#     tooltip = iso3,\n#     data_id = iso3)) +\n#   geom_point_interactive()\n# girafe(tempg)\n# Selected countries to view\nview_iso3 &lt;- c(\"QAT\", \"IRL\", \"LUX\", \"ARE\", \"USA\", \"CHN\", \"IND\", \"BRN\")\nicon_code &lt;- c(\"qa\", \"ie\", \"lu\", \"ae\", \"us\", \"cn\", \"in\", \"bn\" )\n\ntemp1 &lt;- tibble(\n  iso3 = view_iso3,\n  iso2 = icon_code\n  )\n\n\n# Installing ggflags package for flag icons\n# install.packages(\"ggflags\", repos = c(\n#   \"https://jimjam-slam.r-universe.dev\",\n#   \"https://cloud.r-project.org\"))\n\nlibrary(ggflags)\nlibrary(gganimate)\n\nfont_add_google(\"Barlow Semi Condensed\", \"flag_font\")\nfont_add_google(\"Saira Extra Condensed\", \"caption_font\")\nshowtext_auto()\n\nsubtitle_text &lt;- \"Comparison of effect of rising incomes on carbon dioxide emissions in different countries.\\nWhile Ireland and Luxembourg have grown per capita incomes without increasing emissions, Qatar & Brunei have massively rising emissions, without commesurate per capita income rise.\"\nsubtitle_anim &lt;- str_wrap(subtitle_text, 40)\nstr_view(subtitle_anim)\n\ngfanim &lt;- df4 |&gt; \n  filter(iso3 %in% view_iso3) |&gt; \n  pivot_wider(\n    id_cols = c(iso3, country, year),\n    names_from = variable,\n    values_from = value\n  ) |&gt;\n  left_join(temp1) |&gt; \n  ggplot(\n    aes(\n      x = gnipc,\n      y = co2prod,\n      country = iso2,\n      label = country\n    )\n  ) +\n  ggflags::geom_flag(\n    size = 20\n  ) +\n  geom_text(\n    aes(y = co2prod + 5),\n    family = \"flag_font\",\n    size = 5\n  ) +\n  annotate(\n    geom = \"text\",\n    x = 0, \n    y = 80,\n    label = subtitle_anim,\n    family = \"flag_font\",\n    size = 5,\n    hjust = 0,\n    vjust = 1,\n    colour = \"grey30\",\n    lineheight = 1.5\n  ) +\n  scale_x_continuous(\n    expand = expansion(c(0.02, 0)),\n    labels = label_number(\n      prefix = \"$\",\n      scale_cut = cut_short_scale()\n    )\n  ) +\n  scale_y_continuous(\n    expand = expansion(c(0.02, 0.05)),\n    breaks = seq(0, 75, 15)\n  ) +\n  labs(\n    y = \"Annual carbon dioxide emissions, per capita (in Tonnes)\",\n    x = \"Gross National Income, per capita (in 2017 PPP US $)\",\n    title = \"Emissions & Incomes: {frame_time}\",\n    caption = \"Data: UNDP  |  Code: (GitHub) @aditya-dahiya\"\n  ) +\n  theme_classic(\n    base_size = 16, \n    base_family = \"flag_font\"\n    ) +\n  theme(\n    plot.title = element_text(\n      hjust = 0,\n      face = \"bold\",\n      size = 42, \n      colour = \"grey30\"\n    ),\n    plot.caption = element_text(\n      family = \"caption_font\",\n      colour = \"grey20\"),\n    axis.title = element_text(\n      colour = \"grey20\"\n    ),\n    axis.line = element_line(\n      linewidth = 0.5,\n      arrow = arrow(length = unit(0.25, \"cm\")),\n      colour = \"grey50\"\n    ),\n    axis.ticks = element_line(linewidth = 0.15, colour = \"grey50\"),\n    axis.ticks.length = unit(0.5, \"cm\"),\n    plot.title.position = \"panel\",\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(\n      colour = \"lightgrey\",\n      linewidth = 0.25,\n      linetype = \"dotted\"\n    )\n  ) +\n  transition_time(as.integer(year)) +\n  ease_aes('linear')\n\nanim_save(\n  filename = \"hdi_anim_flags.gif\",\n  path = here(\"docs\"),\n  animation = gfanim,\n  duration = 20,\n  fps = 12,\n  start_pause = 5,\n  end_pause = 20,\n  height = 800,\n  width = 700,\n  units = \"px\"\n  ) \n\n\n\n\n\n\n\n\nFigure¬†11: An animated scatterplot of Gross National Income (x-axis) vs.¬†Per-capita Carbon dioxide emissions (Y-axis) from year 1990-2022 for some countries. Incomes in Ireland and Luxembourg increased without raising emissions, while the emissions rose in Brunei and Qatar without much impact on per capita incomes."
  }
]