[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Presentations, Data Viz & More",
    "section": "",
    "text": "Welcome to my webpage, where knowledge meets creativity! Explore my Presentations tab to delve into a collection of insightful training sessions and lectures, and head to Projects to witness the art of data visualization and data science in action. For more about me, visit my main webpage here."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Dr.¬†Aditya Dahiya, IAS\nWelcome to my corner of the internet, where I aim to share my experiences and insights gained from a journey that has taken me from the halls of Harvard to the heart of Haryana. I am Dr.¬†Aditya Dahiya, an IAS officer with a background in medicine, and it‚Äôs truly an honor to have you here. This website serves as a platform where I house the session presentations from various lectures I‚Äôve had the privilege of giving in different places. As I embark on this digital voyage, my hope is to engage with you in meaningful conversations about the worlds of public health, governance, and perhaps even a few stories from the tennis court."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html",
    "href": "manual_office_procedure_22_sep_23.html",
    "title": "Manual of Office Procedure",
    "section": "",
    "text": "Part-IPart-IIPart-III\n\n\n\nBranch: The work unit within a department responsible for attending to items of work allotted to it. It includes ‚ÄòCell,‚Äô ‚ÄòUnit,‚Äô ‚ÄòSection,‚Äô and similar terms. Generally headed by a Branch In-charge, Superintendent, or other officials.\nBranch Officer (Secretariat): An officer of the level of Under Secretary/Deputy Secretary responsible for work within the Branch.\n\n\n\n\nCome-back Case: A case received back for further action, such as re-examination or drafting a summary.\nCall Book: If a current case cannot be expedited for at least 6 months (e.g., cases held up in law courts), it may be transferred to the call book with approval from an officer not below the level of Branch Officer.\n\n\n\n\nSectional Note: A note recorded on one of the many issues raised in the PUC.\nStanding Note: A continuing note explaining the history and development of policy and procedure, serving as background material for policy reviews, replies to Assembly questions, and induction/training material."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-i-definitions",
    "href": "manual_office_procedure_22_sep_23.html#part-i-definitions",
    "title": "Manual of Office Procedure",
    "section": "Part-I: Definitions",
    "text": "Part-I: Definitions\n\nBranch: The work unit within a department responsible for attending to items of work allotted to it. It includes ‚ÄòCell,‚Äô ‚ÄòUnit,‚Äô ‚ÄòSection,‚Äô and similar terms. Generally headed by a Branch In-charge, Superintendent, or other officials.\nBranch Officer (Secretariat): An officer of the level of Under Secretary/Deputy Secretary responsible for work within the Branch."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-ii-definitions",
    "href": "manual_office_procedure_22_sep_23.html#part-ii-definitions",
    "title": "Manual of Office Procedure",
    "section": "Part-II: Definitions",
    "text": "Part-II: Definitions\n\nCome-back Case: A case received back for further action, such as re-examination or drafting a summary.\nCall Book: If a current case cannot be expedited for at least 6 months (e.g., cases held up in law courts), it may be transferred to the call book with approval from an officer not below the level of Branch Officer."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-iii-definitions",
    "href": "manual_office_procedure_22_sep_23.html#part-iii-definitions",
    "title": "Manual of Office Procedure",
    "section": "Part-III: Definitions",
    "text": "Part-III: Definitions\n\nSectional Note: A note recorded on one of the many issues raised in the PUC.\nStanding Note: A continuing note explaining the history and development of policy and procedure, serving as background material for policy reviews, replies to Assembly questions, and induction/training material."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#business-of-the-haryana-government-allocation-rules-1974",
    "href": "manual_office_procedure_22_sep_23.html#business-of-the-haryana-government-allocation-rules-1974",
    "title": "Manual of Office Procedure",
    "section": "Business of the Haryana Government (Allocation) Rules, 1974",
    "text": "Business of the Haryana Government (Allocation) Rules, 1974\n\nAllocate government business among different departments."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#rules-of-business-of-the-government-of-haryana-1977",
    "href": "manual_office_procedure_22_sep_23.html#rules-of-business-of-the-government-of-haryana-1977",
    "title": "Manual of Office Procedure",
    "section": "Rules of Business of the Government of Haryana, 1977",
    "text": "Rules of Business of the Government of Haryana, 1977\n\nPart IPart II\n\n\n\nDefine the authority, responsibility, and obligations of each department.\nSpecify cases to be submitted for prior approval to the Governor, Chief Minister, and Cabinet.\nDescribe circumstances requiring consultation with other departments.\n\n\n\n\nRule 18: Cases disposed of by or under the authority of the Minister-in-charge. Delegation via Standing Orders.\nRule 19: Minister‚Äôs arrangement with Administrative Secretary for cases brought to personal notice.\nRule 28: Matters required to be submitted to the Chief Minister/Governor."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#rules-of-business-of-the-government-of-haryana-1977-1",
    "href": "manual_office_procedure_22_sep_23.html#rules-of-business-of-the-government-of-haryana-1977-1",
    "title": "Manual of Office Procedure",
    "section": "Rules of Business of the Government of Haryana, 1977",
    "text": "Rules of Business of the Government of Haryana, 1977\n\nRule 18: Cases disposed of by or under the authority of the Minister-in-charge. Delegation via Standing Orders.\nRule 19: Minister‚Äôs arrangement with Administrative Secretary for cases brought to personal notice.\nRule 28: Matters required to be submitted to the Chief Minister/Governor."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-i-duties-of-branch-officer",
    "href": "manual_office_procedure_22_sep_23.html#part-i-duties-of-branch-officer",
    "title": "Manual of Office Procedure",
    "section": "Part-I: Duties of Branch Officer",
    "text": "Part-I: Duties of Branch Officer\n\nA Branch officer is the junior most officer on the first rung of the secretariat hierarchy authorized to issue orders in the name of the Governor of Haryana as per Rule 9(i) of the Rules of Business of Government of Haryana, 1977.\nControl and supervise the Branch(es) placed in his charge.\nGuide the staff on how to deal with papers, both generally and in individual cases."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-ii-duties-of-branch-officer",
    "href": "manual_office_procedure_22_sep_23.html#part-ii-duties-of-branch-officer",
    "title": "Manual of Office Procedure",
    "section": "Part-II: Duties of Branch Officer",
    "text": "Part-II: Duties of Branch Officer\n\nCheck for delay, superfluous noting, and prolixity of language, whether in notes or drafts, and enforce the rigid observance of all rules.\nPass final orders approving proposals of a routine nature or requiring only the formal sanction of Government.\nEnsure that points on which orders are required are clearly and concisely set forth and ordinarily express his own views on them."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-iii-duties-of-branch-officer",
    "href": "manual_office_procedure_22_sep_23.html#part-iii-duties-of-branch-officer",
    "title": "Manual of Office Procedure",
    "section": "Part-III: Duties of Branch Officer",
    "text": "Part-III: Duties of Branch Officer\n\nNoting and drafting on cases of policy framing and complicated nature should, as far as possible, be done by the Branch Officer who should utilize the service of Dealing-hand/Assistant/Branch In-charge for the collection of statistics or papers.\nIf there is any dispute on a particular receipt regarding which Branch or who will examine it, the decision for allocation shall be taken by the Branch officer.\nMake surprise visits to the Branch to check attendance and ensure that other instructions are correctly observed."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-i-duties-of-ddo",
    "href": "manual_office_procedure_22_sep_23.html#part-i-duties-of-ddo",
    "title": "Manual of Office Procedure",
    "section": "Part-I: Duties of DDO",
    "text": "Part-I: Duties of DDO\n\nAssist the Head of Office/Head of Department in the discharge of financial activities.\nTimely preparation and submission of receipts/expenditure through the online system.\nTimely submission of reports and returns to the Finance Department/Principal Accountant General, Haryana."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-ii-duties-of-ddo",
    "href": "manual_office_procedure_22_sep_23.html#part-ii-duties-of-ddo",
    "title": "Manual of Office Procedure",
    "section": "Part-II: Duties of DDO",
    "text": "Part-II: Duties of DDO\n\nMaintenance of Salary Bills Register, TA Bills Register, Contingent Register, and Cash Book.\nUpdate entries in the Service Book of employees manually and through HRMS.\nMake available all records required by the Audit Party."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-i-branch-in-charge-duties",
    "href": "manual_office_procedure_22_sep_23.html#part-i-branch-in-charge-duties",
    "title": "Manual of Office Procedure",
    "section": "Part-I: Branch In-charge duties",
    "text": "Part-I: Branch In-charge duties\n\nOverall responsible for supervising the activities and performance of the Branch.\nGo through the dak received, mark it to the dealing hands with dated initials indicating the urgency.\nReturn the dak not concerned to the Branch, if any.\nSend a photo-copy of fresh receipt of important nature to the higher authorities for perusal in case the said authorities have not seen the same, with the indication that action is being taken."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-ii-branch-in-charge-duties",
    "href": "manual_office_procedure_22_sep_23.html#part-ii-branch-in-charge-duties",
    "title": "Manual of Office Procedure",
    "section": "Part-II: Branch In-charge duties",
    "text": "Part-II: Branch In-charge duties\n\nSee that all the corrections have been made before submitting the fair draft for signatures.\nGive special instructions, where necessary, on the draft as to the manner of its issue, e.g., ‚ÄúBy Registered Post,‚Äù ‚ÄúInsured Cover,‚Äù ‚ÄúSpeed Post,‚Äù ‚ÄúBy Hand through Special Messenger,‚Äù or Through email, etc.\nKeep a note in his personal diary about all important receipts like Court Cases; Assembly Business; Important letters received from GOI; and letter(s)/file(s) with the remarks of higher authorities which need prompt examination."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-iii-branch-in-charge-duties",
    "href": "manual_office_procedure_22_sep_23.html#part-iii-branch-in-charge-duties",
    "title": "Manual of Office Procedure",
    "section": "Part-III: Branch In-charge duties",
    "text": "Part-III: Branch In-charge duties\n\nScrutinize the notes and drafts submitted by Assistants for correctness and accuracy and add his own remarks or suggestions where necessary before submitting the case to the higher officers.\nInspect the tables of his Assistant/Clerks periodically to see that fresh receipts and cases are properly and punctually submitted.\nGive priority markings on dak, drafts, letters, etc., and remove or revise such markings as and when necessary."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-iv-branch-in-charge-duties",
    "href": "manual_office_procedure_22_sep_23.html#part-iv-branch-in-charge-duties",
    "title": "Manual of Office Procedure",
    "section": "Part-IV: Branch In-charge duties",
    "text": "Part-IV: Branch In-charge duties\n\nEnsure that the Attendance Register is maintained correctly and submitted to the immediate superior in due time.\nEnsure availability of staff posted under him on holidays or early or late hours whenever required, maintain local addresses and mobile numbers of the entire staff.\nEnsure that each dealing hand and the diarist maintains all required registers and keep the same up-to-date. He should also check these registers at regular intervals."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#part-v-branch-in-charge-duties",
    "href": "manual_office_procedure_22_sep_23.html#part-v-branch-in-charge-duties",
    "title": "Manual of Office Procedure",
    "section": "Part-V: Branch In-charge duties",
    "text": "Part-V: Branch In-charge duties\n\nEnsure that all Manuals, Acts, Rules, Instructions, Guard Files, and Precedent Registers of the Branch are kept up-to-date by inserting correction-slips or getting new editions.\nKeep in his custody the personal files of the staff and ensure that blank forms for annual reports are put up to the Officers In-charge of the officials working under them in the month of March.\nCheck that the inventory of articles of furniture, etc., hung in their respective Rooms/Branches is kept up-to-date."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---i",
    "href": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---i",
    "title": "Manual of Office Procedure",
    "section": "Duties of ‚Äúdealing hand‚Äù - I",
    "text": "Duties of ‚Äúdealing hand‚Äù - I\n\nAn Assistant/dealing-hand posted in a branch/office works under the supervision of the Branch In-charge.\nHe/she is expected to deal with all the matters allocated to him and submit to the Branch In-charge efficiently as per the prescribed procedure.\nWhere a Record Keeper has not been provided, the functions of the Record Keeper will also be performed by the Assistant/Dealing-hand himself."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---ii",
    "href": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---ii",
    "title": "Manual of Office Procedure",
    "section": "Duties of ‚Äúdealing hand‚Äù - II",
    "text": "Duties of ‚Äúdealing hand‚Äù - II\n\nBefore proper examination of any issue on a file, Dealing-hand should ensure to go through the receipts to check the enclosures/facts and take note of any mistake(s).\nIf a file exists for the receipt, add the receipt to the existing file containing previous papers. In case there is no file on the subject, a new file may be opened as per the procedure laid down."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---iii",
    "href": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---iii",
    "title": "Manual of Office Procedure",
    "section": "Duties of ‚Äúdealing hand‚Äù - III",
    "text": "Duties of ‚Äúdealing hand‚Äù - III\n\nPut up the Standing Guard File/Precedents File or reference folder, other facts and figures relevant to the issue under consideration.\nDocket the receipt and reproduce the remarks, if any, recorded by an officer on the receipt, in the beginning on the right-hand side of his noting.\nRecord his note on the noting-sheet as per the procedure laid down in Chapter-VII, Action on Receipt ‚Äì Noting."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---iv",
    "href": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---iv",
    "title": "Manual of Office Procedure",
    "section": "Duties of ‚Äúdealing hand‚Äù - IV",
    "text": "Duties of ‚Äúdealing hand‚Äù - IV\n\nBring out clearly the administrative, financial, and legal implications, if any, and suggest a course of action wherever possible.\nPrepare and keep up-to-date a ‚Äúrunning summary of facts‚Äù or pr√©cis on a case where it is considered necessary.\nPut up a draft as per detailed procedure in Chapter-VIII of the Manual.\nIndicate the ‚ÄòLevel‚Äô of disposal in the margin of the note as per ‚ÄòStanding Order‚Äô or any other order/decision in vogue."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---v",
    "href": "manual_office_procedure_22_sep_23.html#duties-of-dealing-hand---v",
    "title": "Manual of Office Procedure",
    "section": "Duties of ‚Äúdealing hand‚Äù - V",
    "text": "Duties of ‚Äúdealing hand‚Äù - V\n\nMaintain the Guard File of important decisions and instructions concerning him.\nEnsure acknowledgments to communications received from Members of Parliament, Legislature, and Public Bodies promptly, and issue interim replies if a delay is anticipated in sending out the final reply.\nMaintain a subject-wise collection of all important decisions and circulars/other communications relating to various subjects dealt with in the Branch along with standard drafts, if any."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#referencing-on-files---i",
    "href": "manual_office_procedure_22_sep_23.html#referencing-on-files---i",
    "title": "Manual of Office Procedure",
    "section": "Referencing on Files - I",
    "text": "Referencing on Files - I\n\nEvery page of the noting/correspondence portion of the file should be consecutively numbered.\nThe paper under consideration or a fresh receipt will be flagged ‚ÄòPUC‚Äô on the right corner of the paper.\nIn case a draft reply is also added, it will be flagged ‚ÄòDFA‚Äô on the left corner of the paper. In referring to the papers, the relevant page number of the noting/correspondence portions will be quoted invariably in the margin of PUC/DFA."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#referencing-on-files---ii",
    "href": "manual_office_procedure_22_sep_23.html#referencing-on-files---ii",
    "title": "Manual of Office Procedure",
    "section": "Referencing on Files - II",
    "text": "Referencing on Files - II\n\nThe recorded files and all other papers which are put up with the current file will be flagged with alphabetical slips for quick identification.\nOnly one alphabetical slip will be attached to each recorded file or compilation. While giving reference to the papers contained therein, those should be identified by the relevant page in addition to the alphabetical slip, e.g., A/15, A/29, and so on."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#referencing-on-files---iii",
    "href": "manual_office_procedure_22_sep_23.html#referencing-on-files---iii",
    "title": "Manual of Office Procedure",
    "section": "Referencing on Files - III",
    "text": "Referencing on Files - III\n\nWhenever reference to the papers contained in other files is given in the note, the number of the file may also be quoted in the note in order to facilitate the location of the reference after those files are removed from the current file after completion of action.\nWhen a single reference is quoted in a fresh receipt, and that reference is in a file put up with another case, a copy of the required paper should be made, and the fresh receipt submitted with it to avoid delay."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#referencing-on-files---iv",
    "href": "manual_office_procedure_22_sep_23.html#referencing-on-files---iv",
    "title": "Manual of Office Procedure",
    "section": "Referencing on Files - IV",
    "text": "Referencing on Files - IV\n\nNo case should be kept pending until the connected references are available without the specific orders of the Branch In-charge.\nIn urgent cases, the Branch In-charge should take orders of higher officers, and he should do the same in ordinary cases if the references needed do not become available within, say, a week of receipt of the communication. Such cases should always be shown in the arrear lists, and it should be noted whether the case is pending under the orders of an officer."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---i",
    "href": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---i",
    "title": "Manual of Office Procedure",
    "section": "Guidelines for Noting - I",
    "text": "Guidelines for Noting - I\n\nA note must be concise, clear, complete, correct, courteous, and to the point. Lengthy notes are to be avoided.\nThe verbatim reproduction of extracts from or paraphrasing of the paper under consideration, fresh receipt, or any other part of correspondence or notes on the same file should be avoided.\nAll notes should be written in the third person."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---ii",
    "href": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---ii",
    "title": "Manual of Office Procedure",
    "section": "Guidelines for Noting - II",
    "text": "Guidelines for Noting - II\n\nRelevant extracts of the provisions of the Act, Rules, and /or guidelines will be placed on the file, and attention will be drawn to it in the note, rather than reproducing the relevant provisions in the note.\nMake a note of the actual points proposed to make without reiterating the ground already covered in the previous notes. If one agrees with the line of action suggested in the preceding note, merely append a signature.\nA self-contained note will be put up with every case submitted to the Administrative Secretary or Minister."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---iii",
    "href": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---iii",
    "title": "Manual of Office Procedure",
    "section": "Guidelines for Noting - III",
    "text": "Guidelines for Noting - III\n\nA self-contained note is prepared while seeking advice or opinion or concurrence of another Department.\nSufficient space, not less than one quarter of the page, should be left below the last recorded note in the note sheet of the file, especially when the file is submitted to the Secretary or Minister level."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---iv",
    "href": "manual_office_procedure_22_sep_23.html#guidelines-for-noting---iv",
    "title": "Manual of Office Procedure",
    "section": "Guidelines for Noting - IV",
    "text": "Guidelines for Noting - IV\n\nTwo extra blank note-sheets should be added to the noting portion after completing the note.\nThe dealing hand (non-gazetted) is required to sign the note on the extreme left part near the margin. However, the gazetted officers will sign on the right-hand side."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#examination-of-file-note-by-a-branch-in-charge",
    "href": "manual_office_procedure_22_sep_23.html#examination-of-file-note-by-a-branch-in-charge",
    "title": "Manual of Office Procedure",
    "section": "Examination of File Note by a Branch In-charge",
    "text": "Examination of File Note by a Branch In-charge\n\nWhen making suggestions for approval of senior officers, the Branch In-charge will confine his note to the actual points he proposes to make without re-iterating the grounds already covered in the previous notes.\nState the questions for consideration and bring out clearly the points requiring a decision."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#running-summary-of-facts",
    "href": "manual_office_procedure_22_sep_23.html#running-summary-of-facts",
    "title": "Manual of Office Procedure",
    "section": "Running Summary of Facts",
    "text": "Running Summary of Facts\n\nTo facilitate consideration and to obviate repeated recapitulation in important, complex, and court cases, a running summary of facts will be prepared and placed on the file in a separate folder labeled as such in every case where it is evident that such a summary would contribute to its speedy disposal.\nPrevious versions of the running summary, if any, shall not be destroyed."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#modification-of-notes-or-order",
    "href": "manual_office_procedure_22_sep_23.html#modification-of-notes-or-order",
    "title": "Manual of Office Procedure",
    "section": "Modification of Notes or Order",
    "text": "Modification of Notes or Order\n\nWhere a final decision already communicated to a party is found later on to have been given on a mistaken ground or wrong facts or wrong interpretation of rules due to misunderstanding or otherwise, such replacement or modification of a note may have legal implications.\nIn all such cases, wherever necessary, a review of the decision should be examined, and the revised decision shall be taken with the approval of an officer higher than the one, if available, who took the original decision."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#types-or-categories-of-cases-and-quantum-of-noting",
    "href": "manual_office_procedure_22_sep_23.html#types-or-categories-of-cases-and-quantum-of-noting",
    "title": "Manual of Office Procedure",
    "section": "Types or Categories of Cases and Quantum of Noting",
    "text": "Types or Categories of Cases and Quantum of Noting\n\n\n\n\n\n\n\n\n\nType or Category of the Case\nQuantum of Noting\n\n\n\n\n1\nEphemeral\nNo noting is needed\n\n\n2\nAction in Correspondence Cases\nShort notes of a few sentences\n\n\n3\nRoutine or Repetitive Case\nDevelop and use Standard Process Sheet\n\n\n4\nProblem Solving Case\nA structured and detailed note is prepared.\n\n\n5\nPolicy/Planning Case\nDetailed note is prepared covering various aspects, implications, and expected outcomes of a policy to be developed or under review."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---i",
    "href": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---i",
    "title": "Manual of Office Procedure",
    "section": "U.O. Letter or Un-Official References - I",
    "text": "U.O. Letter or Un-Official References - I\n\nInter-departmental references are made un-officially to officers and Heads of Departments who are not part of Secretariat.\nWhen Secretaries to Government desire to obtain an expression of opinion, advice, or supplementary information from such officers and Heads of Departments in an un-official manner, they should do so by sending the files and notes.\nIt is only where these officers make references as Secretaries on their own files that it is treated as an un-official reference."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---ii",
    "href": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---ii",
    "title": "Manual of Office Procedure",
    "section": "U.O. Letter or Un-Official References - II",
    "text": "U.O. Letter or Un-Official References - II\n\nIn the case of inter-departmental reference, the department or office of origin should state, with as much precision as possible, the specific points in respect to which reference is made.\nReferences to the Legal Remembrancer should definitely state the points on which his opinion or advice is required."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---iii",
    "href": "manual_office_procedure_22_sep_23.html#u.o.-letter-or-un-official-references---iii",
    "title": "Manual of Office Procedure",
    "section": "U.O. Letter or Un-Official References - III",
    "text": "U.O. Letter or Un-Official References - III\n\nIn every file referred to by one department or office to another department or office, the notes written in the department or office referred to should (when this is desirable) be on separate sheets (in duplicate) from the notes written in the referring department, and the conclusion only should be recorded under the signature of the officer to whom an un-official reference was made."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#level-of-approval-of-draft",
    "href": "manual_office_procedure_22_sep_23.html#level-of-approval-of-draft",
    "title": "Manual of Office Procedure",
    "section": "Level of Approval of Draft",
    "text": "Level of Approval of Draft\n\nAfter the orders are passed by the competent authority on a file, the Draft for Approval (DFA) should be approved by the authority minimum one step above the authority who has to sign the fair draft, except in routine cases (e.g., reminder letter, supply of definite information) after the approval of the competent authority."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#drafting-by-officers-of-important-cases",
    "href": "manual_office_procedure_22_sep_23.html#drafting-by-officers-of-important-cases",
    "title": "Manual of Office Procedure",
    "section": "Drafting by Officers of Important Cases",
    "text": "Drafting by Officers of Important Cases\n\nBranch officers are expected to prepare drafts of important cases. As a general rule, the Branch officer should send to Branch only such cases for submission of drafts, which can easily be followed by an Assistant/Dealing hand."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#inter-departmental-consultation",
    "href": "manual_office_procedure_22_sep_23.html#inter-departmental-consultation",
    "title": "Manual of Office Procedure",
    "section": "Inter-Departmental Consultation",
    "text": "Inter-Departmental Consultation\n\nOn file, the consultation with the concerned Department can be done by either of the two methods:\n\nBy referring the case file; or\nBy making a self-contained U.O. (Un-Official) reference with all relevant documents.\n\nThe first method is the common one and is generally followed in most of the cases, as it is simple because all relevant papers are usually available in the case file."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---i",
    "href": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---i",
    "title": "Manual of Office Procedure",
    "section": "Components of a Charge handing-over Note - I",
    "text": "Components of a Charge handing-over Note - I\n\nList of key areas/responsibilities related to key areas.\nStaff position at present.\nA brief write-up on the sensitive matters being dealt with in the Division."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---ii",
    "href": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---ii",
    "title": "Manual of Office Procedure",
    "section": "Components of a Charge handing-over Note - II",
    "text": "Components of a Charge handing-over Note - II\n\nList of documents required by the officer for handling the responsibilities are annexed.\nWhat were the predecessor‚Äôs experiences of working in the ministry/Department and what steps need to be taken to improve the situation.\nChallenges that he/she has faced and how they have overcome them."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---iii",
    "href": "manual_office_procedure_22_sep_23.html#components-of-a-charge-handing-over-note---iii",
    "title": "Manual of Office Procedure",
    "section": "Components of a Charge handing-over Note - III",
    "text": "Components of a Charge handing-over Note - III\n\nWhat are the constraints under which the work had to be undertaken.\nDetails of counterparts in other Ministries with whom constant interaction takes place and also details of officers of nodal ministries/Departments.\nList of counterparts in various Departments along with the subject matter."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#list-of-important-documents---i",
    "href": "manual_office_procedure_22_sep_23.html#list-of-important-documents---i",
    "title": "Manual of Office Procedure",
    "section": "List of important documents - I",
    "text": "List of important documents - I\n\nSecond Schedule of Rules of Business of Haryana Government, 1977.\nRelevant portion of the Business of the Haryana Government (Allocation) Rules, 1974.\nOrganisation / Functional Chart.\nWork allocation with details of work allocated to sections."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#list-of-important-documents---ii",
    "href": "manual_office_procedure_22_sep_23.html#list-of-important-documents---ii",
    "title": "Manual of Office Procedure",
    "section": "List of important documents - II",
    "text": "List of important documents - II\n\nList of attached offices, subordinate offices, autonomous bodies.\nDelegation of powers and Departmental instructions for decision-making within the Organisation.\nParliamentary matters - A folder containing answers provided to previous questions, notes for supplementary questions, Question days of the Ministry/Department."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#list-of-important-documents---iii",
    "href": "manual_office_procedure_22_sep_23.html#list-of-important-documents---iii",
    "title": "Manual of Office Procedure",
    "section": "List of important documents - III",
    "text": "List of important documents - III\n\nCourt cases - Status of court cases requiring attention.\nProjects/schemes completed and under process.\nBudget provision and the status of the utilization of funds/budget. Action on additional budget requirements, pending Audit paragraphs.\nRTI applications - pending."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#list-of-important-documents---iv",
    "href": "manual_office_procedure_22_sep_23.html#list-of-important-documents---iv",
    "title": "Manual of Office Procedure",
    "section": "List of important documents - IV",
    "text": "List of important documents - IV\n\nImportant instructions on files from senior officers on which responses are pending.\nImportant meetings in the next fortnight. Follow-up action on previous meetings.\nList of periodic reports that are generated by the office and that are received by the office."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#why",
    "href": "manual_office_procedure_22_sep_23.html#why",
    "title": "Manual of Office Procedure",
    "section": "Why?",
    "text": "Why?"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#the-fall-of-the-byzantine-empire",
    "href": "manual_office_procedure_22_sep_23.html#the-fall-of-the-byzantine-empire",
    "title": "Manual of Office Procedure",
    "section": "1. The Fall of the Byzantine Empire:",
    "text": "1. The Fall of the Byzantine Empire:\n\nThe Byzantine Empire fell in 1453 to the Ottoman Empire in part because they failed to adopt newer military technologies such as gunpowder cannons and firearms. This historic event illustrates how the reluctance to embrace technological innovation can lead to a civilization‚Äôs downfall."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#the-kodak-story",
    "href": "manual_office_procedure_22_sep_23.html#the-kodak-story",
    "title": "Manual of Office Procedure",
    "section": "2. The Kodak Story:",
    "text": "2. The Kodak Story:\n\nKodak, once a dominant force in the photography industry, failed to embrace digital photography technology in its early stages. The company‚Äôs reluctance to adapt eventually led to its decline, while digital photography companies like Canon and Nikon thrived. This story emphasizes the importance of staying ahead in the technology curve."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#nokia-and-the-smartphone-revolution",
    "href": "manual_office_procedure_22_sep_23.html#nokia-and-the-smartphone-revolution",
    "title": "Manual of Office Procedure",
    "section": "3. Nokia and the Smartphone Revolution:",
    "text": "3. Nokia and the Smartphone Revolution:\n\nNokia, once the world‚Äôs largest mobile phone manufacturer, underestimated the shift toward smartphones and touchscreen technology. Their inability to adapt quickly led to a significant decline in market share and eventual acquisition by Microsoft. It underscores the importance of recognizing and adapting to industry-changing technologies."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#scheduling-meetings-when2meet",
    "href": "manual_office_procedure_22_sep_23.html#scheduling-meetings-when2meet",
    "title": "Manual of Office Procedure",
    "section": "Scheduling Meetings: When2Meet",
    "text": "Scheduling Meetings: When2Meet\n\n\nThe problem of finding when everyone‚Äôs available !\nSolution:\nwhen2meet.com"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#automate-drafting-chatgpt",
    "href": "manual_office_procedure_22_sep_23.html#automate-drafting-chatgpt",
    "title": "Manual of Office Procedure",
    "section": "Automate Drafting: ChatGPT",
    "text": "Automate Drafting: ChatGPT\n\n\nMinutes of Meeting\nNoting\nPolicy Draft\nChatGPT\nDemonstration"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#speech-to-text",
    "href": "manual_office_procedure_22_sep_23.html#speech-to-text",
    "title": "Manual of Office Procedure",
    "section": "Speech-to-text",
    "text": "Speech-to-text\n\n\nGoogle Docs\nhttps://docs.google.com/\ndicatation.io\nhttps://dictation.io/speech"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#improving-grammer",
    "href": "manual_office_procedure_22_sep_23.html#improving-grammer",
    "title": "Manual of Office Procedure",
    "section": "Improving grammer",
    "text": "Improving grammer\n\nWordTune / Grammarly\nhttps://app.wordtune.com/editor\nChatGPT\nhttps://chat.openai.com/"
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Talks",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nManual of Office Procedure\n\n\nDuties of Under Secretary/Deputy Secretary/Joint Secretary of Secretariat Establishment\n\n\nSep 22, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\n\n\n\n\n\n\n\n\n\nYear\nDegree\nInstitution\nLocation\n\n\n\n\n2021-22\nMaster of Public Health\nHarvard University\nUSA\n\n\n2005-10\nM.B.B.S.\nAll India Institute of Medical Sciences (AIIMS)\nNew Delhi, India"
  },
  {
    "objectID": "about.html#work",
    "href": "about.html#work",
    "title": "About",
    "section": "Work",
    "text": "Work\n\n\n\n\n\n\n\nYear\nPosition\n\n\n\n\n2011-present\nIndian Administrative Service (IAS)\n\n\nJun 2022 - present\nDirector, Medical Education Haryana and Special Secretary\n\n\n\nGeneral Administration Department, Haryana\n\n\nAug 2021 - Jun 2022\nStudy Leave (Harvard University, USA)\n\n\nFeb 2019 - Aug 2021\nDeputy Commissioner, Jind District\n\n\nJuly 2017 - Feb 2019\nDeputy Commissioner, Karnal District\n\n\nAug 2016 - Jul 2017\nCommissioner, Municipal Corporation Karnal\n\n\nDec 2015 - Aug 2016\nCommissioner, Municipal Corporation Faridabad\n\n\nNov 2014 - Aug 2016\nAdditional Deputy Commissioner, Faridabad\n\n\nSep 2013 - Nov 2014\nSub-Divisional Magistrate, Jagadhri (Yamunanagar)\n\n\nJan 2011 - Aug 2011\nJunior Resident, Department of Neuro-Radiology, AIIMS, New Delhi\n\n\n\nAwards & Honors\n\nMar 2021: Fulbright Masters Fellowship by the Fulbright Commission in India\nDec 25, 2020: Atal Bihari Vajpayee Good Governance Award ‚Äì 2020 by the Government of Haryana\nJuly 15, 2020: Joint-Japan World Bank Graduate Fellowship by the World Bank\nMar 13, 2020: Best Officer in the Mid-Career Training Programme for Indian Administrative Service Officers, Lal Bahadur Shastri National Academy of Administration at Mussoorie (India)\nJan 24, 2019: National Award by the Ministry of Women and Child Development, Government of India for ‚ÄúEffective Community Engagement‚Äù in improvement in Gender-Ratio at Birth (GRB)\nMay 4, 2017: National Award as Commissioner of the Karnal Municipal Corporation - Cleanest City in North India (population category 0.2 to 0.5 million)\nDec 9, 2011: Director‚Äôs Shield for the Best All-Round Officer Trainee of the 86th Foundation Course of All India Services.\nOct 1, 2010: Delhi Medical Association‚Äôs Gold Medal for best all-round medical graduate at A.I.I.M.S. New Delhi\nMay, 2005: 1st Rank in National Pre-Medical Entrance Examination (CBSE PMT) for medical colleges in India\n\nExtracurricular Activities\n\n2013 ‚Äì 2015: Part of the Haryana state team at All-India Civil Services Lawn Tennis Tournament at Bhopal (2013), Chennai (2014), and Pune (2015).\nMay 4, 2013: Participated in the Dida I.T.F. Men‚Äôs Futures 15K Tournament held at Rohtak, India organized by the International Tennis Federation Futures Circuit for Men.\n\nConnect with me!\nWell, folks, that‚Äôs my life in a nutshell - a whirlwind journey that‚Äôs taken me from Harvard‚Äôs hallowed halls to the heartland of Haryana, from the world of scalpels and stethoscopes to the battlefield of bureaucracy, and yes, from the operating room to the tennis court (where I sometimes try to ‚Äòserve‚Äô justice, pun intended).\nDon‚Äôt hesitate to connect, dear reader. I‚Äôm just a click away, and I‚Äôd love to hear your thoughts, questions, or maybe even your own adventures from the world of academia, administration, or sports. üéìüéæ"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#definitions",
    "href": "manual_office_procedure_22_sep_23.html#definitions",
    "title": "Manual of Office Procedure",
    "section": "",
    "text": "Part-IPart-IIPart-III\n\n\n\nBranch: The work unit within a department responsible for attending to items of work allotted to it. It includes ‚ÄòCell,‚Äô ‚ÄòUnit,‚Äô ‚ÄòSection,‚Äô and similar terms. Generally headed by a Branch In-charge, Superintendent, or other officials.\nBranch Officer (Secretariat): An officer of the level of Under Secretary/Deputy Secretary responsible for work within the Branch.\n\n\n\n\nCome-back Case: A case received back for further action, such as re-examination or drafting a summary.\nCall Book: If a current case cannot be expedited for at least 6 months (e.g., cases held up in law courts), it may be transferred to the call book with approval from an officer not below the level of Branch Officer.\n\n\n\n\nSectional Note: A note recorded on one of the many issues raised in the PUC.\nStanding Note: A continuing note explaining the history and development of policy and procedure, serving as background material for policy reviews, replies to Assembly questions, and induction/training material."
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#thank-you",
    "href": "manual_office_procedure_22_sep_23.html#thank-you",
    "title": "Manual of Office Procedure",
    "section": "Thank You",
    "text": "Thank You"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#dealing-files-from-another-department",
    "href": "manual_office_procedure_22_sep_23.html#dealing-files-from-another-department",
    "title": "Manual of Office Procedure",
    "section": "Dealing Files from Another Department",
    "text": "Dealing Files from Another Department\n\nIn every file referred by one Department to another for advice, concurrence, or opinion, the notes written by the Department or Branch/Section referred to should be on a ‚Äòshadow file,‚Äô i.e., a separate file.\nIn case the proposal of the receiving Department has been approved by the concerned Minister-in-Charge/Chief Minister, then a specific mention should be made in the advice being tendered to the referring Department that ‚ÄúMinister-in-Charge or Chief Minister, as the case may be, has approved.‚Äù"
  },
  {
    "objectID": "manual_office_procedure_22_sep_23.html#guidelines-for-noting",
    "href": "manual_office_procedure_22_sep_23.html#guidelines-for-noting",
    "title": "Manual of Office Procedure",
    "section": "Guidelines for Noting",
    "text": "Guidelines for Noting\n\nIIIIIIIV\n\n\n\nA note must be concise, clear, complete, correct, courteous, and to the point. Lengthy notes are to be avoided.\nThe verbatim reproduction of extracts from or paraphrasing of the paper under consideration, fresh receipt, or any other part of correspondence or notes on the same file should be avoided.\nAll notes should be written in the third person.\n\n\n\n\nRelevant extracts of the provisions of the Act, Rules, and /or guidelines will be placed on the file, and attention will be drawn to it in the note, rather than reproducing the relevant provisions in the note.\nMake a note of the actual points proposed to make without reiterating the ground already covered in the previous notes. If one agrees with the line of action suggested in the preceding note, merely append a signature.\nA self-contained note will be put up with every case submitted to the Administrative Secretary or Minister.\n\n\n\n\nA self-contained note is prepared while seeking advice or opinion or concurrence of another Department.\nSufficient space, not less than one quarter of the page, should be left below the last recorded note in the note sheet of the file, especially when the file is submitted to the Secretary or Minister level.\n\n\n\n\nTwo extra blank note-sheets should be added to the noting portion after completing the note.\nThe dealing hand (non-gazetted) is required to sign the note on the extreme left part near the margin. However, the gazetted officers will sign on the right-hand side."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Random Projects",
    "section": "",
    "text": "TidyTuesday Week 44: Horror Legends\n\n\nLooking at the snopes.com articles as a part of #TidyTuesday Week 44 (Oct 31, 2023)\n\n\n\n\n#TidyTuesday\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\n  \n\n\n\n\nPatient Risk Profiles\n\n\nLooking at the Jenna Rep‚Äôs curated data-set of Patient Risk Profiles as a part of #TidyTuesday Week 43 (Oct 23, 2023)\n\n\n\n\n#TidyTuesday\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\n  \n\n\n\n\nMaking road-maps of cities with Open Street Maps\n\n\nA user-created function to create street art maps in a single line of code\n\n\n\n\nData Visualization\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\n  \n\n\n\n\nDancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music\n\n\nLooking at the W. Jake Thompson‚Äôs curated data-set of Taylor Swift songs as a part of #TidyTuesday (Oct 10, 2023)\n\n\n\n\n#TidyTuesday\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\n  \n\n\n\n\nCreating racing bar charts in R with gganimate\n\n\nAnnotated code to create racing bar charts using nycflight13 dataset\n\n\n\n\nData Visualization\n\n\n\n\n\n\n\n\n\n\n\nOct 17, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\n  \n\n\n\n\nGhostly Jargon in Haunted Spots: A Gendered Perspective\n\n\nLooking at the dataset for haunted places in USA as a part of Tidy Tuesday (Oct 10, 2023)\n\n\n\n\n#TidyTuesday\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tidy_tuesday_2023_10_10.html",
    "href": "tidy_tuesday_2023_10_10.html",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "",
    "text": "Figure¬†1: Percentage of haunted locations with gender-specific terms in descriptions"
  },
  {
    "objectID": "tidy_tuesday_2023_10_10.html#ghostly-jargon-in-haunted-spots-a-gendered-perspective",
    "href": "tidy_tuesday_2023_10_10.html#ghostly-jargon-in-haunted-spots-a-gendered-perspective",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "text": "Ghostly Jargon in Haunted Spots: A Gendered Perspective\nFigure¬†2 illustrates the prevalence of gender-specific common words in haunted locations, comparing all American locations to haunted spots in universities and colleges.\n\n\n\n\n\nFigure¬†2: Gender-specific words‚Äô prevalence in haunted locations, comparing sites across USA with those in universities and colleges.\n\n\n\n\nCredits: Sentiment Analysis (Mohammad and Turney 2012) and code inspiration from Steven Ponce‚Äôs R script on GitHub."
  },
  {
    "objectID": "tidy_tuesday_2023_10_10.html#unique-verbiage-in-these-haunted-places",
    "href": "tidy_tuesday_2023_10_10.html#unique-verbiage-in-these-haunted-places",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "Unique Verbiage in these haunted places",
    "text": "Unique Verbiage in these haunted places\nIn contrast to the previous slide‚Äôs word clouds featuring overlapping terms, the Figure¬†3 shows distinct vocabulary found exclusively in male and female haunted locations.\n\n\n\n\n\nFigure¬†3: Unique words in descriptions of gender-specific haunted locations, but absent in descriptions of the opposite gender‚Äôs haunted places.\n\n\n\n\nCarefully look at All Haunted Places citing males: Who knew America‚Äôs haunted places had such a penchant for ‚Äúwife‚Äù ‚Äì even beyond the grave! Ghostly husbands, you‚Äôve got some explaining to do! üòÑüëª"
  },
  {
    "objectID": "projects/racing_bar_charts_r.html",
    "href": "projects/racing_bar_charts_r.html",
    "title": "Creating racing bar charts in R with gganimate",
    "section": "",
    "text": "Background\nWe‚Äôre about to embark on a thrilling journey through the world of animated racing bar charts in R - dynamic, action-packed data visualization that showcases the ebb and flow of information over time.\nInspired by the ingenious work of Deepsha Meghnani‚Äôs article on TidyTuesday and drawing creative insights from the brilliant minds at datacornering.com, we‚Äôll be crafting our very own data-driven racing bar chart masterpiece.\nOur canvas is the nycflights13 dataset, with details on flights departing from New York City‚Äôs three iconic airports, courtesy of various carriers, all throughout the year 2013.\nBut that‚Äôs not all. We won‚Äôt stop at just displaying the numbers. We‚Äôll also throw in some flair by illustrating the average delays associated with each of these carriers, injecting a dose of character into the aviation landscape of the Big Apple. We‚Äôre going to unravel the secrets of creating animated racing bar charts using the formidable ggplot2 and gganimate packages in R.\n\n\nCode\nlibrary(tidyverse)          # Loading Tidyverse for data wrangling\nlibrary(gt)                 # Loading gt package for beautiful tables\nlibrary(gganimate)          # For animations\nlibrary(nycflights13)       # for the flights data-set\nlibrary(lubridate)          # to handle dates in tidyverse\n\n\n\n\nCode\n# Loading the flights dataset\ndata(\"flights\")\n\n# Pick out the top nine airline carriers only, to avoid crowding the\n# upcoming animated plot\ncarriers_to_plot &lt;- flights |&gt;\n  \n  # Count the number of flights for each carrier and sort them in descending order\n  count(carrier, sort = TRUE) |&gt;\n  \n  # Select the top 9 carriers based on flight count\n  slice_head(n = 9) |&gt;\n  \n  # Extract the 'carrier' column from the result\n  pull(carrier)\n\ndf &lt;- flights |&gt; \n  \n  # Filter the flights dataset to include only the top 9 carriers\n  filter(carrier %in% carriers_to_plot) |&gt; \n  \n  # Create a new 'date' column by combining year, month, and day\n  # This allows us to make a single date variable, that nicely evolves\n  # over time in an animated plot\n  mutate(date = make_date(year = year, month = month, day = day)) |&gt; \n  \n  # Select only the 'date' and 'carrier' columns\n  select(date, carrier) |&gt;\n  \n  # Joining the full names of airlines for the annotations in animated plot\n  left_join(nycflights13::airlines, by = join_by(carrier)) |&gt;\n  \n  # Remove the 'carrier' column after joining\n  select(-carrier) |&gt;\n  \n  # Rename the 'name' column to 'carrier'\n  rename(carrier = name) |&gt;\n  \n  # Count the number of flights for each date and carrier combination\n  count(date, carrier)\n\n\n\n\nExample 1\nThe visualization below captures the total number of flights operated by each carrier each month, spanning the entire year from January to December 2013. This is an animated bar chart, evolving over time, rather than a truly ‚Äúracing‚Äù bar chart.\n\n\nCode\ngganim &lt;- df |&gt;\n  \n  # Create two new columns, 'month' and 'month_anim'\n  mutate(month = month(date, label = TRUE, abbr = FALSE),\n         month_anim = month(date)) |&gt;\n  \n  # Group the data by 'month' and 'month_anim', and count the number \n  # of flights for each 'carrier'\n  group_by(month, month_anim) |&gt;\n  count(carrier, wt = n) |&gt;\n  \n  # Calculate the rank of each 'carrier' based on the flight count\n  mutate(rank_car = rank(n)) |&gt;\n  \n  # Remove grouping information\n  ungroup() |&gt;\n  \n  # Create a ggplot object with specific aesthetics for rectangles\n  ggplot(aes(xmin = 0,\n             xmax = n,\n             y = rank_car,\n             ymin = rank_car - 0.45,\n             ymax = rank_car + 0.45,\n             fill = carrier,\n             label = round(n, 0))) +\n  \n  # Add filled rectangles with transparency\n  geom_rect(alpha = 0.5) +\n  \n  # Add text labels for flight counts\n  geom_text(aes(x = n, label = as.character(n)), hjust = \"left\") +\n  \n  # Add text labels for carriers\n  geom_text(aes(x = 0, label = carrier), hjust = \"left\") +\n  \n  # Adjust the x-axis scale limits\n  scale_x_continuous(limits = c(0, 5500)) +\n  \n  # Customize labels and titles\n  labs(x = NULL, y = NULL, title = \"Number of flights each month\") +\n  \n  # Add a label indicating the month\n  geom_label(aes(label = month), \n             x = 4500, y = 1, \n             fill = \"white\", col = \"black\",\n             size = 10, \n             label.padding = unit(0.5, \"lines\")) +\n  \n  # Apply a classic theme\n  theme_classic() +\n  \n  # Customize plot appearance\n  theme(legend.position = \"none\",\n        axis.line.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.x = element_blank(),\n        title = element_text(size = 20, hjust = 0.5)) +\n  \n  # Create multiple subplots for each month\n  facet_wrap(~month_anim) +\n  \n  # Remove facet labels: this allows us to superlay the facets on top of each other\n  # and then animate the facets\n  facet_null() + \n  \n  # Create a time-based animation based on 'month_anim'\n  transition_time(month_anim)\n\n# Animate the ggplot object with specified settings\nanimate(gganim,\n        duration = 30,\n        fps = 10,\n        width = 800,\n        height = 500,\n        start_pause = 10, \n        end_pause = 20)\n\n\n\n\n\nAnimated Horizontal Bar chart showing the total flights operated by each carrier, per month.\n\n\n\n\n\nExample 2\nThe visualization below offers a unique perspective, showcasing the cumulative total of flights operated by each carrier from January to December 2013, steadily building the story month by month. A truly ‚Äúracing‚Äù bar chart.\n\n\nCode\ndf1 &lt;- df |&gt;\n  \n  # Group the data by 'carrier'\n  group_by(carrier) |&gt;\n  \n  # Calculate the cumulative sum of 'n' within each carrier group\n  # This allows us to ahve a cumulative number of flights over time in a \n  # truly \"racing\" bar cahrt over time\n  mutate(cum_n = cumsum(n)) |&gt;\n  \n  # Remove grouping information\n  ungroup() |&gt;\n  \n  # Group the data by 'date'\n  group_by(date) |&gt;\n  \n  # Calculate the rank of 'cum_n' within each date group\n  mutate(day_rank = rank(cum_n, ties.method = \"first\"))\n\ngganim &lt;- df1 |&gt; \n  \n  # Create a ggplot object with specific aesthetics for reactangles\n  ggplot(aes(xmin = 0,\n             xmax = cum_n,\n             y = day_rank,\n             ymin = day_rank - 0.45,\n             ymax = day_rank + 0.45,\n             fill = carrier,\n             label = cum_n)) +\n  \n  # Add filled rectangles with transparency\n  geom_rect(alpha = 0.5) +\n  \n  # Add text labels for cumulative flight counts\n  geom_text(aes(x = cum_n, label = as.character(cum_n)), hjust = \"left\") +\n  \n  # Add text labels for carriers\n  geom_text(aes(x = 0, label = carrier), hjust = \"left\") +\n  \n  # Customize labels and titles. Adding {closest_state} adds the transition\n  # variable value to the plot title\n  labs(x = NULL, y = NULL, title = \"Number of total flights operated up to {closest_state}\") +\n  \n  # Apply a classic theme\n  theme_classic() +\n  \n  # Customize plot appearance\n  theme(legend.position = \"none\",\n        axis.line.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.x = element_blank(),\n        title = element_text(size = 20, hjust = 0.5)) +\n  \n  # Create multiple subplots for each date\n  facet_wrap(~ date) +\n \n   # Remove facet labels\n  facet_null() +\n  \n  # Transition the plot by 'date'\n  transition_states(date) +\n  \n  # Follow the view with a fixed x-axis\n  view_follow(fixed_x = FALSE)\n\n# Animate the ggplot object with specified settings\nanimate(gganim,\n        duration = 40,\n        fps = 6,\n        width = 800,\n        height = 500,\n        start_pause = 10, \n        end_pause = 20)\n\n\n\n\n\nCumulative Horizontal racing bar-chart depicting total flights operated by each carrier over the course of the year.\n\n\n\n\n\nExample 3\nIn the final visualiation below, we delve into the average flights‚Äô arrival delay (in minutes) for each carrier, every month, over the course of the year. What makes this data dance even more exciting is how it ranks carriers from the highest delay to the lowest delay, and as we traverse the months, watch as these rankings twirl and pirouette.\n\n\nCode\ngganim2 &lt;- flights |&gt;\n \n   # Filter the flights dataset to include only the top 9 carriers\n  filter(carrier %in% carriers_to_plot) |&gt;\n  \n  # Create new columns: 'date' by combining year, month, and day, and \n  # 'month' to represent the month as a label\n  mutate(date = make_date(year = year, month = month, day = day),\n         month = month(date, label = TRUE, abbr = FALSE)) |&gt;\n  \n  # Select specific columns for the subsequent analysis\n  select(date, month, carrier, arr_delay) |&gt;\n \n  # Group the data by 'month' and 'carrier', and calculate the average arrival delay\n  group_by(month, carrier) |&gt;\n  summarize(\n    avg_delay = mean(arr_delay, na.rm = TRUE)\n  ) |&gt;\n  \n  # Join the full names of airlines for the annotations in the animated plot\n  left_join(nycflights13::airlines, by = join_by(carrier)) |&gt;\n  \n  # Remove the 'carrier' column after joining and rename 'name' to 'carrier'\n  select(-carrier) |&gt;\n  rename(carrier = name) |&gt;\n  \n  # Calculate the rank of average delay, considering ties\n  mutate(delay_rank = rank(avg_delay, ties.method = \"first\")) |&gt;\n  \n  # Create a ggplot object with specific aesthetics for the rectangles\n  ggplot(aes(xmin = 0,\n             xmax = avg_delay,\n             y = delay_rank,\n             ymin = delay_rank - 0.45,\n             ymax = delay_rank + 0.45,\n             fill = carrier\n             )\n         ) +\n  \n  # Add filled rectangles with transparency\n  geom_rect(alpha = 0.5) +\n  \n  # Add text labels for average delay values\n  geom_text(aes(x = avg_delay, \n                label = as.character(round(avg_delay, 1))), \n            hjust = \"left\") +\n  \n  # Add text labels for carriers\n  geom_text(aes(x = 0, label = carrier), hjust = \"left\") +\n  \n  # Add a label indicating the month\n  geom_label(aes(label = month),\n             x = 4500, y = 1,\n             fill = \"white\", col = \"black\",\n             size = 10,\n             label.padding = unit(0.5, \"lines\")) +\n  \n  # Customize labels and titles\n  labs(x = NULL, y = NULL,\n       title = \"Average flight arrival delay (in minutes) during {closest_state}\") +\n  \n  # Apply a classic theme\n  theme_classic() +\n \n  # Customize plot appearance\n  theme(legend.position = \"none\",\n        axis.line.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.x = element_blank(),\n        title = element_text(size = 20, hjust = 0.5)) +\n  \n  # Create multiple subplots for each month\n  facet_wrap(~ month) +\n  \n  # Remove facet labels\n  facet_null() +\n  \n  # Transition the plot by 'month'\n  transition_states(month)\n\n# Animate the ggplot object with specified settings\nanimate(gganim2,\n        duration = 40,\n        fps = 10,\n        width = 800,\n        height = 500,\n        start_pause = 10, \n        end_pause = 20)\n\n\n\n\n\nAn animated horizontal bar chart for average flight arrival delay in each month for different airline carriers\n\n\nNotice that in some bad weather months (like June, July and December), almost every airline has considerable delays. On the contrary, if you like being on time, the best months to fly seem to be September to November."
  },
  {
    "objectID": "projects/tidy_tuesday_2023_10_10.html",
    "href": "projects/tidy_tuesday_2023_10_10.html",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "",
    "text": "Figure¬†1: Percentage of haunted locations with gender-specific terms in descriptions"
  },
  {
    "objectID": "projects/tidy_tuesday_2023_10_10.html#ghostly-jargon-in-haunted-spots-a-gendered-perspective",
    "href": "projects/tidy_tuesday_2023_10_10.html#ghostly-jargon-in-haunted-spots-a-gendered-perspective",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "text": "Ghostly Jargon in Haunted Spots: A Gendered Perspective\nFigure¬†2 illustrates the prevalence of gender-specific common words in haunted locations, comparing all American locations to haunted spots in universities and colleges.\n\n\n\n\n\nFigure¬†2: Gender-specific words‚Äô prevalence in haunted locations, comparing sites across USA with those in universities and colleges.\n\n\n\n\nCredits: Sentiment Analysis (Mohammad and Turney 2012) and code inspiration from Steven Ponce‚Äôs R script on GitHub."
  },
  {
    "objectID": "projects/tidy_tuesday_2023_10_10.html#unique-verbiage-in-these-haunted-places",
    "href": "projects/tidy_tuesday_2023_10_10.html#unique-verbiage-in-these-haunted-places",
    "title": "Ghostly Jargon in Haunted Spots: A Gendered Perspective",
    "section": "Unique Verbiage in these haunted places",
    "text": "Unique Verbiage in these haunted places\nIn contrast to the previous slide‚Äôs word clouds featuring overlapping terms, the Figure¬†3 shows distinct vocabulary found exclusively in male and female haunted locations.\n\n\n\n\n\nFigure¬†3: Unique words in descriptions of gender-specific haunted locations, but absent in descriptions of the opposite gender‚Äôs haunted places.\n\n\n\n\nCarefully look at All Haunted Places citing males: Who knew America‚Äôs haunted places had such a penchant for ‚Äúwife‚Äù ‚Äì even beyond the grave! Ghostly husbands, you‚Äôve got some explaining to do! üòÑüëª"
  },
  {
    "objectID": "projects/taylor_swift.html",
    "href": "projects/taylor_swift.html",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "",
    "text": "Getting the data from TidyTuesday Retrieve the data originally from the taylor R package from W. Jake Thompson is a curated data set of Taylor Swift songs, including lyrics and audio characteristics. The data comes from Genius and the Spotify API.\n\n\nCode\nlibrary(tidyverse)       # Data Wrangling and Visualization\nlibrary(visdat)          # View data in Exploratory Data Analysis\nlibrary(gganimate)       # For animation\nlibrary(transformr)      # to smoothly animate polygons and paths\n\n# Using Option 2: Read data directly from GitHub\n\ntaylor_album_songs &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_album_songs.csv')\ntaylor_all_songs &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_all_songs.csv')\ntaylor_albums &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_albums.csv')"
  },
  {
    "objectID": "projects/taylor_swift.html#creating-an-animated-plot",
    "href": "projects/taylor_swift.html#creating-an-animated-plot",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Creating an animated plot",
    "text": "Creating an animated plot\n\n# creating a loess predictor variable\ndf &lt;- taylor_all_songs |&gt; \n  select(album_name,\n         track_release,\n         danceability, \n         acousticness) |&gt; \n  drop_na()\n  \ngganim &lt;- df |&gt; \n  mutate(\n    smooth_dance = predict(loess(danceability ~ as.numeric(track_release), \n                                data = df,\n                                span = span_taylor)),\n    smooth_acous = predict(loess(acousticness ~ as.numeric(track_release), \n                                data = df,\n                                span = span_taylor))\n  ) |&gt; \n  pivot_longer(cols = starts_with(\"smooth\"),\n               names_to = \"smooth_indicator\",\n               values_to = \"value_smooth\") |&gt; \n  ggplot(aes(x = track_release)) +\n  geom_jitter(aes(y = danceability,\n                  group = seq_along(track_release)),\n              width = 20, \n              height = 0.001, \n              alpha = 0.3,\n              size = 3,\n              color = \"#54483e\") +\n  geom_jitter(aes(y = acousticness,\n                  group = seq_along(track_release)),\n              width = 20, \n              height = 0.001, \n              alpha = 0.3,\n              size = 3,\n              color = \"#b8396b\") +\n  ggtext::geom_richtext(data = taylor_albums, \n             mapping = aes(x = album_release,\n                           y = 0,\n                           label = album_name),\n             col = \"black\",\n             angle = 90, \n            hjust = \"left\",\n            alpha = 0.8) +\n  geom_line(aes(y = value_smooth,\n                col = smooth_indicator),\n            alpha = 0.7,\n            lwd = 2) +\n  theme_minimal() +\n  \n  scale_x_continuous(breaks = taylor_albums$album_release,\n                     labels = format(taylor_albums$album_release, \n                                     \"%b %Y\")) +\n  \n  # Using color palettes for package tayloRswift for her albums\n  tayloRswift::scale_color_taylor(palette = \"lover\",\n                                  labels = c(\"Acousticness\",\n                                             \"Danceability\") ) +\n  \n  labs(x = NULL,\n       y = \"Spotify App Score for songs\",\n       color = NULL, \n       title = \"Taylor Swift's songs over the years\",\n       subtitle = \"After 2015: Increased Acousticness, reduced danceability\",\n       caption = \"Data: taylor R package (W. Jake Thompson). Animation: Aditya Dahiya #TidyTuesday\") +\n  \n  theme(axis.text.x = element_text(angle = 90,\n                                   size = 10),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(), \n        legend.position = \"bottom\",\n        title = element_text(hjust = 0.5,\n                             size = 20),\n        legend.text = element_text(size = 20)) +\n\n  \n  transition_reveal(track_release) +\n  ease_aes(\"linear\") +\n  shadow_mark(past = TRUE)\n\nanimate(gganim, \n        height = 600,\n        width = 800,\n        fps = 10, \n        duration = 10,\n        start_pause = 3,\n        end_pause = 10)\n\nanim_save(\"docs/taylor_anim1.gif\")\n\n\n\n\nAn animated line chart (with scatterplot in background) of Taylor Swift‚Äôs songs‚Äô acousticness and danceability. The names of albums and release dates are on the bottom x-axis.\n\n\nFuture Plan: Creating an image for the page from AI images: Taylor Swift + R Tidyverse"
  },
  {
    "objectID": "projects/taylor_swift.html#step-3-creating-an-animated-plot",
    "href": "projects/taylor_swift.html#step-3-creating-an-animated-plot",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Step 3: Creating an animated plot",
    "text": "Step 3: Creating an animated plot\n\n\nCode\n# creating a loess predictor variable\ndf &lt;- taylor_all_songs |&gt; \n  select(album_name,\n         track_release,\n         danceability, \n         acousticness) |&gt; \n  drop_na()\n  \ngganim &lt;- df |&gt; \n  mutate(\n    smooth_dance = predict(loess(danceability ~ as.numeric(track_release), \n                                data = df,\n                                span = span_taylor)),\n    smooth_acous = predict(loess(acousticness ~ as.numeric(track_release), \n                                data = df,\n                                span = span_taylor))\n  ) |&gt; \n  pivot_longer(cols = starts_with(\"smooth\"),\n               names_to = \"smooth_indicator\",\n               values_to = \"value_smooth\") |&gt; \n  ggplot(aes(x = track_release)) +\n  geom_jitter(aes(y = danceability,\n                  group = seq_along(track_release)),\n              width = 20, \n              height = 0.001, \n              alpha = 0.3,\n              size = 3,\n              color = \"#54483e\") +\n  geom_jitter(aes(y = acousticness,\n                  group = seq_along(track_release)),\n              width = 20, \n              height = 0.001, \n              alpha = 0.3,\n              size = 3,\n              color = \"#b8396b\") +\n  ggtext::geom_richtext(data = taylor_albums, \n             mapping = aes(x = album_release,\n                           y = 0,\n                           label = album_name),\n             col = \"black\",\n             angle = 90, \n            hjust = \"left\",\n            alpha = 0.8) +\n  geom_line(aes(y = value_smooth,\n                col = smooth_indicator),\n            alpha = 0.7,\n            lwd = 2) +\n  theme_minimal() +\n  \n  scale_x_continuous(breaks = taylor_albums$album_release,\n                     labels = format(taylor_albums$album_release, \n                                     \"%b %Y\")) +\n  \n  # Using color palettes for package tayloRswift for her albums\n  tayloRswift::scale_color_taylor(palette = \"lover\",\n                                  labels = c(\"Acousticness\",\n                                             \"Danceability\") ) +\n  \n  labs(x = NULL,\n       y = \"Spotify App Score for songs\",\n       color = NULL, \n       title = \"Taylor Swift's songs over the years\",\n       subtitle = \"After 2015: Increased Acousticness, reduced danceability\",\n       caption = \"Data: taylor R package (W. Jake Thompson). Animation: Aditya Dahiya #TidyTuesday\") +\n  \n  theme(axis.text.x = element_text(angle = 90,\n                                   size = 10),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(), \n        legend.position = \"bottom\",\n        title = element_text(hjust = 0.5,\n                             size = 20),\n        legend.text = element_text(size = 20)) +\n\n  \n  transition_reveal(track_release) +\n  ease_aes(\"linear\") +\n  shadow_mark(past = TRUE)\n\nanimate(gganim, \n        height = 600,\n        width = 800,\n        fps = 10, \n        duration = 10,\n        start_pause = 3,\n        end_pause = 10)\n\nanim_save(\"docs/taylor_anim1.gif\")\n\n\n\n\n\nAn animated line chart (with scatterplot in background) of Taylor Swift‚Äôs songs‚Äô acousticness and danceability. The names of albums and release dates are on the bottom x-axis."
  },
  {
    "objectID": "street_map_art.html",
    "href": "street_map_art.html",
    "title": "Making road-maps of cities with Open Street Maps",
    "section": "",
    "text": "Here, I have tried to create a user friends single line of code fucntion to recreate street art maps using OpenStreetMaps. The inspiration is from the Github Workflow of Evgeny Politov. Credits to him for the majority of the code here, taken from his insights explained in this article on medium.com.\n\n# Code used for Chandigarh\ncty &lt;- opq(\"Chandigarh\")\n\ncty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\nvery_minor &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"footway\", \"track\", \"path\", \"tertiary_link\", \"secondary_link\", \"primary_link\", \"trunk_link\"))\n\nminor_road &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"residential\", \"tertiary\", \"secondary\"))\n\nmain_roads &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"primary\", \"trunk\"))\n\ncty_map &lt;- ggplot() +\n  geom_sf(\n    data = very_minor,\n    linewidth = 0.1,\n    alpha = 0.2\n  ) +\n  geom_sf(\n    data = minor_road,\n    linewidth = 0.3,\n    alpha = 0.5\n  ) +\n  geom_sf(\n    data = main_roads,\n    linewidth = 0.6,\n    alpha = 0.8\n  ) +\n  labs(title = \"Chandigarh\") +\ntheme_void()\n\nggsave(\"docs/cty_map.png\",\n  plot = cty_map,\n  device = \"png\",\n  width = 1800,\n  height = 1800,\n  units = \"px\"\n)\n\n\nNow, I create a function draw_street_map() to do this task and automate for other cities. If you want, simply copy paste the function, and use it for any city.\n\n# Code used for Chandigarh\n\ndraw_street_map &lt;- function(cityname, filename){\n  require(osmdata)\n  require(tidyverse)\n  require(sf)\n  \n  cty &lt;- osmdata::opq(cityname)\n  \n  cty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\n  very_minor &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"footway\", \"track\", \"path\", \n                          \"tertiary_link\", \"secondary_link\", \n                          \"primary_link\", \"trunk_link\"))\n\n  minor_road &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"residential\", \"tertiary\", \n                          \"secondary\"))\n\n  main_roads &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"primary\", \"trunk\"))\n\n  cty_map &lt;- ggplot() +\n    geom_sf(\n      data = very_minor,\n      linewidth = 0.1,\n      alpha = 0.2\n    ) +\n    geom_sf(\n      data = minor_road,\n      linewidth = 0.3,\n      alpha = 0.5\n    ) +\n    geom_sf(\n      data = main_roads,\n      linewidth = 0.6,\n      alpha = 0.8\n    ) +\n    labs(title = cityname) +\n  theme_void()\n\n  ggsave(filename,\n    plot = cty_map,\n    device = \"png\",\n    width = 1800,\n    height = 1800,\n    units = \"px\")\n  \n}\n\n\ndraw_street_map(\"Panchkula\", \"docs/panchkula.png\")\n\n\n\ndraw_street_map(\"Faridabad\", \"docs/faridabad.png\")\n\n\n\ndraw_street_map(\"Gurugram\", \"docs/gurugram.png\")\n\n\nNow, we create a Gurugram city centre map with some tweaks in the code. Can use opq() or the Open Street Maps‚Äô Export Interface here to get the latitude and longitude of any portion of any city and then just paste it here.\n\n# Code used for Chandigarh\ncty &lt;- opq(\"Gurugram\")\n\ncty$bbox &lt;- \"28.4071, 76.9881, 28.5106, 77.1051\"\n\ncty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\nvery_minor &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"footway\", \"track\", \"path\", \"tertiary_link\", \"secondary_link\", \"primary_link\", \"trunk_link\"))\n\nminor_road &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"residential\", \"tertiary\", \"secondary\"))\n\nmain_roads &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"primary\", \"trunk\"))\n\ncty_map &lt;- ggplot() +\n  geom_sf(\n    data = very_minor,\n    linewidth = 0.1,\n    alpha = 0.2\n  ) +\n  geom_sf(\n    data = minor_road,\n    linewidth = 0.3,\n    alpha = 0.5\n  ) +\n  geom_sf(\n    data = main_roads,\n    linewidth = 0.6,\n    alpha = 0.8\n  ) +\n  labs(title = \"Gurugram City (Central Area)\") +\ntheme_void()\n\nggsave(\"docs/gurugram_city_centre.png\",\n  plot = cty_map,\n  device = \"png\",\n  width = 1800,\n  height = 1800,\n  units = \"px\"\n)"
  },
  {
    "objectID": "street_map_art.html#prepare-the-query",
    "href": "street_map_art.html#prepare-the-query",
    "title": "Making artistic roadmaps of cities with Open Street Maps",
    "section": "Prepare the query",
    "text": "Prepare the query"
  },
  {
    "objectID": "street_map_art.html#pull-data",
    "href": "street_map_art.html#pull-data",
    "title": "Making artistic roadmaps of cities with Open Street Maps",
    "section": "Pull Data",
    "text": "Pull Data"
  },
  {
    "objectID": "street_map_art.html#examine-the-datasets-and-plot-samples",
    "href": "street_map_art.html#examine-the-datasets-and-plot-samples",
    "title": "Making artistic roadmaps of cities with Open Street Maps",
    "section": "Examine the datasets and plot samples",
    "text": "Examine the datasets and plot samples\nIf needed add/remove features and re-run queries"
  },
  {
    "objectID": "projects/street_map_art.html",
    "href": "projects/street_map_art.html",
    "title": "Making road-maps of cities with Open Street Maps",
    "section": "",
    "text": "Here, I have tried to create a user friends single line of code fucntion to recreate street art maps using OpenStreetMaps. The inspiration is from the Github Workflow of Evgeny Politov. Credits to him for the majority of the code here, taken from his insights explained in this article on medium.com.\n\n# Code used for Chandigarh\ncty &lt;- opq(\"Chandigarh\")\n\ncty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\nvery_minor &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"footway\", \"track\", \"path\", \"tertiary_link\", \"secondary_link\", \"primary_link\", \"trunk_link\"))\n\nminor_road &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"residential\", \"tertiary\", \"secondary\"))\n\nmain_roads &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"primary\", \"trunk\"))\n\ncty_map &lt;- ggplot() +\n  geom_sf(\n    data = very_minor,\n    linewidth = 0.1,\n    alpha = 0.2\n  ) +\n  geom_sf(\n    data = minor_road,\n    linewidth = 0.3,\n    alpha = 0.5\n  ) +\n  geom_sf(\n    data = main_roads,\n    linewidth = 0.6,\n    alpha = 0.8\n  ) +\n  labs(title = \"Chandigarh\") +\ntheme_void()\n\nggsave(\"docs/cty_map.png\",\n  plot = cty_map,\n  device = \"png\",\n  width = 1800,\n  height = 1800,\n  units = \"px\"\n)\n\n\nNow, I create a function draw_street_map() to do this task and automate for other cities. If you want, simply copy paste the function, and use it for any city.\n\n# Code used for Chandigarh\n\ndraw_street_map &lt;- function(cityname, filename){\n  require(osmdata)\n  require(tidyverse)\n  require(sf)\n  \n  cty &lt;- osmdata::opq(cityname)\n  \n  cty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\n  very_minor &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"footway\", \"track\", \"path\", \n                          \"tertiary_link\", \"secondary_link\", \n                          \"primary_link\", \"trunk_link\"))\n\n  minor_road &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"residential\", \"tertiary\", \n                          \"secondary\"))\n\n  main_roads &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"primary\", \"trunk\"))\n\n  cty_map &lt;- ggplot() +\n    geom_sf(\n      data = very_minor,\n      linewidth = 0.1,\n      alpha = 0.2\n    ) +\n    geom_sf(\n      data = minor_road,\n      linewidth = 0.3,\n      alpha = 0.5\n    ) +\n    geom_sf(\n      data = main_roads,\n      linewidth = 0.6,\n      alpha = 0.8\n    ) +\n    labs(title = cityname) +\n  theme_void()\n\n  ggsave(filename,\n    plot = cty_map,\n    device = \"png\",\n    width = 1800,\n    height = 1800,\n    units = \"px\")\n  \n}\n\n\ndraw_street_map(\"Panchkula\", \"docs/panchkula.png\")\n\n\n\ndraw_street_map(\"Faridabad\", \"docs/faridabad.png\")\n\n\n\ndraw_street_map(\"Gurugram\", \"docs/gurugram.png\")\n\n\nNow, we create a Gurugram city centre map with some tweaks in the code. Can use opq() or the Open Street Maps‚Äô Export Interface here to get the latitude and longitude of any portion of any city and then just paste it here.\n\ncty &lt;- opq(\"Gurugram\")\n\ncty$bbox &lt;- \"28.4071, 76.9881, 28.5106, 77.1051\"\n\ncty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\nvery_minor &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"footway\", \"track\", \"path\", \"tertiary_link\", \"secondary_link\", \"primary_link\", \"trunk_link\"))\n\nminor_road &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"residential\", \"tertiary\", \"secondary\"))\n\nmain_roads &lt;- cty_roads$osm_lines |&gt;\n  filter(highway %in% c(\"primary\", \"trunk\"))\n\ncty_map &lt;- ggplot() +\n  geom_sf(\n    data = very_minor,\n    linewidth = 0.1,\n    alpha = 0.2\n  ) +\n  geom_sf(\n    data = minor_road,\n    linewidth = 0.3,\n    alpha = 0.5\n  ) +\n  geom_sf(\n    data = main_roads,\n    linewidth = 0.6,\n    alpha = 0.8\n  ) +\n  labs(title = \"Gurugram City (Central Area)\") +\ntheme_void()\n\nggsave(\"docs/gurugram_city_centre.png\",\n  plot = cty_map,\n  device = \"png\",\n  width = 1800,\n  height = 1800,\n  units = \"px\"\n)\n\n\nLastly, I create a simple custom function draw_custom_street_map() to provide custom coordinates and plot these maps. Feel free to use this in your workflows!\nAs an example, I create map for the NIT and Old Faridabad town area of Faridabad City.\n\n\nCode\ndraw_custom_street_map &lt;- function(cityname, filename,\n                                   latitude_min, latitude_max,\n                                   longitude_min, longitude_max){\n  require(osmdata)\n  require(tidyverse)\n  require(sf)\n  \n  cty &lt;- osmdata::opq(cityname)\n  \n  cty$bbox &lt;- paste0(latitude_min, \", \", longitude_min, \", \",\n                     latitude_max, \", \", longitude_max)\n  \n  cty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\n  very_minor &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"footway\", \"track\", \"path\", \n                          \"tertiary_link\", \"secondary_link\", \n                          \"primary_link\", \"trunk_link\"))\n\n  minor_road &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"residential\", \"tertiary\", \n                          \"secondary\"))\n\n  main_roads &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"primary\", \"trunk\"))\n\n  cty_map &lt;- ggplot() +\n    geom_sf(\n      data = very_minor,\n      linewidth = 0.1,\n      alpha = 0.2\n    ) +\n    geom_sf(\n      data = minor_road,\n      linewidth = 0.3,\n      alpha = 0.5\n    ) +\n    geom_sf(\n      data = main_roads,\n      linewidth = 0.6,\n      alpha = 0.8\n    ) +\n    labs(title = cityname) +\n  theme_void()\n\n  ggsave(filename,\n    plot = cty_map,\n    device = \"png\",\n    width = 1800,\n    height = 1800,\n    units = \"px\")\n  \n}\n\n# A box coordinates of box area of NIT and Old Faridabad towns\nlatitude_min &lt;- 28.3687\nlatitude_max &lt;- 28.4291\nlongitude_min &lt;- 77.2783\nlongitude_max &lt;- 77.3397\n\n\n\ndraw_custom_street_map(\"Faridabad\", \"faridabad.png\",\n                       latitude_min = 28.3687,\n                       latitude_max = 28.4291,\n                       longitude_min = 77.2783,\n                       longitude_max = 77.3397)\n\n\nRemember, with some basic ggplot2 knowledge, you can always change the colours and various aesthetics of these maps. An example is shown below: ‚Äì\n\n\nCode\nrequire(osmdata)\nrequire(tidyverse)\nrequire(sf)\n  \ncty &lt;- osmdata::opq(\"Faridabad\")\n  \ncty$bbox &lt;- \"28.3687, 77.2783, 28.4291, 77.3397\"\n  \ncty_roads &lt;- cty |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n\nvery_minor &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"footway\", \"track\", \"path\", \n                          \"tertiary_link\", \"secondary_link\", \n                          \"primary_link\", \"trunk_link\"))\n\nminor_road &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"residential\", \"tertiary\", \n                          \"secondary\"))\n\nmain_roads &lt;- cty_roads$osm_lines |&gt;\n    filter(highway %in% c(\"primary\", \"trunk\"))\n\ncty_map &lt;- ggplot() +\n    geom_sf(\n      data = very_minor,\n      linewidth = 0.1,\n      alpha = 0.2,\n      col = \"steelblue\"\n    ) +\n    geom_sf(\n      data = minor_road,\n      linewidth = 0.3,\n      alpha = 0.5,\n      col = \"steelblue\"\n    ) +\n    geom_sf(\n      data = main_roads,\n      linewidth = 0.6,\n      alpha = 0.8,\n      col = \"#f20a1d\"\n    ) +\n    labs(title = \"Faridabad: NIT, HSVP Sectors and Old City\") +\n  theme_void() +\n  scale_y_continuous(limits = c(28.3689, 28.427))\n\nggsave(\"faridabad_col.png\",\n    plot = cty_map,\n    device = \"png\",\n    width = 1800,\n    height = 1800,\n    units = \"px\")"
  },
  {
    "objectID": "projects/taylor_swift.html#step-1-data-import",
    "href": "projects/taylor_swift.html#step-1-data-import",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "",
    "text": "Getting the data from TidyTuesday Retrieve the data originally from the taylor R package from W. Jake Thompson is a curated data set of Taylor Swift songs, including lyrics and audio characteristics. The data comes from Genius and the Spotify API.\n\n\nCode\nlibrary(tidyverse)       # Data Wrangling and Visualization\nlibrary(visdat)          # View data in Exploratory Data Analysis\nlibrary(gganimate)       # For animation\nlibrary(transformr)      # to smoothly animate polygons and paths\n\n# Using Option 2: Read data directly from GitHub\n\ntaylor_album_songs &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_album_songs.csv')\ntaylor_all_songs &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_all_songs.csv')\ntaylor_albums &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-17/taylor_albums.csv')"
  },
  {
    "objectID": "projects/taylor_swift.html#step-2-some-exploratory-data-analysis",
    "href": "projects/taylor_swift.html#step-2-some-exploratory-data-analysis",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Step 2: Some Exploratory Data Analysis",
    "text": "Step 2: Some Exploratory Data Analysis\n\n\nCode\n# Since all songs of Taylor Swift occur in taylor_all_songs, let us\n# focus on that data set only for now\ntaylor_album_songs |&gt; \n  anti_join(taylor_all_songs)\n\n\n# A tibble: 0 √ó 29\n# ‚Ñπ 29 variables: album_name &lt;chr&gt;, ep &lt;lgl&gt;, album_release &lt;date&gt;,\n#   track_number &lt;dbl&gt;, track_name &lt;chr&gt;, artist &lt;chr&gt;, featuring &lt;chr&gt;,\n#   bonus_track &lt;lgl&gt;, promotional_release &lt;date&gt;, single_release &lt;date&gt;,\n#   track_release &lt;date&gt;, danceability &lt;dbl&gt;, energy &lt;dbl&gt;, key &lt;dbl&gt;,\n#   loudness &lt;dbl&gt;, mode &lt;dbl&gt;, speechiness &lt;dbl&gt;, acousticness &lt;dbl&gt;,\n#   instrumentalness &lt;dbl&gt;, liveness &lt;dbl&gt;, valence &lt;dbl&gt;, tempo &lt;dbl&gt;,\n#   time_signature &lt;dbl&gt;, duration_ms &lt;dbl&gt;, explicit &lt;lgl&gt;, key_name &lt;chr&gt;, ‚Ä¶\n\n\nCode\n# Seeing the number of distinct values for each variable\ntaylor_all_songs |&gt; \n  summarise(across(.cols = everything(),\n                .fns = n_distinct)) |&gt; \n  pivot_longer(cols = everything(),\n               names_to = \"Variable\",\n               values_to = \"n_distinct\")\n\n\n# A tibble: 29 √ó 2\n   Variable            n_distinct\n   &lt;chr&gt;                    &lt;int&gt;\n 1 album_name                  15\n 2 ep                           3\n 3 album_release               15\n 4 track_number                31\n 5 track_name                 273\n 6 artist                      11\n 7 featuring                   20\n 8 bonus_track                  3\n 9 promotional_release         40\n10 single_release              62\n# ‚Ñπ 19 more rows\n\n\nUsing a popular function vis_dat() to see the structure of the data: ‚Äì\n\n\nCode\n# Vis_dat the data\ntaylor_all_songs |&gt; \n  vis_dat()\n\n\n\n\n\nAnd, seeing the change in different song characteristics over time: ‚Äì\n\n\nCode\n# We see the patterns over time for different variables of her \n# songs to see any distinct patterns\ntaylor_all_songs |&gt;\n  select(album_name, track_name, track_release,\n         danceability:duration_ms) |&gt; \n  pivot_longer(cols = -c(album_name, track_name, track_release),\n               names_to = \"indicator\",\n               values_to = \"value\") |&gt; \n  ggplot(aes(x = track_release,\n             y = value)) +\n  geom_point() +\n  geom_smooth() +\n  facet_wrap(~ indicator, scales = \"free\") +\n  theme_classic()\n\n\n\n\n\nCreating a static graph which we will animate later, and setting the span parameter for loess smoother: ‚Äì\n\n\nCode\n#define span to use\nspan_taylor = 0.75\n\n# Take the taylor_all_songs data frame and select specific columns:\ntaylor_all_songs |&gt; \n  select(album_name,\n         track_release,\n         danceability, \n         acousticness) |&gt; \n\n# Pivot the selected columns into a longer format with \"indicators\" and \"values\" columns:\n  pivot_longer(cols = -c(album_name, track_release),\n               names_to = \"indicators\",\n               values_to = \"values\") |&gt;\n\n# Create a ggplot visualization, setting aesthetics and geometries:\n  ggplot(aes(x = track_release,\n             y = values,\n             col = indicators,\n             label = indicators)) +\n\n# Add jittered points to the plot with specified width, height, and alpha:\n  geom_jitter(width = 20, \n              height = 0.001, \n              alpha = 0.2) +\n\n# Add a smoothed line to the plot with specified span, se, and alpha:\n  geom_smooth(span = span_taylor, \n              se = FALSE,\n              alpha = 0.6,\n              lwd = 1.2) +\n\n# Add text labels to the plot, referencing data from taylor_albums:\n  geom_text(data = taylor_albums, \n             mapping = aes(x = album_release,\n                           y = 0,\n                           label = album_name),\n             col = \"black\",\n             angle = 90, \n            hjust = \"left\") +\n\n# Apply a minimal theme to the plot:\n  theme_minimal() +\n\n# Customize the x-axis labels using breaks and formatted labels:\n  scale_x_continuous(breaks = taylor_albums$album_release,\n                     labels = format(taylor_albums$album_release, \n                                     \"%b %Y\")) +\n\n# Using color palettes from the tayloRswift package for Taylor Swift's albums:\n  tayloRswift::scale_color_taylor(palette = \"lover\") +\n\n# Add labels and customize the appearance of the plot:\n  labs(x = NULL,\n       y = \"Spotify App Score for songs\",\n       color = NULL) +\n\n# Further customize the appearance of the plot using theme settings:\n  theme(axis.text.x = element_text(angle = 90),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(), \n        legend.position = \"bottom\")"
  },
  {
    "objectID": "projects/taylor_swift.html#step-4-exploring-further-for-any-interesting-correlations",
    "href": "projects/taylor_swift.html#step-4-exploring-further-for-any-interesting-correlations",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Step 4: Exploring further for any interesting correlations",
    "text": "Step 4: Exploring further for any interesting correlations\n\n\nCode\nvars = c(\"danceability\", \"energy\", \"loudness\",\n         \"speechiness\", \"acousticness\", \"instrumentalness\",\n         \"valence\", \"tempo\", \"duration_ms\")\n\n# Select some variables to examine relations\ntaylor_all_songs |&gt; \n  select(all_of(vars)) |&gt; \n  GGally::ggpairs()\n\n\n\n\n\n\nLets re-focus on danceability and acoustics: ‚Äì\n\n\nCode\ntaylor_all_songs |&gt; \n  select(album_name, track_name, track_release,\n         danceability, acousticness) |&gt; \n  mutate(era = if_else(track_release &lt; ymd(\"2015-01-01\"),\n                       \"Earlier Era\",\n                       \"Recent Era\")) |&gt; \n  ggplot(aes(y = acousticness,\n             x = danceability)) +\n  geom_point(aes(group = era,\n                 col = era),\n             alpha = 0.75) +\n  geom_smooth(aes(group = era,\n                  col = era),\n              se = FALSE) +\n  theme_minimal()\n\n\n\n\n\n\n\nTrying Cluster Analysis, with some interesting results!\n\n\nCode\ntaylor1 &lt;- taylor_all_songs |&gt; \n  select(album_name, track_name, album_release,\n         danceability, acousticness, energy, loudness, \n         speechiness, instrumentalness, tempo) |&gt; \n  drop_na()\n\ntaylor_cluster &lt;- taylor1 |&gt;\n  select(danceability, acousticness) |&gt; \n  as.matrix() |&gt; \n  kmeans(x = _, centers = 2)\n\ntaylor1 |&gt; \n  mutate(cluster = as_factor(taylor_cluster$cluster)) |&gt; \n  mutate(era = if_else(album_release &lt; ymd(\"2013-01-01\"),\n                       \"Pre-2015\",\n                       \"Post-2015\")) |&gt; \n  ggplot(aes(y = acousticness,\n             x = danceability)) +\n  geom_smooth(se = F,\n              method = \"lm\",\n              col = \"grey\",\n              alpha = 0.2,\n              lwd = 2) +\n  geom_point(aes(col = cluster),\n             alpha = 0.5,\n             size = 2) +\n  facet_wrap(~ fct(era,\n                   levels = c(\"Pre-2015\", \"Post-2015\"))) +\n  theme_classic() +\n  theme(legend.position = \"bottom\") +\n  # Using color palettes for package tayloRswift\n  tayloRswift::scale_color_taylor(\n    palette = \"lover\",\n    labels = c(\"Danceability\",\n               \"Acousticness\")) +\n  labs(x = \"Danceability Score (Spotify)\",\n       y = \"Acousticness Score (Spotify)\",\n       col = \"Songs with higher: \")"
  },
  {
    "objectID": "projects/taylor_swift.html#lastly-the-animation",
    "href": "projects/taylor_swift.html#lastly-the-animation",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Lastly, the animation: ‚Äì",
    "text": "Lastly, the animation: ‚Äì\n\nlibrary(magick)\nimg &lt;- image_read(\"docs/taylor_jpeg.jpg\") |&gt; \n  image_colorize(opacity = 80,\n                 color = \"white\")\n  \nanim3 &lt;- taylor1 |&gt; \n  mutate(\n    cluster = as_factor(taylor_cluster$cluster),\n    album_name = fct_reorder(fct(album_name),\n                             .x = album_release)\n  ) |&gt; \n  ggplot(aes(y = acousticness,\n             x = danceability)) +\n  annotation_raster(img,\n                    xmin = -Inf, xmax = Inf,\n                    ymin = -Inf, ymax = Inf) +\n  geom_point(aes(col = cluster),\n             alpha = 0.9,\n             size = 4,\n             shape = 19) +\n  geom_text(aes(label = paste0(month(album_release, \n                                     label = TRUE), \n                               \", \", \n                               year(album_release)),\n                x = 0.25, y = 0.8\n                ),\n            hjust = \"left\",\n            size = 5\n            ) +\n  geom_text(aes(label = album_name,\n                x = 0.25, y = 0.95),\n            hjust = \"left\",\n            size = 8) +\n  facet_wrap(~ album_release) +\n  facet_null() +\n  scale_color_manual(values = c(\"#54483e\",\n                                \"#b8396b\"),\n                     labels = c(\"Danceability\",\n                                \"Acousticness\")) +\n  labs(x = \"Danceability Score (Spotify)\",\n       y = \"Acousticness Score (Spotify)\",\n       col = \"Songs with higher: \",\n       title = \"Acoustics and Danceability in Taylor Swift's songs\",\n       subtitle = \"Albums \\\"folklore\\\" and \\\"evermore\\\" were different from all other albums\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        plot.title.position = \"plot\",\n        title = element_text(size = 15),\n        legend.text = element_text(size = 15)) +\n  transition_states(states = album_release,\n                    transition_length = 6,\n                    state_length = 2) +\n  enter_fade() +\n  exit_fade()\n\nanimate(anim3,\n        height = 350,\n        width = 470,\n        duration = 20,\n        fps = 10,\n        end_pause = 3,\n        start_pause = 1)\n\nanim_save(\"docs/taylor_anim2.gif\")\n\n\nFuture Plan: Adding a time bar below the animated plot! I haven‚Äôt figured it out yet! If you can help, please click on Edit this Page on the right, or go here and send a pull request on GitHub. Thanks in anticipation!"
  },
  {
    "objectID": "projects/taylor_swift.html#step-5-lastly-the-second-animation",
    "href": "projects/taylor_swift.html#step-5-lastly-the-second-animation",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Step 5: Lastly, the second animation: ‚Äì",
    "text": "Step 5: Lastly, the second animation: ‚Äì\n\n\nCode\nlibrary(magick)\nimg &lt;- image_read(\"docs/taylor_jpeg.jpg\") |&gt; \n  image_colorize(opacity = 80,\n                 color = \"white\")\n  \nanim3 &lt;- taylor1 |&gt; \n  mutate(\n    cluster = as_factor(taylor_cluster$cluster),\n    album_name = fct_reorder(fct(album_name),\n                             .x = album_release)\n  ) |&gt; \n  ggplot(aes(y = acousticness,\n             x = danceability)) +\n  annotation_raster(img,\n                    xmin = -Inf, xmax = Inf,\n                    ymin = -Inf, ymax = Inf) +\n  geom_point(aes(col = cluster),\n             alpha = 0.9,\n             size = 4,\n             shape = 19) +\n  geom_text(aes(label = paste0(month(album_release, \n                                     label = TRUE), \n                               \", \", \n                               year(album_release)),\n                x = 0.25, y = 0.8\n                ),\n            hjust = \"left\",\n            size = 5\n            ) +\n  geom_text(aes(label = album_name,\n                x = 0.25, y = 0.95),\n            hjust = \"left\",\n            size = 8) +\n  facet_wrap(~ album_release) +\n  facet_null() +\n  scale_color_manual(values = c(\"#54483e\",\n                                \"#b8396b\"),\n                     labels = c(\"Danceability\",\n                                \"Acousticness\")) +\n  labs(x = \"Danceability Score (Spotify)\",\n       y = \"Acousticness Score (Spotify)\",\n       col = \"Songs with higher: \",\n       title = \"Acoustics and Danceability in Taylor Swift's songs\",\n       subtitle = \"Albums \\\"folklore\\\" and \\\"evermore\\\" were different from all other albums\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        plot.title.position = \"plot\",\n        title = element_text(size = 15),\n        legend.text = element_text(size = 15)) +\n  transition_states(states = album_release,\n                    transition_length = 6,\n                    state_length = 2) +\n  enter_fade() +\n  exit_fade()\n\nanimate(anim3,\n        height = 350,\n        width = 470,\n        duration = 20,\n        fps = 10,\n        end_pause = 3,\n        start_pause = 1)\n\nanim_save(\"docs/taylor_anim2.gif\")"
  },
  {
    "objectID": "projects/taylor_swift.html#step-6-future-plan",
    "href": "projects/taylor_swift.html#step-6-future-plan",
    "title": "Dancing Through the Years: A Data-Driven Look at Taylor Swift‚Äôs Music",
    "section": "Step 6? Future Plan",
    "text": "Step 6? Future Plan\nAdding a time bar below the animated plot! I haven‚Äôt figured it out yet! If you can help, please click on Edit this Page on the right, or go here and send a pull request on GitHub. Thanks in anticipation!"
  },
  {
    "objectID": "patient_risk_profiles.html",
    "href": "patient_risk_profiles.html",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "In celebration of the virtual R/Pharma Conference, we delve into the fascinating realm of Patient Risk Profiles. Thanks to the dedicated work of Jenna Reps, we have at our disposal a dataset encompassing the medical history features of 100 simulated patients, along with the predicted 1-year risk of 14 distinct outcomes derived from each patient‚Äôs unique medical history.\nWith a keen eye for exploration and a flair for data visualization, we have harnessed the power of the R programming language to unveil Interesting Relations between the different ailments (outcomes) within this dataset, ultimately culminating in the creation of an interactive visualization based on a random forests model. Join us on this data-driven journey as we unlock the secrets concealed within patient risk profiles.\n\n\n\n\n\nThe data is completely numerical, and there are no missing values. So it seems good for creating statistical learning models.\n\n\nCode\npatient_risk_profiles |&gt; \n  visdat::vis_dat() +\n  theme(axis.text.x = element_text(angle = 90,\n                                   size = 4),\n        legend.position = \"bottom\")\n\n\n\n\n\nFigure¬†1: Entire dataframe with vis_dat()\n\n\n\n\nUpon exploration, it seems that the data has mainly these columns:\n\npersonID\nAge groups\nSex\nPresence / Absence of many different risk factors as binary variables\nRisk of many outcomes as decimals (between 0 and 1)\n\nLets us improve the age groups and sex columns to make them into 1 column each. This will allow us to use age as an ordinal variable; or even the mid-point age in developing models.\n\n\n\n\n\nCode\n# Assign the result of a series of data manipulation operations to the 'prf' variable.\n\nprf &lt;- patient_risk_profiles |&gt; \n\n  # Select columns: 'personId,' names starting with \"age group\" and \"Sex\"\n  # select(personId, starts_with(\"age group\"), starts_with(\"Sex\")) |&gt; \n  \n  # Reshape the data to long format for columns starting with \"age group.\"\n  pivot_longer(cols = starts_with(\"age group\"),\n               names_to = \"age_group\",\n               values_to = \"age_value\",\n               names_prefix = \"age group:  \") |&gt; \n  \n  # Filter out rows where 'age_value' is not equal to 0.\n  filter(age_value != 0) |&gt; \n  \n  # Reshape the data to long format for columns starting with \"Sex.\"\n  pivot_longer(cols = starts_with(\"Sex\"),\n               names_to = \"gender\",\n               values_to = \"sex_value\",\n               names_prefix = \"Sex = \") |&gt; \n  \n  # Filter out rows where 'sex_value' is not equal to 0.\n  filter(sex_value != 0) |&gt; \n  \n  # Select all columns except 'sex_value' and 'age_value.'\n  select(-c(sex_value, age_value)) |&gt; \n  \n  # Reorder the columns with 'age_group' and 'gender' after 'personId.'\n  relocate(age_group, gender, .after = personId)\n\n# Creating levels of the age group to make it an ordinal variable\nlevels_age &lt;- prf |&gt; \n  distinct(age_group) |&gt; \n  separate_wider_delim(cols = age_group,\n                       delim = \" -  \",\n                       names = c(\"age_lower\", NA),\n                       cols_remove = FALSE) |&gt; \n  mutate(age_lower = parse_number(age_lower)) |&gt; \n  arrange(age_lower) |&gt; \n  pull(age_group)\n\n# Adding levels of factor to age group  \nprf &lt;- prf |&gt; \n  mutate(age_group = fct(age_group, levels = levels_age))\n\n# Removing double observations for persons with sex male and female both\ngend_rm &lt;- patient_risk_profiles |&gt; \n  filter(`Sex = FEMALE` == 1 & `Sex = MALE` == 1) |&gt; \n  pull(personId)\n\nprf &lt;- prf |&gt; \n  mutate(gender = if_else(personId %in% gend_rm,\n                          \"MIXED\",\n                          gender)) |&gt; \n  filter(!duplicated(personId))\n\n\n\n\n\n\n\n\nCode\nprf |&gt; \n  ggplot(aes(y = age_group)) +\n  geom_bar() +\n  theme_minimal() +\n  labs(title = \"Distribution of age-groups in the data set shows no particular pattern\",\n       y = NULL, x = \"Number of persons in the data set\") +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nFigure¬†2: A bar chart showing distribution of age groups int he simulated data set on Patient Risk Profiles\n\n\n\n\n\n\n\n\nNow, lets focus on outcomes to visually check correlations amongst them. We can see there are total 14 different outcomes which are ‚Äúpredicted‚Äù in this data-set. An interactive heat-map using heatmaply package with a dendrogram to classify groups of outcomes: ‚Äì\n\n\nCode\ncolnames_prf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\")) |&gt; \n  colnames() |&gt;\n  as_tibble() |&gt; \n  mutate(small = str_remove(value, \"predicted risk of \"),\n         smaller = str_sub(small, start = 1, end = 20))\n\nprf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\"))\n\ncolnames(prf1) &lt;- colnames_prf1$smaller\n\nprf1 |&gt; \n  as.data.frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor()\n\n\n\n\n\n\nWe can see that there are two groups of outcomes, one in bottom-left (very strong correlations) and other small group at top-right (less stronger correlations). Lets keep that in mind as we come to it later.\nLets also try principal components analysis to see if there exist groups of outcomes within the 100 simulated patients in terms of their outcomes: ‚Äì\n\n\nCode\npc1 &lt;- prf1 |&gt; \n  as.matrix() |&gt; \n  prcomp(scale = TRUE)\n\nbiplot(pc1, scale = 0)\n\n\n\n\n\nAs we can see in the bivariate plot, the predicted conditions (in red arrows) are clustered along two directions. This, sort of, reinforces out view formed earlier from the heatmap that there are, broadly, two groups of outcomes.\n\n\n\n\nListing the predictors present in the data set: there are 64 of them !\n\n\nCode\nprf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender)) |&gt; \n  colnames() |&gt; \n  as_tibble() |&gt; \n  rename(`Variables` = value) |&gt; \n  gt::gt() |&gt; gt::opt_interactive(page_size_default = 5) |&gt; \n  gt::tab_header(title = \"List of risk factors in the data set\")\n\n\n\n\n\n\nList of risk factors in the data set\n\n\n\n\n\n\n\nAnd, the correlations between different risk factors using an interactive heat-map: ‚Äì\n\n\nCode\n# Selecting the predictors alone\nprf2 &lt;- prf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender))\n\n# Creating a tibble of their full names, small and \n# smaller names\ncolnames_prf2 &lt;- colnames(prf2) |&gt;\n  as_tibble() |&gt; \n  mutate(\n    small = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_to_title(),\n    \n    smaller = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_sub(start = 1, end = 15) |&gt; \n      str_to_title()\n  )\n\n# Easy names to display in correlation matrix\ncolnames(prf2) &lt;- colnames_prf2$smaller\n\nprf2 |&gt; \n  as_data_frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor(fontsize_row = 4,\n                           fontsize_col = 4)\n\n\n\n\n\n\nAs we can see, no specific patterns stand out amongst predictors. A few moderately positive correlations seem to be ones of disease - medicine. For example, Urinary Tract Infections are treated by Spreptogramins. Hence, both appear together.\n\n\n\n\nTrying out Variable Importance Plots and Random Forests to select best predictors\nPlanned steps\n\nFind top predictors for each outcome and also save their %IncMSE\nCombine predictor importance for each outcome into a final tibble\nCreate a stacked bar chart for all these predictors\nMake it interactive with plotly\n\n\n\n\n\nCode\n# Loading random Forest library\nlibrary(randomForest)\n\n# Setting a seed for reproducability of results\nset.seed(1)\n\n# cleaning out names of all risk factors and outcomes for easy\n# construction of formulas in for loops\nprftemp &lt;- prf |&gt;\n  clean_names()\n\n# An empty tibble to fill in the data\nrisk_factors &lt;- tibble(\n  outcome_variable = NA,\n  risk_factors = NA,\n  percentage_increase_in_MSE = NA\n)\n\n# Repeating the following loop for all outcomes\n\nfor (i in 68:81) {\n  \n  # Finding the i'th outcome variable\n  var_num = i\n  \n  # Name of the outcome - condition\n  output_var = names(prftemp)[var_num]\n  \n  # A vector of all risk factors\n  input_var = str_flatten(names(prftemp)[2:67], collapse = \" + \")\n  \n  # Creating a formula to use in Random Forest\n  modelformula = formula(paste0(output_var, \" ~ \", input_var))\n  \n  # RandomForest model created\n  model &lt;- randomForest(formula = modelformula, \n                        data = prftemp, \n                        importance = TRUE)\n  \n  # Adding risk factors and their importance to final tibbe to plot\n  risk_factors &lt;- bind_rows(\n    \n    risk_factors,\n    \n    as_tibble(\n    data.frame(risk_factors = rownames(importance(model)), \n               importance(model),\n               outcome_variable = output_var)\n    ) |&gt; \n    rename(percentage_increase_in_MSE = `X.IncMSE`) |&gt; \n    select(-IncNodePurity) |&gt; \n    relocate(outcome_variable) |&gt; \n    arrange(desc(percentage_increase_in_MSE))\n    \n  )  \n  \n}\n\n\nNow, plotting the results in a nice static ggplot2 graph: ‚Äì\n\n\nCode\n# Writing a nice caption for the plot\nplot_caption &lt;- expression(paste(\n  italic(\"#TidyTuesday\"),\n  \". Data: Simulated Patient Risk Profiles by Jenna Reps.\",\n  italic(\"Graphics: Aditya Dahiya\")))\n\nrisk_factors |&gt; \n  drop_na() |&gt; \n  mutate(\n    outcome_variable = str_remove(outcome_variable,\n                                       \"predicted_risk_of_\"),\n    outcome_variable = to_title_case(outcome_variable),\n    risk_factors = to_sentence_case(risk_factors),\n    outcome_variable = str_remove(outcome_variable, \" with\"),\n    outcome_variable = str_remove(outcome_variable, \" Trd\")\n  ) |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" No \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" or 2 Nd \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt;\n  filter(percentage_increase_in_MSE &gt; 5) |&gt; \n  group_by(outcome_variable) |&gt; \n  mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(y = reorder(outcome_variable, reorder_var),\n             x = percentage_increase_in_MSE,\n             fill = risk_factors)) +\n  geom_bar(stat = \"identity\",\n           position = position_stack(reverse = TRUE)) +\n  labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n       y = NULL,\n       title = \"Age is the most important risk factor associated with 8 out of 13 conditions\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n       caption = plot_caption,\n       fill = NULL) +\n  scale_fill_brewer(palette = \"Set3\") +\n  theme_minimal() +\n  theme(axis.line = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.grid = element_blank(),\n        plot.title.position = \"plot\",\n        legend.position = \"bottom\")\n\n\n\n\n\n\nA static graph can only show so few risk factor to avoid overcrowding. Lets look at an interactive graph now using ggplotly() (Sievert 2020) to display all the risk factors: ‚Äì\n\n\nCode\nlibrary(plotly)\n\nplotly::ggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE),\n           percentage_increase_in_MSE = round(percentage_increase_in_MSE, 1)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Age is the most important risk factor for most ailments\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\"),\n  \n  tooltip = c(\"fill\", \"x\")\n)\n\n\n\n\n\nFigure¬†3: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors in predicting the outcome ailments in the simulated Patient Risk Profiles data-set\n\n\n\n\n\n\n\nAnother better interactive visualization with higlighting feature across ailments using datawrapper.de . However, I am unable to add tool-tips to this interactive visualization: ‚Äì\n\n\n\n\n\nNow, since we know that age is such a dominant risk factor, lets remove it and see the other most important risk factor in an interactive visualization with plotly: ‚Äì\n\n\nCode\nggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    filter(risk_factors != \"Age group\") |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Role of other risk factors (removing age)\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    scale_fill_viridis_d() +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\")\n  ,\n  \n  tooltip = c(\"fill\", \"x\")\n  )\n\n\n\n\n\nFigure¬†4: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors, except age groups, in predicting the outcome ailments in the simulated Patient Risk Profiles data-set"
  },
  {
    "objectID": "patient_risk_profiles.html#interesting-relations-between-the-different-ailments-outcomes",
    "href": "patient_risk_profiles.html#interesting-relations-between-the-different-ailments-outcomes",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Now, lets focus on outcomes to visually check correlations amongst them. We can see there are total 14 different outcomes which are ‚Äúpredicted‚Äù in this data-set. An interactive heat-map using heatmaply package with a dendrogram to classify groups of outcomes: ‚Äì\n\n\nCode\ncolnames_prf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\")) |&gt; \n  colnames() |&gt;\n  as_tibble() |&gt; \n  mutate(small = str_remove(value, \"predicted risk of \"),\n         smaller = str_sub(small, start = 1, end = 20))\n\nprf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\"))\n\ncolnames(prf1) &lt;- colnames_prf1$smaller\n\nprf1 |&gt; \n  as.data.frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor()\n\n\n\n\n\n\nWe can see that there are two groups of outcomes, one in bottom-left (very strong correlations) and other small group at top-right (less stronger correlations). Lets keep that in mind as we come to it later.\nLets also try principal components analysis to see if there exist groups of outcomes within the 100 simulated patients in terms of their outcomes: ‚Äì\n\n\nCode\npc1 &lt;- prf1 |&gt; \n  as.matrix() |&gt; \n  prcomp(scale = TRUE)\n\nbiplot(pc1, scale = 0)\n\n\n\n\n\nAs we can see in the bivariate plot, the predicted conditions (in red arrows) are clustered along two directions. This, sort of, reinforces out view formed earlier from the heatmap that there are, broadly, two groups of outcomes."
  },
  {
    "objectID": "patient_risk_profiles.html#a-look-at-the-different-risk-factors",
    "href": "patient_risk_profiles.html#a-look-at-the-different-risk-factors",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Listing the predictors present in the data set: there are 64 of them !\n\n\nCode\nprf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender)) |&gt; \n  colnames() |&gt; \n  as_tibble() |&gt; \n  rename(`Variables` = value) |&gt; \n  gt::gt() |&gt; gt::opt_interactive(page_size_default = 5) |&gt; \n  gt::tab_header(title = \"List of risk factors in the data set\")\n\n\n\n\n\n\nList of risk factors in the data set\n\n\n\n\n\n\n\nAnd, the correlations between different risk factors using an interactive heat-map: ‚Äì\n\n\nCode\n# Selecting the predictors alone\nprf2 &lt;- prf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender))\n\n# Creating a tibble of their full names, small and \n# smaller names\ncolnames_prf2 &lt;- colnames(prf2) |&gt;\n  as_tibble() |&gt; \n  mutate(\n    small = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_to_title(),\n    \n    smaller = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_sub(start = 1, end = 15) |&gt; \n      str_to_title()\n  )\n\n# Easy names to display in correlation matrix\ncolnames(prf2) &lt;- colnames_prf2$smaller\n\nprf2 |&gt; \n  as_data_frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor(fontsize_row = 4,\n                           fontsize_col = 4)\n\n\n\n\n\n\nAs we can see, no specific patterns stand out amongst predictors. A few moderately positive correlations seem to be ones of disease - medicine. For example, Urinary Tract Infections are treated by Spreptogramins. Hence, both appear together."
  },
  {
    "objectID": "patient_risk_profiles.html#important-predictors-for-each-outcome",
    "href": "patient_risk_profiles.html#important-predictors-for-each-outcome",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Trying out Variable Importance Plots and Random Forests to select best predictors\nPlanned steps\n\nFind top predictors for each outcome and also save their %IncMSE\nCombine predictor importance for each outcome into a final tibble\nCreate a stacked bar chart for all these predictors\nMake it interactive with plotly\n\n\n\n\n\nCode\n# Loading random Forest library\nlibrary(randomForest)\n\n# Setting a seed for reproducability of results\nset.seed(1)\n\n# cleaning out names of all risk factors and outcomes for easy\n# construction of formulas in for loops\nprftemp &lt;- prf |&gt;\n  clean_names()\n\n# An empty tibble to fill in the data\nrisk_factors &lt;- tibble(\n  outcome_variable = NA,\n  risk_factors = NA,\n  percentage_increase_in_MSE = NA\n)\n\n# Repeating the following loop for all outcomes\n\nfor (i in 68:81) {\n  \n  # Finding the i'th outcome variable\n  var_num = i\n  \n  # Name of the outcome - condition\n  output_var = names(prftemp)[var_num]\n  \n  # A vector of all risk factors\n  input_var = str_flatten(names(prftemp)[2:67], collapse = \" + \")\n  \n  # Creating a formula to use in Random Forest\n  modelformula = formula(paste0(output_var, \" ~ \", input_var))\n  \n  # RandomForest model created\n  model &lt;- randomForest(formula = modelformula, \n                        data = prftemp, \n                        importance = TRUE)\n  \n  # Adding risk factors and their importance to final tibbe to plot\n  risk_factors &lt;- bind_rows(\n    \n    risk_factors,\n    \n    as_tibble(\n    data.frame(risk_factors = rownames(importance(model)), \n               importance(model),\n               outcome_variable = output_var)\n    ) |&gt; \n    rename(percentage_increase_in_MSE = `X.IncMSE`) |&gt; \n    select(-IncNodePurity) |&gt; \n    relocate(outcome_variable) |&gt; \n    arrange(desc(percentage_increase_in_MSE))\n    \n  )  \n  \n}\n\n\nNow, plotting the results in a nice static ggplot2 graph: ‚Äì\n\n\nCode\n# Writing a nice caption for the plot\nplot_caption &lt;- expression(paste(\n  italic(\"#TidyTuesday\"),\n  \". Data: Simulated Patient Risk Profiles by Jenna Reps.\",\n  italic(\"Graphics: Aditya Dahiya\")))\n\nrisk_factors |&gt; \n  drop_na() |&gt; \n  mutate(\n    outcome_variable = str_remove(outcome_variable,\n                                       \"predicted_risk_of_\"),\n    outcome_variable = to_title_case(outcome_variable),\n    risk_factors = to_sentence_case(risk_factors),\n    outcome_variable = str_remove(outcome_variable, \" with\"),\n    outcome_variable = str_remove(outcome_variable, \" Trd\")\n  ) |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" No \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" or 2 Nd \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt;\n  filter(percentage_increase_in_MSE &gt; 5) |&gt; \n  group_by(outcome_variable) |&gt; \n  mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(y = reorder(outcome_variable, reorder_var),\n             x = percentage_increase_in_MSE,\n             fill = risk_factors)) +\n  geom_bar(stat = \"identity\",\n           position = position_stack(reverse = TRUE)) +\n  labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n       y = NULL,\n       title = \"Age is the most important risk factor associated with 8 out of 13 conditions\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n       caption = plot_caption,\n       fill = NULL) +\n  scale_fill_brewer(palette = \"Set3\") +\n  theme_minimal() +\n  theme(axis.line = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.grid = element_blank(),\n        plot.title.position = \"plot\",\n        legend.position = \"bottom\")\n\n\n\n\n\n\nA static graph can only show so few risk factor to avoid overcrowding. Lets look at an interactive graph now using ggplotly() (Sievert 2020) to display all the risk factors: ‚Äì\n\n\nCode\nlibrary(plotly)\n\nplotly::ggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE),\n           percentage_increase_in_MSE = round(percentage_increase_in_MSE, 1)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Age is the most important risk factor for most ailments\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\"),\n  \n  tooltip = c(\"fill\", \"x\")\n)\n\n\n\n\n\nFigure¬†3: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors in predicting the outcome ailments in the simulated Patient Risk Profiles data-set\n\n\n\n\n\n\n\nAnother better interactive visualization with higlighting feature across ailments using datawrapper.de . However, I am unable to add tool-tips to this interactive visualization: ‚Äì\n\n\n\n\n\nNow, since we know that age is such a dominant risk factor, lets remove it and see the other most important risk factor in an interactive visualization with plotly: ‚Äì\n\n\nCode\nggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    filter(risk_factors != \"Age group\") |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Role of other risk factors (removing age)\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    scale_fill_viridis_d() +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\")\n  ,\n  \n  tooltip = c(\"fill\", \"x\")\n  )\n\n\n\n\n\nFigure¬†4: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors, except age groups, in predicting the outcome ailments in the simulated Patient Risk Profiles data-set"
  },
  {
    "objectID": "projects/patient_risk_profiles.html",
    "href": "projects/patient_risk_profiles.html",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "In celebration of the virtual R/Pharma Conference, we delve into the fascinating realm of Patient Risk Profiles. Thanks to the dedicated work of Jenna Reps, we have at our disposal a dataset encompassing the medical history features of 100 simulated patients, along with the predicted 1-year risk of 14 distinct outcomes derived from each patient‚Äôs unique medical history.\nWith a keen eye for exploration and a flair for data visualization, we have harnessed the power of the R programming language to unveil Interesting Relations between the different ailments (outcomes) within this dataset, ultimately culminating in the creation of an interactive visualization based on a random forests model. Join us on this data-driven journey as we unlock the secrets concealed within patient risk profiles.\n\n\n\n\n\nThe data is completely numerical, and there are no missing values. So it seems good for creating statistical learning models.\n\n\nCode\npatient_risk_profiles |&gt; \n  visdat::vis_dat() +\n  theme(axis.text.x = element_text(angle = 90,\n                                   size = 4),\n        legend.position = \"bottom\")\n\n\n\n\n\nFigure¬†1: Entire dataframe with vis_dat()\n\n\n\n\nUpon exploration, it seems that the data has mainly these columns:\n\npersonID\nAge groups\nSex\nPresence / Absence of many different risk factors as binary variables\nRisk of many outcomes as decimals (between 0 and 1)\n\nLets us improve the age groups and sex columns to make them into 1 column each. This will allow us to use age as an ordinal variable; or even the mid-point age in developing models.\n\n\n\n\n\nCode\n# Assign the result of a series of data manipulation operations to the 'prf' variable.\n\nprf &lt;- patient_risk_profiles |&gt; \n\n  # Select columns: 'personId,' names starting with \"age group\" and \"Sex\"\n  # select(personId, starts_with(\"age group\"), starts_with(\"Sex\")) |&gt; \n  \n  # Reshape the data to long format for columns starting with \"age group.\"\n  pivot_longer(cols = starts_with(\"age group\"),\n               names_to = \"age_group\",\n               values_to = \"age_value\",\n               names_prefix = \"age group:  \") |&gt; \n  \n  # Filter out rows where 'age_value' is not equal to 0.\n  filter(age_value != 0) |&gt; \n  \n  # Reshape the data to long format for columns starting with \"Sex.\"\n  pivot_longer(cols = starts_with(\"Sex\"),\n               names_to = \"gender\",\n               values_to = \"sex_value\",\n               names_prefix = \"Sex = \") |&gt; \n  \n  # Filter out rows where 'sex_value' is not equal to 0.\n  filter(sex_value != 0) |&gt; \n  \n  # Select all columns except 'sex_value' and 'age_value.'\n  select(-c(sex_value, age_value)) |&gt; \n  \n  # Reorder the columns with 'age_group' and 'gender' after 'personId.'\n  relocate(age_group, gender, .after = personId)\n\n# Creating levels of the age group to make it an ordinal variable\nlevels_age &lt;- prf |&gt; \n  distinct(age_group) |&gt; \n  separate_wider_delim(cols = age_group,\n                       delim = \" -  \",\n                       names = c(\"age_lower\", NA),\n                       cols_remove = FALSE) |&gt; \n  mutate(age_lower = parse_number(age_lower)) |&gt; \n  arrange(age_lower) |&gt; \n  pull(age_group)\n\n# Adding levels of factor to age group  \nprf &lt;- prf |&gt; \n  mutate(age_group = fct(age_group, levels = levels_age))\n\n# Removing double observations for persons with sex male and female both\ngend_rm &lt;- patient_risk_profiles |&gt; \n  filter(`Sex = FEMALE` == 1 & `Sex = MALE` == 1) |&gt; \n  pull(personId)\n\nprf &lt;- prf |&gt; \n  mutate(gender = if_else(personId %in% gend_rm,\n                          \"MIXED\",\n                          gender)) |&gt; \n  filter(!duplicated(personId))\n\n\n\n\n\n\n\n\nCode\nprf |&gt; \n  ggplot(aes(y = age_group)) +\n  geom_bar() +\n  theme_minimal() +\n  labs(title = \"Distribution of age-groups in the data set shows no particular pattern\",\n       y = NULL, x = \"Number of persons in the data set\") +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nFigure¬†2: A bar chart showing distribution of age groups int he simulated data set on Patient Risk Profiles\n\n\n\n\n\n\n\n\nNow, lets focus on outcomes to visually check correlations amongst them. We can see there are total 14 different outcomes which are ‚Äúpredicted‚Äù in this data-set. An interactive heat-map using heatmaply package with a dendrogram to classify groups of outcomes: ‚Äì\n\n\nCode\ncolnames_prf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\")) |&gt; \n  colnames() |&gt;\n  as_tibble() |&gt; \n  mutate(small = str_remove(value, \"predicted risk of \"),\n         smaller = str_sub(small, start = 1, end = 20))\n\nprf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\"))\n\ncolnames(prf1) &lt;- colnames_prf1$smaller\n\nprf1 |&gt; \n  as.data.frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor()\n\n\n\n\n\n\nWe can see that there are two groups of outcomes, one in bottom-left (very strong correlations) and other small group at top-right (less stronger correlations). Lets keep that in mind as we come to it later.\nLets also try principal components analysis to see if there exist groups of outcomes within the 100 simulated patients in terms of their outcomes: ‚Äì\n\n\nCode\npc1 &lt;- prf1 |&gt; \n  as.matrix() |&gt; \n  prcomp(scale = TRUE)\n\nbiplot(pc1, scale = 0)\n\n\n\n\n\nAs we can see in the bivariate plot, the predicted conditions (in red arrows) are clustered along two directions. This, sort of, reinforces out view formed earlier from the heatmap that there are, broadly, two groups of outcomes.\n\n\n\n\nListing the predictors present in the data set: there are 64 of them !\n\n\nCode\nprf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender)) |&gt; \n  colnames() |&gt; \n  as_tibble() |&gt; \n  rename(`Variables` = value) |&gt; \n  gt::gt() |&gt; gt::opt_interactive(page_size_default = 5) |&gt; \n  gt::tab_header(title = \"List of risk factors in the data set\")\n\n\n\n\n\n\nList of risk factors in the data set\n\n\n\n\n\n\n\nAnd, the correlations between different risk factors using an interactive heat-map: ‚Äì\n\n\nCode\n# Selecting the predictors alone\nprf2 &lt;- prf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender))\n\n# Creating a tibble of their full names, small and \n# smaller names\ncolnames_prf2 &lt;- colnames(prf2) |&gt;\n  as_tibble() |&gt; \n  mutate(\n    small = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_to_title(),\n    \n    smaller = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_sub(start = 1, end = 15) |&gt; \n      str_to_title()\n  )\n\n# Easy names to display in correlation matrix\ncolnames(prf2) &lt;- colnames_prf2$smaller\n\nprf2 |&gt; \n  as_data_frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor(fontsize_row = 4,\n                           fontsize_col = 4)\n\n\n\n\n\n\nAs we can see, no specific patterns stand out amongst predictors. A few moderately positive correlations seem to be ones of disease - medicine. For example, Urinary Tract Infections are treated by Spreptogramins. Hence, both appear together.\n\n\n\n\nTrying out Variable Importance Plots and Random Forests to select best predictors\nPlanned steps\n\nFind top predictors for each outcome and also save their %IncMSE\nCombine predictor importance for each outcome into a final tibble\nCreate a stacked bar chart for all these predictors\nMake it interactive with plotly\n\n\n\n\n\nCode\n# Loading random Forest library\nlibrary(randomForest)\n\n# Setting a seed for reproducability of results\nset.seed(1)\n\n# cleaning out names of all risk factors and outcomes for easy\n# construction of formulas in for loops\nprftemp &lt;- prf |&gt;\n  clean_names()\n\n# An empty tibble to fill in the data\nrisk_factors &lt;- tibble(\n  outcome_variable = NA,\n  risk_factors = NA,\n  percentage_increase_in_MSE = NA\n)\n\n# Repeating the following loop for all outcomes\n\nfor (i in 68:81) {\n  \n  # Finding the i'th outcome variable\n  var_num = i\n  \n  # Name of the outcome - condition\n  output_var = names(prftemp)[var_num]\n  \n  # A vector of all risk factors\n  input_var = str_flatten(names(prftemp)[2:67], collapse = \" + \")\n  \n  # Creating a formula to use in Random Forest\n  modelformula = formula(paste0(output_var, \" ~ \", input_var))\n  \n  # RandomForest model created\n  model &lt;- randomForest(formula = modelformula, \n                        data = prftemp, \n                        importance = TRUE)\n  \n  # Adding risk factors and their importance to final tibbe to plot\n  risk_factors &lt;- bind_rows(\n    \n    risk_factors,\n    \n    as_tibble(\n    data.frame(risk_factors = rownames(importance(model)), \n               importance(model),\n               outcome_variable = output_var)\n    ) |&gt; \n    rename(percentage_increase_in_MSE = `X.IncMSE`) |&gt; \n    select(-IncNodePurity) |&gt; \n    relocate(outcome_variable) |&gt; \n    arrange(desc(percentage_increase_in_MSE))\n    \n  )  \n  \n}\n\n\nNow, plotting the results in a nice static ggplot2 graph: ‚Äì\n\n\nCode\n# Writing a nice caption for the plot\nplot_caption &lt;- expression(paste(\n  italic(\"#TidyTuesday\"),\n  \". Data: Simulated Patient Risk Profiles by Jenna Reps.\",\n  italic(\"Graphics: Aditya Dahiya\")))\n\nrisk_factors |&gt; \n  drop_na() |&gt; \n  mutate(\n    outcome_variable = str_remove(outcome_variable,\n                                       \"predicted_risk_of_\"),\n    outcome_variable = to_title_case(outcome_variable),\n    risk_factors = to_sentence_case(risk_factors),\n    outcome_variable = str_remove(outcome_variable, \" with\"),\n    outcome_variable = str_remove(outcome_variable, \" Trd\")\n  ) |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" No \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" or 2 Nd \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt;\n  filter(percentage_increase_in_MSE &gt; 5) |&gt; \n  group_by(outcome_variable) |&gt; \n  mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(y = reorder(outcome_variable, reorder_var),\n             x = percentage_increase_in_MSE,\n             fill = risk_factors)) +\n  geom_bar(stat = \"identity\",\n           position = position_stack(reverse = TRUE)) +\n  labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n       y = NULL,\n       title = \"Age is the most important risk factor associated with 8 out of 13 conditions\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n       caption = plot_caption,\n       fill = NULL) +\n  scale_fill_brewer(palette = \"Set3\") +\n  theme_minimal() +\n  theme(axis.line = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.grid = element_blank(),\n        plot.title.position = \"plot\",\n        legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nA static graph can only show so few risk factor to avoid overcrowding. Lets look at an interactive graph now using ggplotly() to display all the risk factors: ‚Äì\n\n\nCode\nlibrary(plotly)\n\nplotly::ggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE),\n           percentage_increase_in_MSE = round(percentage_increase_in_MSE, 1)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Age is the most important risk factor for most ailments\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\"),\n  \n  tooltip = c(\"fill\", \"x\")\n)\n\n\n\n\n\nFigure¬†3: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors in predicting the outcome ailments in the simulated Patient Risk Profiles data-set\n\n\n\n\n\n\nTrying to create and embed an interactive visualization from observable, with data wrangling in R: ‚Äì\n\n\n\n\n\nAnother better interactive visualization with highlighting feature across ailments using datawrapper.de . However, I am unable to add tool-tips to this interactive visualization: ‚Äì\n\n\n\n\n\nNow, since we know that age is such a dominant risk factor, lets remove it and see the other most important risk factor in an interactive visualization with plotly: ‚Äì\n\n\nCode\nggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    filter(risk_factors != \"Age group\") |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Role of other risk factors (removing age)\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    scale_fill_viridis_d() +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\")\n  ,\n  \n  tooltip = c(\"fill\", \"x\")\n  )\n\n\n\n\n\nFigure¬†4: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors, except age groups, in predicting the outcome ailments in the simulated Patient Risk Profiles data-set"
  },
  {
    "objectID": "projects/patient_risk_profiles.html#interesting-relations-between-the-different-ailments-outcomes",
    "href": "projects/patient_risk_profiles.html#interesting-relations-between-the-different-ailments-outcomes",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Now, lets focus on outcomes to visually check correlations amongst them. We can see there are total 14 different outcomes which are ‚Äúpredicted‚Äù in this data-set. An interactive heat-map using heatmaply package with a dendrogram to classify groups of outcomes: ‚Äì\n\n\nCode\ncolnames_prf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\")) |&gt; \n  colnames() |&gt;\n  as_tibble() |&gt; \n  mutate(small = str_remove(value, \"predicted risk of \"),\n         smaller = str_sub(small, start = 1, end = 20))\n\nprf1 &lt;- prf |&gt; \n  select(starts_with(\"predicted\"))\n\ncolnames(prf1) &lt;- colnames_prf1$smaller\n\nprf1 |&gt; \n  as.data.frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor()\n\n\n\n\n\n\nWe can see that there are two groups of outcomes, one in bottom-left (very strong correlations) and other small group at top-right (less stronger correlations). Lets keep that in mind as we come to it later.\nLets also try principal components analysis to see if there exist groups of outcomes within the 100 simulated patients in terms of their outcomes: ‚Äì\n\n\nCode\npc1 &lt;- prf1 |&gt; \n  as.matrix() |&gt; \n  prcomp(scale = TRUE)\n\nbiplot(pc1, scale = 0)\n\n\n\n\n\nAs we can see in the bivariate plot, the predicted conditions (in red arrows) are clustered along two directions. This, sort of, reinforces out view formed earlier from the heatmap that there are, broadly, two groups of outcomes."
  },
  {
    "objectID": "projects/patient_risk_profiles.html#a-look-at-the-different-risk-factors",
    "href": "projects/patient_risk_profiles.html#a-look-at-the-different-risk-factors",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Listing the predictors present in the data set: there are 64 of them !\n\n\nCode\nprf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender)) |&gt; \n  colnames() |&gt; \n  as_tibble() |&gt; \n  rename(`Variables` = value) |&gt; \n  gt::gt() |&gt; gt::opt_interactive(page_size_default = 5) |&gt; \n  gt::tab_header(title = \"List of risk factors in the data set\")\n\n\n\n\n\n\nList of risk factors in the data set\n\n\n\n\n\n\n\nAnd, the correlations between different risk factors using an interactive heat-map: ‚Äì\n\n\nCode\n# Selecting the predictors alone\nprf2 &lt;- prf |&gt; \n  select(!starts_with(\"predicted\"), \n         -c(personId, age_group, gender))\n\n# Creating a tibble of their full names, small and \n# smaller names\ncolnames_prf2 &lt;- colnames(prf2) |&gt;\n  as_tibble() |&gt; \n  mutate(\n    small = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_to_title(),\n    \n    smaller = value |&gt; \n      str_remove(\" in prior year\") |&gt; \n      str_remove(\"Occurrence of \") |&gt;\n      str_remove(\"Antibiotics \") |&gt; \n      str_sub(start = 1, end = 15) |&gt; \n      str_to_title()\n  )\n\n# Easy names to display in correlation matrix\ncolnames(prf2) &lt;- colnames_prf2$smaller\n\nprf2 |&gt; \n  as_data_frame() |&gt; \n  cor() |&gt; \n  heatmaply::heatmaply_cor(fontsize_row = 4,\n                           fontsize_col = 4)\n\n\n\n\n\n\nAs we can see, no specific patterns stand out amongst predictors. A few moderately positive correlations seem to be ones of disease - medicine. For example, Urinary Tract Infections are treated by Spreptogramins. Hence, both appear together."
  },
  {
    "objectID": "projects/patient_risk_profiles.html#important-predictors-for-each-outcome",
    "href": "projects/patient_risk_profiles.html#important-predictors-for-each-outcome",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "Trying out Variable Importance Plots and Random Forests to select best predictors\nPlanned steps\n\nFind top predictors for each outcome and also save their %IncMSE\nCombine predictor importance for each outcome into a final tibble\nCreate a stacked bar chart for all these predictors\nMake it interactive with plotly\n\n\n\n\n\nCode\n# Loading random Forest library\nlibrary(randomForest)\n\n# Setting a seed for reproducability of results\nset.seed(1)\n\n# cleaning out names of all risk factors and outcomes for easy\n# construction of formulas in for loops\nprftemp &lt;- prf |&gt;\n  clean_names()\n\n# An empty tibble to fill in the data\nrisk_factors &lt;- tibble(\n  outcome_variable = NA,\n  risk_factors = NA,\n  percentage_increase_in_MSE = NA\n)\n\n# Repeating the following loop for all outcomes\n\nfor (i in 68:81) {\n  \n  # Finding the i'th outcome variable\n  var_num = i\n  \n  # Name of the outcome - condition\n  output_var = names(prftemp)[var_num]\n  \n  # A vector of all risk factors\n  input_var = str_flatten(names(prftemp)[2:67], collapse = \" + \")\n  \n  # Creating a formula to use in Random Forest\n  modelformula = formula(paste0(output_var, \" ~ \", input_var))\n  \n  # RandomForest model created\n  model &lt;- randomForest(formula = modelformula, \n                        data = prftemp, \n                        importance = TRUE)\n  \n  # Adding risk factors and their importance to final tibbe to plot\n  risk_factors &lt;- bind_rows(\n    \n    risk_factors,\n    \n    as_tibble(\n    data.frame(risk_factors = rownames(importance(model)), \n               importance(model),\n               outcome_variable = output_var)\n    ) |&gt; \n    rename(percentage_increase_in_MSE = `X.IncMSE`) |&gt; \n    select(-IncNodePurity) |&gt; \n    relocate(outcome_variable) |&gt; \n    arrange(desc(percentage_increase_in_MSE))\n    \n  )  \n  \n}\n\n\nNow, plotting the results in a nice static ggplot2 graph: ‚Äì\n\n\nCode\n# Writing a nice caption for the plot\nplot_caption &lt;- expression(paste(\n  italic(\"#TidyTuesday\"),\n  \". Data: Simulated Patient Risk Profiles by Jenna Reps.\",\n  italic(\"Graphics: Aditya Dahiya\")))\n\nrisk_factors |&gt; \n  drop_na() |&gt; \n  mutate(\n    outcome_variable = str_remove(outcome_variable,\n                                       \"predicted_risk_of_\"),\n    outcome_variable = to_title_case(outcome_variable),\n    risk_factors = to_sentence_case(risk_factors),\n    outcome_variable = str_remove(outcome_variable, \" with\"),\n    outcome_variable = str_remove(outcome_variable, \" Trd\")\n  ) |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" No \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt; \n  separate_wider_delim(cols = outcome_variable,\n                       delim = \" or 2 Nd \",\n                       names = c(\"outcome_variable\", NA),\n                       too_few = \"align_start\") |&gt;\n  filter(percentage_increase_in_MSE &gt; 5) |&gt; \n  group_by(outcome_variable) |&gt; \n  mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(y = reorder(outcome_variable, reorder_var),\n             x = percentage_increase_in_MSE,\n             fill = risk_factors)) +\n  geom_bar(stat = \"identity\",\n           position = position_stack(reverse = TRUE)) +\n  labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n       y = NULL,\n       title = \"Age is the most important risk factor associated with 8 out of 13 conditions\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n       caption = plot_caption,\n       fill = NULL) +\n  scale_fill_brewer(palette = \"Set3\") +\n  theme_minimal() +\n  theme(axis.line = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.grid = element_blank(),\n        plot.title.position = \"plot\",\n        legend.position = \"bottom\")"
  },
  {
    "objectID": "projects/patient_risk_profiles.html#interactive-visualization",
    "href": "projects/patient_risk_profiles.html#interactive-visualization",
    "title": "Patient Risk Profiles",
    "section": "",
    "text": "A static graph can only show so few risk factor to avoid overcrowding. Lets look at an interactive graph now using ggplotly() to display all the risk factors: ‚Äì\n\n\nCode\nlibrary(plotly)\n\nplotly::ggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE),\n           percentage_increase_in_MSE = round(percentage_increase_in_MSE, 1)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Age is the most important risk factor for most ailments\",\n       subtitle = \"Using RandomForests we find importance of each risk factor in predicting the 13 ailments in the dataset.\\nThe graph shows important (more than 5% increase in MSE) risk factors for predicting each ailment\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\"),\n  \n  tooltip = c(\"fill\", \"x\")\n)\n\n\n\n\n\nFigure¬†3: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors in predicting the outcome ailments in the simulated Patient Risk Profiles data-set\n\n\n\n\n\n\nTrying to create and embed an interactive visualization from observable, with data wrangling in R: ‚Äì\n\n\n\n\n\nAnother better interactive visualization with highlighting feature across ailments using datawrapper.de . However, I am unable to add tool-tips to this interactive visualization: ‚Äì\n\n\n\n\n\nNow, since we know that age is such a dominant risk factor, lets remove it and see the other most important risk factor in an interactive visualization with plotly: ‚Äì\n\n\nCode\nggplotly(\n  \n  risk_factors |&gt; \n    drop_na() |&gt; \n    mutate(\n      outcome_variable = str_remove(outcome_variable,\n                                         \"predicted_risk_of_\"),\n      outcome_variable = to_title_case(outcome_variable),\n      risk_factors = to_sentence_case(risk_factors),\n      outcome_variable = str_remove(outcome_variable, \" with\"),\n      outcome_variable = str_remove(outcome_variable, \" Trd\")\n    ) |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" No \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt; \n    separate_wider_delim(cols = outcome_variable,\n                         delim = \" or 2 Nd \",\n                         names = c(\"outcome_variable\", NA),\n                         too_few = \"align_start\") |&gt;\n    group_by(outcome_variable) |&gt; \n    mutate(reorder_var = sum(percentage_increase_in_MSE)) |&gt; \n    ungroup() |&gt; \n    filter(percentage_increase_in_MSE &gt; 0) |&gt; \n    filter(risk_factors != \"Age group\") |&gt; \n    janitor::clean_names(case = \"title\") |&gt; \n    ggplot(aes(y = reorder(`Outcome Variable`, `Reorder Var`),\n               x = `Percentage Increase in Mse`,\n               fill = `Risk Factors`)) +\n    geom_bar(stat = \"identity\",\n             position = position_stack(reverse = TRUE),\n             col = \"white\") +\n    labs(x = \"Importance of a risk factor in predicting the condition\\n(Percentage increase in MSE explained by the risk factor)\",\n         y = NULL,\n         title = \"Role of other risk factors (removing age)\",\n         fill = NULL) +\n    scale_x_continuous(limits = c(0, 100)) +\n    scale_fill_viridis_d() +\n    theme_minimal() +\n    theme(axis.line = element_blank(),\n          axis.ticks.y = element_blank(),\n          panel.grid = element_blank(),\n          plot.title.position = \"plot\",\n          legend.position = \"none\")\n  ,\n  \n  tooltip = c(\"fill\", \"x\")\n  )\n\n\n\n\n\nFigure¬†4: An interactive plotly viszualization with a stacked bar chart showing the imporance of different risk factors, except age groups, in predicting the outcome ailments in the simulated Patient Risk Profiles data-set"
  },
  {
    "objectID": "projects/horror_legends.html",
    "href": "projects/horror_legends.html",
    "title": "#TidyTuesday Week 44: Horror Legends",
    "section": "",
    "text": "Code\n# Loading libraries\nlibrary(tidyverse)      # for everything tidy manipulation and plot\nlibrary(gt)             # for nice tables\nlibrary(visdat)         # for visualizing data\nlibrary(tidytext)       # Text Evaluation\nlibrary(rvest)          # Web-scraping for complete articles\n\n# Read data directly from GitHub\n# horror_articles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-31/horror_articles.csv')\n\n# Using harvested data - to include complete text of all articles\nhorror_articles &lt;- read_csv(\"horror_legends.csv\")\n\nvis_dat(horror_articles)\n\n\n\n\n\nAlternate: Cleaning Script from #TidyTuesday webpage\n\n\nCode\nlibrary(tidyverse)\nlibrary(here)\nlibrary(fs)\nlibrary(rvest)\n\nworking_dir &lt;- here::here(\"data\", \"2023\", \"2023-10-31\")\n\nurls &lt;- paste0(\n  \"https://www.snopes.com/fact-check/category/horrors/?pagenum=\",\n  1:15\n)\n\nextract_rating &lt;- function(article_page) {\n  rating &lt;- article_page |&gt; \n    rvest::html_element(\".rating_title_wrap\") |&gt; \n    rvest::html_text2() |&gt; \n    stringr::str_remove(\"About this rating\")\n  if (is.na(rating)) {\n    rating &lt;- article_page |&gt; \n      rvest::html_element(\".status_color\") |&gt; \n      rvest::html_text2()\n  }\n  if (is.na(rating)) {\n    rating &lt;- article_page |&gt; \n      rvest::html_elements(\"noindex\") |&gt; \n      rvest::html_text2() |&gt; \n      stringr::str_squish() |&gt; \n      stringr::str_subset(\"^Status:\") |&gt; \n      stringr::str_remove(\"Status:\")\n  }\n  rating &lt;- tolower(rating) |&gt; \n    stringr::str_squish() |&gt; \n    stringr::str_remove(\"\\\\.|\\\\:\")\n  rating &lt;- dplyr::case_match(\n    rating,\n    c(\n      \"a number of real entries, one unknown, and one fiction\",\n      \"multiple\",\n      \"multiple ‚Äî see below\",\n      \"two real entries, the others are fiction\"\n    ) ~ \"mixture\",\n    .default = rating\n  )\n  return(rating)\n}\n\nextract_claim &lt;- function(article_page) {\n  claim &lt;- article_page |&gt; \n    rvest::html_element(\".claim_cont\") |&gt; \n    rvest::html_text2() |&gt; \n    stringr::str_squish()\n  if (is.na(claim)) {\n    claim &lt;- rvest::html_elements(article_page, \"p\") |&gt; \n      rvest::html_text2() |&gt; \n      stringr::str_subset(\"^Claim:\") |&gt; \n      stringr::str_remove(\"Claim:\") |&gt; \n      stringr::str_squish()\n  }\n  return(claim)\n}\n\nhorror_articles &lt;- urls |&gt;\n  purrr::map(\n    \\(article_list_url) {\n      article_list_url |&gt; \n        rvest::read_html() |&gt; \n        rvest::html_elements(\".article_wrapper\") |&gt; \n        purrr::map(\n          \\(article) {\n            # Grabbbing info from this page can result in truncation. Instead grab the\n            # URL and dig into that.\n            url &lt;- article |&gt;\n              rvest::html_element(\"a\") |&gt;\n              rvest::html_attr(\"href\")\n            article_page &lt;- rvest::read_html(url)\n            tibble::tibble(\n              title = article_page |&gt;\n                rvest::html_element(\"h1\") |&gt; \n                rvest::html_text2(),\n              url = url,\n              # Failed for some articles &lt;= 2015-05-16\n              rating = extract_rating(article_page),\n              subtitle = article_page |&gt;\n                rvest::html_element(\"h2\") |&gt; \n                rvest::html_text2(),\n              author = article_page |&gt; \n                rvest::html_element(\".author_name\") |&gt; \n                rvest::html_text() |&gt; \n                stringr::str_squish(),\n              published = article |&gt; \n                rvest::html_element(\".article_date\") |&gt; \n                rvest::html_text2() |&gt; \n                lubridate::mdy(),\n              # Failed for some articles &lt;= 2015-05-16\n              claim = extract_claim(article_page)\n            )\n          }\n        ) |&gt; \n        purrr::list_rbind()\n    }\n  ) |&gt; \n  purrr::list_rbind()\n\nreadr::write_csv(\n  horror_articles,\n  fs::path(working_dir, \"horror_articles.csv\")\n)\n\n\n\n\nTwo authors dominate the articles‚Äô authorship\n\n\nCode\nhorror_articles |&gt; \n  count(author, sort = TRUE)\n\n\n# A tibble: 13 √ó 2\n   author                n\n   &lt;chr&gt;             &lt;int&gt;\n 1 Barbara Mikkelson  1440\n 2 David Mikkelson     611\n 3 Snopes Staff         98\n 4 Kim LaCapria         40\n 5 Brooke Binkowski     26\n 6 David Emery          23\n 7 Dan Evon             22\n 8 Dan MacGuill         22\n 9 Bethania Palma       21\n10 Jordan Liles         13\n11 Arturo Garcia        12\n12 Alex Kasprak          7\n13 Madison Dapcevich     2"
  },
  {
    "objectID": "projects/horror_legends.html#loading-libraries-and-data",
    "href": "projects/horror_legends.html#loading-libraries-and-data",
    "title": "#TidyTuesday Week 44: Horror Legends",
    "section": "",
    "text": "Code\n# Loading libraries\nlibrary(tidyverse)      # for everything tidy manipulation and plot\nlibrary(gt)             # for nice tables\nlibrary(visdat)         # for visualizing data\nlibrary(tidytext)       # Text Evaluation\nlibrary(rvest)          # Web-scraping for complete articles\n\n# Read data directly from GitHub\n# horror_articles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-31/horror_articles.csv')\n\n# Using harvested data - to include complete text of all articles\nhorror_articles &lt;- read_csv(\"horror_legends.csv\")\n\nvis_dat(horror_articles)\n\n\n\n\n\nAlternate: Cleaning Script from #TidyTuesday webpage\n\n\nCode\nlibrary(tidyverse)\nlibrary(here)\nlibrary(fs)\nlibrary(rvest)\n\nworking_dir &lt;- here::here(\"data\", \"2023\", \"2023-10-31\")\n\nurls &lt;- paste0(\n  \"https://www.snopes.com/fact-check/category/horrors/?pagenum=\",\n  1:15\n)\n\nextract_rating &lt;- function(article_page) {\n  rating &lt;- article_page |&gt; \n    rvest::html_element(\".rating_title_wrap\") |&gt; \n    rvest::html_text2() |&gt; \n    stringr::str_remove(\"About this rating\")\n  if (is.na(rating)) {\n    rating &lt;- article_page |&gt; \n      rvest::html_element(\".status_color\") |&gt; \n      rvest::html_text2()\n  }\n  if (is.na(rating)) {\n    rating &lt;- article_page |&gt; \n      rvest::html_elements(\"noindex\") |&gt; \n      rvest::html_text2() |&gt; \n      stringr::str_squish() |&gt; \n      stringr::str_subset(\"^Status:\") |&gt; \n      stringr::str_remove(\"Status:\")\n  }\n  rating &lt;- tolower(rating) |&gt; \n    stringr::str_squish() |&gt; \n    stringr::str_remove(\"\\\\.|\\\\:\")\n  rating &lt;- dplyr::case_match(\n    rating,\n    c(\n      \"a number of real entries, one unknown, and one fiction\",\n      \"multiple\",\n      \"multiple ‚Äî see below\",\n      \"two real entries, the others are fiction\"\n    ) ~ \"mixture\",\n    .default = rating\n  )\n  return(rating)\n}\n\nextract_claim &lt;- function(article_page) {\n  claim &lt;- article_page |&gt; \n    rvest::html_element(\".claim_cont\") |&gt; \n    rvest::html_text2() |&gt; \n    stringr::str_squish()\n  if (is.na(claim)) {\n    claim &lt;- rvest::html_elements(article_page, \"p\") |&gt; \n      rvest::html_text2() |&gt; \n      stringr::str_subset(\"^Claim:\") |&gt; \n      stringr::str_remove(\"Claim:\") |&gt; \n      stringr::str_squish()\n  }\n  return(claim)\n}\n\nhorror_articles &lt;- urls |&gt;\n  purrr::map(\n    \\(article_list_url) {\n      article_list_url |&gt; \n        rvest::read_html() |&gt; \n        rvest::html_elements(\".article_wrapper\") |&gt; \n        purrr::map(\n          \\(article) {\n            # Grabbbing info from this page can result in truncation. Instead grab the\n            # URL and dig into that.\n            url &lt;- article |&gt;\n              rvest::html_element(\"a\") |&gt;\n              rvest::html_attr(\"href\")\n            article_page &lt;- rvest::read_html(url)\n            tibble::tibble(\n              title = article_page |&gt;\n                rvest::html_element(\"h1\") |&gt; \n                rvest::html_text2(),\n              url = url,\n              # Failed for some articles &lt;= 2015-05-16\n              rating = extract_rating(article_page),\n              subtitle = article_page |&gt;\n                rvest::html_element(\"h2\") |&gt; \n                rvest::html_text2(),\n              author = article_page |&gt; \n                rvest::html_element(\".author_name\") |&gt; \n                rvest::html_text() |&gt; \n                stringr::str_squish(),\n              published = article |&gt; \n                rvest::html_element(\".article_date\") |&gt; \n                rvest::html_text2() |&gt; \n                lubridate::mdy(),\n              # Failed for some articles &lt;= 2015-05-16\n              claim = extract_claim(article_page)\n            )\n          }\n        ) |&gt; \n        purrr::list_rbind()\n    }\n  ) |&gt; \n  purrr::list_rbind()\n\nreadr::write_csv(\n  horror_articles,\n  fs::path(working_dir, \"horror_articles.csv\")\n)\n\n\n\n\nTwo authors dominate the articles‚Äô authorship\n\n\nCode\nhorror_articles |&gt; \n  count(author, sort = TRUE)\n\n\n# A tibble: 13 √ó 2\n   author                n\n   &lt;chr&gt;             &lt;int&gt;\n 1 Barbara Mikkelson  1440\n 2 David Mikkelson     611\n 3 Snopes Staff         98\n 4 Kim LaCapria         40\n 5 Brooke Binkowski     26\n 6 David Emery          23\n 7 Dan Evon             22\n 8 Dan MacGuill         22\n 9 Bethania Palma       21\n10 Jordan Liles         13\n11 Arturo Garcia        12\n12 Alex Kasprak          7\n13 Madison Dapcevich     2"
  },
  {
    "objectID": "projects/horror_legends.html#other-ideas",
    "href": "projects/horror_legends.html#other-ideas",
    "title": "#TidyTuesday Week 44: Horror Legends",
    "section": "Other Ideas:",
    "text": "Other Ideas:\n\nStudy Text Mining with R\nText Analysis of the title, subtitle and claim - facet them by true, false and others.\nScrape story text from url and try to do text analysis by true, false and others.\nImprove visualization skills this time - make a nice poster with custom fonts and shape as from the Halloween previous Tidy Tuesday.\n\n\nMost common words in Titles, Sub-titles and Claim over time\nThere are no enough recurring words in ‚Äútitle‚Äù to draw meaningful conclusions.\n\n\nCode\nhorror_articles |&gt; \n  select(published, title) |&gt; \n  unnest_tokens(output = \"word\",\n                input = \"title\") |&gt; \n  anti_join(stop_words) |&gt; \n  group_by(published) |&gt; \n  count(word, sort = TRUE) |&gt; \n  ungroup() |&gt; \n  arrange(desc(n)) |&gt; \n  slice_head(n = 5)\n\n\n# A tibble: 5 √ó 3\n  published  word         n\n  &lt;date&gt;     &lt;chr&gt;    &lt;int&gt;\n1 1999-02-27 films       38\n2 1999-02-27 snuff       38\n3 1998-03-01 attacks     37\n4 1998-03-01 hiv         37\n5 1998-03-01 infected    37\n\n\nLets try the same in subtitle. Again, very few words that are common or recurring in subtitles.\n\n\nCode\nhorror_articles |&gt; \n  select(published, subtitle) |&gt; \n  unnest_tokens(output = \"word\",\n                input = \"subtitle\") |&gt; \n  anti_join(stop_words) |&gt; \n  group_by(published) |&gt; \n  count(word, sort = TRUE) |&gt; \n  ungroup() |&gt; \n  arrange(desc(n)) |&gt; \n  slice_head(n = 5)\n\n\n# A tibble: 5 √ó 3\n  published  word        n\n  &lt;date&gt;     &lt;chr&gt;   &lt;int&gt;\n1 1999-02-27 films      38\n2 1999-02-27 real       38\n3 1999-02-27 snuff      38\n4 1998-03-01 decades    37\n5 1998-03-01 hiv        37\n\n\nNow, let us try in the claim. First seeing how long the claims are: ‚Äì\n\n\nCode\nhorror_articles |&gt; \n  mutate(claim_length = str_length(claim)) |&gt; \n  pull(claim_length) |&gt; \n  summary()\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  26.00   75.00   92.00   99.17  117.00  625.00 \n\n\nSo, we see that the claims are not very long. On average they are 100 characters long only! Still, let us try to find the common words in claims: ‚Äì\n\n\nCode\nhorror_articles |&gt; \n  select(published, claim) |&gt; \n  unnest_tokens(output = \"word\",\n                input = \"claim\") |&gt; \n  anti_join(stop_words) |&gt; \n  group_by(published) |&gt; \n  count(word, sort = TRUE) |&gt; \n  filter(n &gt;= 2) |&gt; \n  ungroup() |&gt; \n  arrange(desc(n)) |&gt; \n  slice_head(n = 5)\n\n\n# A tibble: 5 √ó 3\n  published  word              n\n  &lt;date&gt;     &lt;chr&gt;         &lt;int&gt;\n1 1999-02-27 camera           38\n2 1999-02-27 entertainment    38\n3 1999-02-27 films            38\n4 1999-02-27 murdered         38\n5 1999-02-27 participants     38\n\n\nAgain, not enough words to plot. Let‚Äôs see if we can download the complete article text? Yes, we can!\nFinding common words in complete text by dates\n\n\nCode\n# Number of common words to plot\ncommon_n &lt;- 9\n\nstop_words &lt;- \n  bind_rows(stop_words,\n            tibble(\n              word = c(\"nbsp\", \"nobr\", \"dt\", \"dd\"),\n              lexicon = \"CUSTOM\"\n            ))\n\ntidy_horror &lt;- horror_articles |&gt; \n  select(text, paragraph, title, published) |&gt; \n  unnest_tokens(output = \"word\", \n                input = text) |&gt; \n  anti_join(stop_words) \n\ncommon_words &lt;- tidy_horror |&gt; \n  count(word, sort = TRUE) |&gt; \n  slice_head(n = common_n) |&gt; \n  pull(word)\n\ntidy_horror |&gt;\n  filter(word %in% common_words) |&gt;\n  mutate(word = fct(word, levels = common_words)) |&gt; \n  count(published, word, sort = TRUE) |&gt; \n  ggplot(aes(x = published, y = n, col = word)) +\n  geom_smooth(se = FALSE, span = 0.2) +\n  gghighlight::gghighlight() +\n  facet_wrap(~ word, ncol = (common_n %/% 3)) +\n  labs(title = \"The most common words in snopes.com articles over time\",\n       y = \"Number of times the word appears in the articles\",\n       x = NULL) +\n  scale_x_date(date_breaks = \"3 year\",\n               date_labels = \"%Y\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        panel.grid.minor = element_blank(),\n        panel.grid.major.y = element_blank(),\n        axis.text.x = element_text(angle = 90),\n        plot.title.position = \"plot\")\n\n\n\n\n\n\n\nSentiment Analysis over the course of time\nUsing nrc sentiment analysis. (Mohammad and Turney 2012)\n\n\nCode\n# seeing the distribution of the number of paragraphs in each article\nhorror_articles |&gt;\n  select(title, paragraph) |&gt; \n  group_by(title) |&gt; \n  mutate(max_p = max(paragraph)) |&gt; \n  ggplot() +\n  geom_histogram(aes(max_p), col = \"darkgrey\", fill = \"white\") +\n  theme_minimal()\n\n\n\n\n\nCode\n# One time download / agree to license of get_sentiments()\n# get_sentiments(\"afinn\")\n# get_sentiments(\"bing\")\nget_sentiments(\"nrc\")\n\n\n# A tibble: 13,872 √ó 2\n   word        sentiment\n   &lt;chr&gt;       &lt;chr&gt;    \n 1 abacus      trust    \n 2 abandon     fear     \n 3 abandon     negative \n 4 abandon     sadness  \n 5 abandoned   anger    \n 6 abandoned   fear     \n 7 abandoned   negative \n 8 abandoned   sadness  \n 9 abandonment anger    \n10 abandonment fear     \n# ‚Ñπ 13,862 more rows\n\n\nCode\n# Sentiment Analysis\nhorror_articles |&gt;\n  select(published, title, paragraph, text) |&gt; \n  unnest_tokens(word, text) |&gt;\n  mutate(index = row_number()) |&gt;\n  anti_join(stop_words) |&gt;\n  inner_join(get_sentiments(\"nrc\"),\n             relationship = \"many-to-many\") |&gt; \n  count(published, sentiment) |&gt;\n  group_by(published) |&gt; \n  mutate(prop_n = n / sum(n)) |&gt;\n  filter(!(sentiment %in% c(\"joy\", \"positive\"))) |&gt; \n  ggplot(aes(x = published,\n             y = prop_n,\n             col = sentiment)) + \n  geom_smooth(span = 0.1, se = FALSE) +\n  gghighlight::gghighlight() +\n  facet_wrap(~ sentiment, nrow = 2) +\n  labs(x = NULL, y = NULL) +\n  scale_y_continuous(labels = )\n\n\n\n\n\nCode\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 90))\n\n\nList of 2\n $ axis.text.x    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.position: chr \"none\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\n\n\n\nWord-Cloud\n\n\nImportant Words: tf-idf (by author)\n\n\nAnalyse bi-grams to find most common bi-grams"
  }
]